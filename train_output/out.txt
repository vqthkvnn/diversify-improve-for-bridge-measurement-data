Environment:
	Python: 3.7.9
	PyTorch: 1.13.0+cpu
	Torchvision: 0.14.0+cpu
	CUDA: None
	CUDNN: None
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10

Traceback (most recent call last):
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\numpy\lib\npyio.py", line 417, in load
    fid = stack.enter_context(open(os_fspath(file), "rb"))
FileNotFoundError: [Errno 2] No such file or directory: 'dataemg/emg_x.npy'
Environment:
	Python: 3.7.9
	PyTorch: 1.13.0+cpu
	Torchvision: 0.14.0+cpu
	CUDA: None
	CUDNN: None
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10

Traceback (most recent call last):
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 662, in _apply
    param_applied = fn(param)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 747, in <lambda>
    return self._apply(lambda t: t.cuda(device))
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\cuda\__init__.py", line 221, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
0                0.5990980268    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.6759639978     1.6707817316     0.0051822653    
Counter({1: 2351, 2: 1051, 0: 742})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.8324569464     0.3269388974     1.1593958139     0.7625482625     0.7275362319     0.6473004695     23.6999993324   

========ROUND 1========
====Feature update====
epoch            class_loss      
0                0.9183411598    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.0627132654     1.0023773909     0.0603359155    
Counter({1: 2373, 2: 1002, 0: 769})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6451337934     0.7862579823     1.4313917160     0.7536196911     0.7623188406     0.6437793427     23.2185163498   

========ROUND 2========
====Feature update====
epoch            class_loss      
0                0.9270728230    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.4616093636     0.9535635710     0.5080457926    
Counter({1: 2181, 2: 1215, 0: 748})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5221518278     0.2533001602     0.7754520178     0.8450772201     0.8376811594     0.6649061033     23.6030142307   

========ROUND 3========
====Feature update====
epoch            class_loss      
0                0.2872414589    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.4764027596     1.2293736935     0.2470290214    
Counter({1: 2068, 2: 1415, 0: 661})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3233915865     0.3248968124     0.6482883692     0.8617277992     0.8260869565     0.6707746479     23.8242774010   

========ROUND 4========
====Feature update====
epoch            class_loss      
0                0.6985042095    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.2798693180     0.8364759684     0.4433933496    
Counter({1: 1906, 2: 1432, 0: 806})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3855334818     0.2812996507     0.6668331623     0.8918918919     0.8570048309     0.6819248826     23.5360288620   

========ROUND 5========
====Feature update====
epoch            class_loss      
0                0.6285949945    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                0.8667916059     0.8243880272     0.0424035788    
Traceback (most recent call last):
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\popen_spawn_win32.py", line 89, in __init__
    reduction.dump(process_obj, to_child)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\reduction.py", line 60, in dump
    ForkingPickler(file, protocol).dump(obj)
BrokenPipeError: [Errno 32] Broken pipe

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 56, in main
    algorithm.set_dlabel(train_loader)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 68, in set_dlabel
    iter_test = iter(loader)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 444, in __iter__
    return self._get_iterator()
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 390, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 1077, in __init__
    w.start()
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\process.py", line 112, in start
    self._popen = self._Popen(self)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 322, in _Popen
    return Popen(process_obj)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\popen_spawn_win32.py", line 89, in __init__
    reduction.dump(process_obj, to_child)
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 25, in main
    best_valid_acc, target_acc = 0, 0
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 23, in main
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 57, in get_act_dataloader
    args, tr, val, targetdata)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 17, in get_dataloader
    train_loader = DataLoader(dataset=tr, batch_size=args.batch_size,
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 23, in main
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 45, in get_act_dataloader
    args.steps_per_epoch = int(args.steps_per_epoch*(1-rate))
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 23, in main
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 38, in get_act_dataloader
    if i in args.test_envs:
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 23, in main
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 37, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 23, in __init__
    self.transform = None
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10

Traceback (most recent call last):
  File "C:/Program Files/JetBrains/PyCharm 2021.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 23, in main
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 37, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 21, in __init__
    self.comb_position(x, cy, py, sy)
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 46, in comb_position
    ttx = np.hstack((ttx, tx[index]))
  File "<__array_function__ internals>", line 6, in hstack
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\numpy\core\shape_base.py", line 345, in hstack
    return _nx.concatenate(arrs, 1)
  File "<__array_function__ internals>", line 6, in concatenate
ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 52 and the array at index 1 has size 0
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 23, in main
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 37, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 22, in __init__
    self.x = self.x[:, :, np.newaxis, :]
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 23, in main
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 49, in get_act_dataloader
    np.random.seed(args.seed)
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 23, in main
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 56, in get_act_dataloader
    train_loader, train_loader_noshuffle, valid_loader, target_loader = get_dataloader(
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 23, in main
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 37, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 18, in __init__
    x, cy, py, sy = loaddata_from_numpy(self.dataset, self.task, root_dir)
  File "E:\robustlearn\diversify\datautil\actdata\util.py", line 25, in loaddata_from_numpy
    cy, py, sy = ty[:, 0], ty[:, 1], ty[:, 2]
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 23, in main
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 37, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 18, in __init__
    x, cy, py, sy = loaddata_from_numpy(self.dataset, self.task, root_dir)
  File "E:\robustlearn\diversify\datautil\actdata\util.py", line 25, in loaddata_from_numpy
    cy, py, sy = ty[:, 0], ty[:, 1], ty[:, 2]
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10

Traceback (most recent call last):
  File "C:/Program Files/JetBrains/PyCharm 2021.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 23, in main
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 37, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 21, in __init__
    self.comb_position(x, cy, py, sy)
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 46, in comb_position
    ttx = np.hstack((ttx, tx[index]))
  File "<__array_function__ internals>", line 6, in hstack
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\numpy\core\shape_base.py", line 345, in hstack
    return _nx.concatenate(arrs, 1)
  File "<__array_function__ internals>", line 6, in concatenate
ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 52 and the array at index 1 has size 0
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10

Traceback (most recent call last):
  File "C:/Program Files/JetBrains/PyCharm 2021.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 23, in main
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 46, in get_act_dataloader
    tdata = combindataset(args, source_datasetlist)
  File "E:\robustlearn\diversify\datautil\util.py", line 107, in __init__
    self.loader = datalist[0].loader
IndexError: list index out of range
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 23, in main
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 38, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 21, in __init__
    self.comb_position(x, cy, py, sy)
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 46, in comb_position
    ttx = np.hstack((ttx, tx[index]))
  File "<__array_function__ internals>", line 6, in hstack
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\numpy\core\shape_base.py", line 345, in hstack
    return _nx.concatenate(arrs, 1)
  File "<__array_function__ internals>", line 6, in concatenate
ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 52 and the array at index 1 has size 0
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10

Traceback (most recent call last):
  File "C:/Program Files/JetBrains/PyCharm 2021.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 23, in main
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 38, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 21, in __init__
    self.comb_position(x, cy, py, sy)
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 46, in comb_position
    ttx = np.hstack((ttx, tx[index]))
  File "<__array_function__ internals>", line 6, in hstack
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\numpy\core\shape_base.py", line 345, in hstack
    return _nx.concatenate(arrs, 1)
  File "<__array_function__ internals>", line 6, in concatenate
ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 52 and the array at index 1 has size 0
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 23, in main
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 38, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 13, in __init__
    self.domain_num = 0
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10

Traceback (most recent call last):
  File "C:/Program Files/JetBrains/PyCharm 2021.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 23, in main
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 38, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 21, in __init__
    self.comb_position(x, cy, py, sy)
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 46, in comb_position
    ttx = np.hstack((ttx, tx[index]))
  File "<__array_function__ internals>", line 6, in hstack
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\numpy\core\shape_base.py", line 345, in hstack
    return _nx.concatenate(arrs, 1)
  File "<__array_function__ internals>", line 6, in concatenate
ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 52 and the array at index 1 has size 0
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 23, in main
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 38, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 21, in __init__
    self.comb_position(x, cy, py, sy)
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 40, in comb_position
    tx, tcy, tsy = x[index], cy[index], sy[index]
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 23, in main
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 38, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 21, in __init__
    self.comb_position(x, cy, py, sy)
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 41, in comb_position
    tx, tcy, tsy = x[index], cy[index], sy[index]
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 23, in main
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 38, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 21, in __init__
    self.comb_position(x, cy, py, sy)
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 40, in comb_position
    indexs = indexs[0]
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 23, in main
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 38, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 21, in __init__
    self.comb_position(x, cy, py, sy)
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 40, in comb_position
    tx, tcy, tsy = x[index], cy[index], sy[index]
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10

Traceback (most recent call last):
  File "C:/Program Files/JetBrains/PyCharm 2021.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 23, in main
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 38, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 21, in __init__
    self.comb_position(x, cy, py, sy)
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 46, in comb_position
    ttx = np.hstack((ttx, tx[index]))
  File "<__array_function__ internals>", line 6, in hstack
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\numpy\core\shape_base.py", line 345, in hstack
    return _nx.concatenate(arrs, 1)
  File "<__array_function__ internals>", line 6, in concatenate
ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 52 and the array at index 1 has size 0
Error evaluating: thread_id: pid_28400_id_2396288337928
frame_id: 2394656406088
scope: FRAME
attrs: index
Traceback (most recent call last):
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydevd_bundle\pydevd_vars.py", line 280, in resolve_compound_variable_fields
    def resolve_compound_variable_fields(thread_id, frame_id, scope, attrs, user_type_renderers={}):
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydevd_bundle\pydevd_vars.py", line 264, in _resolve_default_variable_fields
    def _resolve_default_variable_fields(var, resolver, offset):
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\pydevd_plugins\extensions\types\pydevd_plugin_numpy_types.py", line 84, in get_dictionary
    def get_dictionary(self, obj):
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\numpy\core\_methods.py", line 42, in _amin
    def _amin(a, axis=None, out=None, keepdims=False,
ValueError: zero-size array to reduction operation minimum which has no identity
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 23, in main
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 38, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 21, in __init__
    self.comb_position(x, cy, py, sy)
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 43, in comb_position
    if j == 0:
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 23, in main
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 38, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 21, in __init__
    self.comb_position(x, cy, py, sy)
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 47, in comb_position
    if i == 0:
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 23, in main
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 38, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 21, in __init__
    self.comb_position(x, cy, py, sy)
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 43, in comb_position
    if j == 0:
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 23, in main
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 38, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 21, in __init__
    self.comb_position(x, cy, py, sy)
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 48, in comb_position
    ttx = np.hstack((ttx, tx[index]))
UnboundLocalError: local variable 'ttx' referenced before assignment
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10

Traceback (most recent call last):
  File "C:/Program Files/JetBrains/PyCharm 2021.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 23, in main
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 38, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 21, in __init__
    self.comb_position(x, cy, py, sy)
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 48, in comb_position
    ttx = np.hstack((ttx, tx[index]))
UnboundLocalError: local variable 'ttx' referenced before assignment
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 42, in main
    loss_result_dict = algorithm.update_a(data, opta)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 137, in update_a
    all_z = self.abottleneck(self.featurizer(all_x))
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\robustlearn\diversify\network\act_network.py", line 37, in forward
    x = self.conv2(self.conv1(x))
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\container.py", line 139, in forward
    input = module(input)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\conv.py", line 454, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Given groups=1, weight of size [16, 8, 1, 9], expected input[96, 5, 1, 8000] to have 8 channels, but got 5 channels instead
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 42, in main
    loss_result_dict = algorithm.update_a(data, opta)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 137, in update_a
    all_z = self.abottleneck(self.featurizer(all_x))
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\robustlearn\diversify\network\act_network.py", line 37, in forward
    x = self.conv2(self.conv1(x))
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\container.py", line 139, in forward
    input = module(input)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\conv.py", line 454, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Given groups=1, weight of size [16, 8, 1, 9], expected input[96, 5, 1, 8000] to have 8 channels, but got 5 channels instead
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 42, in main
    loss_result_dict = algorithm.update_a(data, opta)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 137, in update_a
    all_z = self.abottleneck(self.featurizer(all_x))
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\robustlearn\diversify\network\act_network.py", line 37, in forward
    x = self.conv2(self.conv1(x))
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\container.py", line 139, in forward
    input = module(input)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\conv.py", line 454, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Given groups=1, weight of size [16, 8, 1, 9], expected input[96, 5, 1, 8000] to have 8 channels, but got 5 channels instead
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Traceback (most recent call last):
  File "C:/Program Files/JetBrains/PyCharm 2021.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 42, in main
    loss_result_dict = algorithm.update_a(data, opta)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 137, in update_a
    all_z = self.abottleneck(self.featurizer(all_x))
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\robustlearn\diversify\network\act_network.py", line 37, in forward
    x = self.conv2(self.conv1(x))
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\container.py", line 139, in forward
    input = module(input)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\conv.py", line 454, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Given groups=1, weight of size [16, 8, 1, 9], expected input[96, 5, 1, 8000] to have 8 channels, but got 5 channels instead
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 42, in main
    loss_result_dict = algorithm.update_a(data, opta)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 137, in update_a
    all_z = self.abottleneck(self.featurizer(all_x))
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\robustlearn\diversify\network\act_network.py", line 38, in forward
    x = x.view(-1, self.in_features)
RuntimeError: shape '[-1, 1408]' is invalid for input of size 6125568
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Traceback (most recent call last):
  File "C:/Program Files/JetBrains/PyCharm 2021.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 42, in main
    loss_result_dict = algorithm.update_a(data, opta)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 137, in update_a
    all_z = self.abottleneck(self.featurizer(all_x))
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\robustlearn\diversify\network\act_network.py", line 38, in forward
    x = x.view(-1, self.in_features)
RuntimeError: shape '[-1, 1408]' is invalid for input of size 6125568
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Traceback (most recent call last):
  File "C:/Program Files/JetBrains/PyCharm 2021.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 42, in main
    loss_result_dict = algorithm.update_a(data, opta)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 139, in update_a
    classifier_loss = F.cross_entropy(all_preds, all_y)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\functional.py", line 3014, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
ValueError: Expected input batch_size (3072) to match target batch_size (96).
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 28, in main
    algorithm = algorithm_class(args).cuda()
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 22, in __init__
    self.featurizer = get_fea(args)
  File "E:\robustlearn\diversify\alg\modelopera.py", line 9, in get_fea
    net = act_network.ActNetwork(args.dataset)
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 41, in main
    for data in train_loader:
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 444, in __iter__
    return self._get_iterator()
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 390, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 1077, in __init__
    w.start()
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\process.py", line 112, in start
    self._popen = self._Popen(self)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 322, in _Popen
    return Popen(process_obj)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\popen_spawn_win32.py", line 89, in __init__
    reduction.dump(process_obj, to_child)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\reduction.py", line 60, in dump
    ForkingPickler(file, protocol).dump(obj)
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Traceback (most recent call last):
  File "C:/Program Files/JetBrains/PyCharm 2021.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 42, in main
    loss_result_dict = algorithm.update_a(data, opta)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 137, in update_a
    dt_z = self.featurizer(all_x)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\robustlearn\diversify\network\act_network.py", line 40, in forward
    x = x.view(-1, self.in_features)
RuntimeError: shape '[-1, 1408]' is invalid for input of size 6125568
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Traceback (most recent call last):
  File "C:/Program Files/JetBrains/PyCharm 2021.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 42, in main
    loss_result_dict = algorithm.update_a(data, opta)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 138, in update_a
    all_z = self.abottleneck(dt_z)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\robustlearn\diversify\network\common_network.py", line 19, in forward
    x = self.bottleneck(x)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (96x63808 and 1408x256)
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
0                3.3130905628    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.3015856743     2.4991805553     0.8024051785    
Counter({0: 530, 2: 83, 1: 83})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                2.7861430645     0.7419831753     3.5281262398     0.0660919540     0.0520231214     0.0000000000     17.4509017467   

========ROUND 1========
====Feature update====
epoch            class_loss      
0                2.9458580017    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8249621391     2.5379846096     0.2869774997    
Counter({0: 521, 1: 136, 2: 39})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                2.3627645969     0.0668853149     2.4296498299     0.0632183908     0.0809248555     0.0000000000     17.2881302834   

========ROUND 2========
====Feature update====
epoch            class_loss      
0                2.6899659634    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8518495560     2.4932115078     0.3586380482    
Counter({0: 411, 2: 187, 1: 98})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                2.0474698544     0.4816257060     2.5290956497     0.0948275862     0.0924855491     0.0000000000     17.8518800735   

========ROUND 3========
====Feature update====
epoch            class_loss      
0                3.4012386799    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.4823162556     2.8353583813     0.6469578743    
Counter({0: 435, 2: 146, 1: 115})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                2.2228631973     0.4687772989     2.6916403770     0.0747126437     0.0520231214     0.0000000000     20.3071401119   

========ROUND 4========
====Feature update====
epoch            class_loss      
0                2.3632209301    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.1749174595     2.7792551517     0.3956622183    
Counter({0: 696})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                2.3288922310     0.0017115142     2.3306038380     0.0704022989     0.0693641618     0.0000000000     18.7230093479   

========ROUND 5========
====Feature update====
epoch            class_loss      
0                2.6971263885    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7974767685     2.6576051712     0.1398716122    
Counter({1: 447, 0: 185, 2: 64})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                2.2717838287     0.2416297197     2.5134134293     0.0689655172     0.0751445087     0.0000000000     17.9545507431   

========ROUND 6========
====Feature update====
epoch            class_loss      
0                2.6454520226    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.2349057198     2.8103439808     0.4245617688    
Counter({0: 696})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                2.8991012573     0.0156826898     2.9147839546     0.0632183908     0.0809248555     0.0000000000     16.9138848782   

========ROUND 7========
====Feature update====
epoch            class_loss      
0                1.9995760918    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.1198866367     2.8098382950     0.3100483418    
Counter({0: 335, 2: 201, 1: 160})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                2.1607894897     0.7225624919     2.8833520412     0.0704022989     0.0693641618     0.0000000000     16.8303976059   

========ROUND 8========
====Feature update====
epoch            class_loss      
0                2.8125026226    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.3143236637     2.6906950474     0.6236286759    
Counter({2: 360, 1: 206, 0: 130})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3553045988     0.9873406887     2.3426451683     0.0617816092     0.0520231214     0.0000000000     17.8423528671   

========ROUND 9========
====Feature update====
epoch            class_loss      
0                3.1281845570    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8332870007     2.5239851475     0.3093018234    
Counter({0: 696})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.8169369698     0.0265424177     1.8434793949     0.0646551724     0.0867052023     0.0000000000     17.3880620003   

========ROUND 10========
====Feature update====
epoch            class_loss      
0                2.0092530251    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.9171538353     2.7905387878     0.1266150028    
Counter({2: 450, 0: 134, 1: 112})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                2.8914985657     0.3787777424     3.2702763081     0.0732758621     0.0635838150     0.0000000000     17.3826825619   

========ROUND 11========
====Feature update====
epoch            class_loss      
0                2.1794674397    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5893313885     2.3301613331     0.2591701150    
Counter({0: 696})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.4299074411     0.1041853949     1.5340927839     0.0560344828     0.1156069364     0.0000000000     17.3756673336   

========ROUND 12========
====Feature update====
epoch            class_loss      
0                3.1582736969    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7916052341     2.6305167675     0.1610883772    
Counter({2: 422, 0: 196, 1: 78})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                2.1892182827     0.3654843569     2.5547027588     0.0704022989     0.0693641618     0.0000000000     17.3087060452   

========ROUND 13========
====Feature update====
epoch            class_loss      
0                2.9499034882    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.0876224041     2.5858526230     0.5017698407    
Counter({0: 696})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.6491361856     0.0246381834     1.6737743616     0.0689655172     0.0520231214     0.0000000000     17.7127888203   

========ROUND 14========
====Feature update====
epoch            class_loss      
0                1.8373423815    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5740165710     2.4884402752     0.0855762661    
Counter({0: 325, 2: 218, 1: 153})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.4652153254     0.4643697739     1.9295850992     0.0660919540     0.0982658960     0.0000000000     17.0969305038   

========ROUND 15========
====Feature update====
epoch            class_loss      
0                2.3516728878    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.0796005726     2.4674794674     0.6121211648    
Counter({1: 696})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.5478254557     0.0654167905     1.6132422686     0.0617816092     0.0520231214     0.0000000000     17.2330713272   

========ROUND 16========
====Feature update====
epoch            class_loss      
0                2.9310750961    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7619431019     2.6073324680     0.1546106488    
Counter({0: 308, 2: 228, 1: 160})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.1957329512     0.6143106818     1.8100435734     0.0704022989     0.0693641618     0.0000000000     17.2089970112   

========ROUND 17========
====Feature update====
epoch            class_loss      
0                2.7553050518    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8904237747     2.4735972881     0.4168265164    
Counter({1: 696})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.9478582144     0.1365403533     2.0843985081     0.1135057471     0.0867052023     0.0000000000     17.3280110359   

========ROUND 18========
====Feature update====
epoch            class_loss      
0                2.6477661133    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6468508244     2.5573980808     0.0894527435    
Counter({2: 316, 1: 243, 0: 137})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.6798454523     0.7829028964     2.4627482891     0.0732758621     0.0809248555     0.0000000000     17.0272207260   

========ROUND 19========
====Feature update====
epoch            class_loss      
0                2.1506946087    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.9664170742     2.5644180775     0.4019989669    
Counter({2: 305, 0: 260, 1: 131})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6652894616     0.8279387951     1.4932281971     0.0675287356     0.1156069364     0.0000000000     17.0490419865   

========ROUND 20========
====Feature update====
epoch            class_loss      
0                1.9156398773    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8440918922     2.5286545753     0.3154373169    
Counter({2: 412, 0: 194, 1: 90})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.2238194942     0.6400828362     1.8639023304     0.0617816092     0.1156069364     0.0000000000     17.3305270672   

========ROUND 21========
====Feature update====
epoch            class_loss      
0                2.2488982677    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.9405236244     2.6221122742     0.3184114099    
Counter({2: 365, 1: 291, 0: 40})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.8589647412     0.9075772762     1.7665419579     0.0747126437     0.0520231214     0.0000000000     17.0907862186   

========ROUND 22========
====Feature update====
epoch            class_loss      
0                2.2417926788    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.7295439243     2.7395956516     0.9899483323    
Counter({1: 430, 2: 136, 0: 130})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5777224302     0.6592616439     1.2369840145     0.0660919540     0.0578034682     0.0000000000     17.2701876163   

========ROUND 23========
====Feature update====
epoch            class_loss      
0                1.4068474770    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.2028779984     2.7517483234     0.4511295855    
Counter({1: 259, 2: 228, 0: 209})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3204697669     1.1144360304     1.4349057674     0.0632183908     0.0809248555     0.0000000000     16.9794404507   

========ROUND 24========
====Feature update====
epoch            class_loss      
0                1.1615753174    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.0818321705     2.4728934765     0.6089386344    
Counter({1: 299, 2: 221, 0: 176})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7063876987     0.8786584735     1.5850461721     0.0761494253     0.0520231214     0.0000000000     17.4944660664   

========ROUND 25========
====Feature update====
epoch            class_loss      
0                1.4648175240    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.0928056240     2.5060718060     0.5867338777    
Counter({0: 696})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4687132835     0.0214226972     0.4901359677     0.0660919540     0.0578034682     0.0000000000     17.3215956688   

========ROUND 26========
====Feature update====
epoch            class_loss      
0                0.9206054807    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6595268250     2.5845673084     0.0749596059    
Counter({1: 312, 2: 196, 0: 188})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5746669769     1.3346010447     1.9092680216     0.0704022989     0.0693641618     0.0000000000     17.8476731777   

========ROUND 27========
====Feature update====
epoch            class_loss      
0                1.2857295275    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.9795069695     2.5179679394     0.4615390301    
Counter({1: 696})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4667241573     0.0531823747     0.5199065208     0.0660919540     0.0578034682     0.0000000000     17.4855136871   

========ROUND 28========
====Feature update====
epoch            class_loss      
0                0.4237364233    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4964308739     2.3718667030     0.1245641336    
Counter({1: 308, 2: 215, 0: 173})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2444312572     0.7920566201     1.0364878178     0.0617816092     0.0520231214     0.0000000000     17.6462614536   

========ROUND 29========
====Feature update====
epoch            class_loss      
0                1.3275979757    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.6658022404     2.9960243702     0.6697778702    
Counter({2: 510, 0: 114, 1: 72})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7942896485     0.8518567085     1.6461462975     0.0704022989     0.0693641618     0.0000000000     17.2040007114   

========ROUND 30========
====Feature update====
epoch            class_loss      
0                0.8360517621    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7557222843     2.4659173489     0.2898048759    
Counter({2: 276, 0: 222, 1: 198})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0611787848     0.8967679143     0.9579467177     0.0660919540     0.0578034682     0.0000000000     17.3984682560   

========ROUND 31========
====Feature update====
epoch            class_loss      
0                0.9855377674    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.1527705193     2.5825235844     0.5702469945    
Counter({1: 382, 0: 217, 2: 97})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2472719699     0.7585557103     1.0058276653     0.0761494253     0.0982658960     0.0000000000     17.1705029011   

========ROUND 32========
====Feature update====
epoch            class_loss      
0                1.2609413862    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.1912038326     2.6038966179     0.5873071551    
Counter({0: 374, 2: 207, 1: 115})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1135572419     0.8798997998     0.9934570193     0.0560344828     0.1156069364     0.0000000000     17.2136461735   

========ROUND 33========
====Feature update====
epoch            class_loss      
0                1.0545346737    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.2350087166     2.4910407066     0.7439679503    
Counter({2: 291, 0: 242, 1: 163})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2242075801     0.9502933621     1.1745009422     0.0761494253     0.0693641618     0.0000000000     16.9338467121   

========ROUND 34========
====Feature update====
epoch            class_loss      
0                0.8963146210    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.2893023491     2.6894235611     0.5998787880    
Counter({2: 273, 0: 238, 1: 185})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3485315144     1.0698459148     1.4183773994     0.0948275862     0.0404624277     0.0000000000     17.8020770550   

========ROUND 35========
====Feature update====
epoch            class_loss      
0                1.0322751999    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.2823877335     2.5717487335     0.7106389403    
Counter({2: 368, 0: 205, 1: 123})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2804805934     0.8906993270     1.1711798906     0.0617816092     0.0520231214     0.0000000000     17.7774622440   

========ROUND 36========
====Feature update====
epoch            class_loss      
0                1.1429098845    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.9977080822     2.6448318958     0.3528761566    
Counter({1: 312, 2: 256, 0: 128})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0618368052     1.0054961443     1.0673329830     0.1034482759     0.0462427746     0.0000000000     17.5215358734   

========ROUND 37========
====Feature update====
epoch            class_loss      
0                0.7544303536    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.1151185036     2.4869337082     0.6281847358    
Counter({1: 676, 2: 17, 0: 3})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3748634160     0.1480477005     0.5229111314     0.0632183908     0.0520231214     0.0000000000     17.1892962456   

========ROUND 38========
====Feature update====
epoch            class_loss      
0                0.6135335565    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6218054295     2.5750339031     0.0467714332    
Counter({1: 326, 0: 200, 2: 170})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2040631324     0.9585781097     1.1626412868     0.0704022989     0.0693641618     0.0000000000     17.4375793934   

========ROUND 39========
====Feature update====
epoch            class_loss      
0                0.9563093781    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.4827861786     2.8043518066     0.6784343123    
Counter({2: 296, 0: 211, 1: 189})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0537711717     0.7417464852     0.7955176830     0.0704022989     0.0693641618     0.0000000000     17.4233057499   

========ROUND 40========
====Feature update====
epoch            class_loss      
0                0.7374557853    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.0442538261     2.6131134033     0.4311405420    
Counter({0: 301, 1: 223, 2: 172})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0709588602     0.9681468010     1.0391056538     0.0718390805     0.0924855491     0.0000000000     17.2783200741   

========ROUND 41========
====Feature update====
epoch            class_loss      
0                0.5626063347    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.1606249809     2.7422788143     0.4183461666    
Counter({0: 293, 1: 241, 2: 162})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0744274482     0.9228553176     0.9972827435     0.0675287356     0.0635838150     0.0000000000     17.1772611141   

========ROUND 42========
====Feature update====
epoch            class_loss      
0                0.9643826485    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.9687561989     2.5628554821     0.4059006870    
Counter({0: 328, 1: 205, 2: 163})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0767359659     0.8498240113     0.9265599847     0.0704022989     0.0693641618     0.0000000000     17.2144515514   

========ROUND 43========
====Feature update====
epoch            class_loss      
0                0.9851897359    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.0270857811     2.5973815918     0.4297042191    
Counter({0: 285, 1: 241, 2: 170})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2527283728     0.9197404385     1.1724687815     0.0617816092     0.0520231214     0.0000000000     17.5037825108   

========ROUND 44========
====Feature update====
epoch            class_loss      
0                1.3704549074    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.3124253750     2.3495149612     0.9629103541    
Counter({0: 326, 2: 213, 1: 157})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0805541202     0.9419154525     1.0224695206     0.0617816092     0.0520231214     0.0000000000     17.4896500111   

========ROUND 45========
====Feature update====
epoch            class_loss      
0                1.1764899492    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.3731513023     2.5921709538     0.7809803486    
Counter({1: 307, 2: 285, 0: 104})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0516111553     1.0185009241     1.0701121092     0.0704022989     0.0693641618     0.0000000000     17.2330758572   

========ROUND 46========
====Feature update====
epoch            class_loss      
0                0.9666786790    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.2720816135     2.6170475483     0.6550340056    
Counter({0: 259, 1: 253, 2: 184})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2483484000     0.9418582916     1.1902066469     0.0704022989     0.0693641618     0.0000000000     17.1606647968   

========ROUND 47========
====Feature update====
epoch            class_loss      
0                0.7795228958    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.1572215557     2.5570962429     0.6001253128    
Counter({1: 361, 0: 183, 2: 152})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0257661808     0.6156931520     0.6414593458     0.0847701149     0.0635838150     0.0000000000     17.6336610317   

========ROUND 48========
====Feature update====
epoch            class_loss      
0                0.7868143916    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.5258681774     2.7126123905     0.8132558465    
Counter({0: 431, 1: 192, 2: 73})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2623126507     0.8855879307     1.1479005814     0.0660919540     0.0578034682     0.0000000000     17.5883827209   

========ROUND 49========
====Feature update====
epoch            class_loss      
0                0.6338911653    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.2249507904     2.5286748409     0.6962759495    
Counter({1: 330, 2: 211, 0: 155})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0527384430     1.0038384199     1.0565768480     0.0704022989     0.0693641618     0.0000000000     17.2836735249   

========ROUND 50========
====Feature update====
epoch            class_loss      
0                0.8635544181    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.2799639702     2.6867771149     0.5931869149    
Counter({2: 339, 1: 215, 0: 142})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1002151296     0.5986002088     0.6988153458     0.0704022989     0.0693641618     0.0000000000     17.3830025196   

========ROUND 51========
====Feature update====
epoch            class_loss      
0                0.7670245767    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.9712338448     2.5523838997     0.4188498259    
Counter({1: 455, 0: 154, 2: 87})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1597354561     0.7504411340     0.9101765752     0.0862068966     0.0578034682     0.0000000000     19.1440870762   

========ROUND 52========
====Feature update====
epoch            class_loss      
0                0.5460491180    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.9049251080     2.6191599369     0.2857652605    
Counter({0: 406, 2: 182, 1: 108})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0352401920     0.9633186460     0.9985588193     0.1063218391     0.0867052023     0.0000000000     17.8154017925   

========ROUND 53========
====Feature update====
epoch            class_loss      
0                1.0532213449    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.1331982613     2.5859653950     0.5472329259    
Counter({2: 423, 0: 249, 1: 24})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1664712727     0.7222120762     0.8886833191     0.0704022989     0.0693641618     0.0000000000     18.4117763042   

========ROUND 54========
====Feature update====
epoch            class_loss      
0                0.3439165056    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.0747416019     2.6481430531     0.4265985191    
Counter({0: 377, 2: 214, 1: 105})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0261424314     0.6860229373     0.7121653557     0.0689655172     0.0693641618     0.0000000000     16.4985892773   

========ROUND 55========
====Feature update====
epoch            class_loss      
0                0.5900186300    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8942942619     2.5605876446     0.3337066174    
Counter({2: 341, 1: 232, 0: 123})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1358992606     0.9499525428     1.0858517885     0.0790229885     0.0520231214     0.0000000000     16.9452917576   

========ROUND 56========
====Feature update====
epoch            class_loss      
0                1.0184359550    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.1257786751     2.5569860935     0.5687925816    
Counter({1: 298, 0: 242, 2: 156})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0255110729     0.9641934037     0.9897044897     0.0617816092     0.0520231214     0.0000000000     16.1556718349   

========ROUND 57========
====Feature update====
epoch            class_loss      
0                0.7957649231    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8187639713     2.3714718819     0.4472920001    
Counter({0: 520, 1: 124, 2: 52})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1335521787     0.5192955136     0.6528477073     0.0646551724     0.0809248555     0.0000000000     16.1297349930   

========ROUND 58========
====Feature update====
epoch            class_loss      
0                0.6552484035    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7079634666     2.4107511044     0.2972123921    
Counter({0: 279, 1: 235, 2: 182})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7023718953     0.6482924223     1.3506643772     0.0689655172     0.0693641618     0.0000000000     16.2896816730   

========ROUND 59========
====Feature update====
epoch            class_loss      
0                0.6672411561    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.1840333939     2.6420090199     0.5420243740    
Counter({1: 420, 0: 147, 2: 129})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0269418936     0.6335086226     0.6604505181     0.0617816092     0.0520231214     0.0000000000     16.2014682293   

========ROUND 60========
====Feature update====
epoch            class_loss      
0                0.6198294759    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.2599856853     2.7149269581     0.5450586677    
Counter({2: 369, 1: 179, 0: 148})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0035465274     0.9157949090     0.9193414450     0.0660919540     0.0520231214     0.0000000000     16.1629638672   

========ROUND 61========
====Feature update====
epoch            class_loss      
0                1.0308320522    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.2081103325     2.5692849159     0.6388255358    
Counter({2: 337, 1: 216, 0: 143})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2923176587     1.1766687632     1.4689863920     0.1048850575     0.0809248555     0.0000000000     16.0997951031   

========ROUND 62========
====Feature update====
epoch            class_loss      
0                0.5678915977    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8808963299     2.4454429150     0.4354534447    
Counter({1: 324, 2: 214, 0: 158})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0817615613     0.7070022225     0.7887637615     0.0660919540     0.0578034682     0.0000000000     16.4319493771   

========ROUND 63========
====Feature update====
epoch            class_loss      
0                0.6834893227    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.1377897263     2.5869140625     0.5508756638    
Counter({2: 321, 1: 229, 0: 146})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1054185629     0.9052087665     1.0106272697     0.0660919540     0.0578034682     0.0000000000     15.9954030514   

========ROUND 64========
====Feature update====
epoch            class_loss      
0                0.7947278023    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.1486132145     2.4377617836     0.7108513713    
Counter({1: 276, 0: 250, 2: 170})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0121002570     0.8792915344     0.8913918138     0.0905172414     0.0635838150     0.0000000000     16.4048588276   

========ROUND 65========
====Feature update====
epoch            class_loss      
0                0.5525949001    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.0896310806     2.5312430859     0.5583879352    
Counter({0: 300, 1: 240, 2: 156})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1960269958     0.8194634318     1.0154904127     0.0689655172     0.0578034682     0.0000000000     16.2159347534   

========ROUND 66========
====Feature update====
epoch            class_loss      
0                0.9663896561    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7929432392     2.4991180897     0.2938251793    
Counter({1: 375, 0: 255, 2: 66})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2722197175     0.7048683763     0.9770880938     0.0933908046     0.0693641618     0.0000000000     16.3309450150   

========ROUND 67========
====Feature update====
epoch            class_loss      
0                0.7074013352    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.9668092728     2.6254746914     0.3413344920    
Counter({0: 310, 1: 228, 2: 158})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5011625886     0.7232356071     1.2243981361     0.0704022989     0.0693641618     0.0000000000     16.0937185287   

========ROUND 68========
====Feature update====
epoch            class_loss      
0                0.6134828329    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.9681365490     2.4692327976     0.4989037812    
Counter({1: 350, 2: 218, 0: 128})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0528260618     0.6827792525     0.7356052995     0.0775862069     0.0520231214     0.0000000000     16.3878903389   

========ROUND 69========
====Feature update====
epoch            class_loss      
0                0.6462661624    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8736548424     2.4201035500     0.4535512924    
Counter({1: 255, 2: 244, 0: 197})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0734710619     1.1604434252     1.2339144945     0.0818965517     0.0578034682     0.0000000000     16.3558552265   

========ROUND 70========
====Feature update====
epoch            class_loss      
0                0.6004438996    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.0125782490     2.5446221828     0.4679560959    
Counter({1: 271, 0: 236, 2: 189})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0794794410     0.8440422416     0.9235216975     0.0747126437     0.0520231214     0.0000000000     16.2454259396   

========ROUND 71========
====Feature update====
epoch            class_loss      
0                1.0711740255    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.3836040497     2.7435455322     0.6400583982    
Counter({0: 241, 1: 241, 2: 214})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2424141020     0.7568672299     0.9992813468     0.0617816092     0.0520231214     0.0000000000     16.0046484470   

========ROUND 72========
====Feature update====
epoch            class_loss      
0                0.8867535591    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.1806309223     2.4710412025     0.7095896602    
Counter({0: 273, 1: 250, 2: 173})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0611103624     0.8413038254     0.9024142027     0.0732758621     0.0346820809     0.0000000000     16.2942209244   

========ROUND 73========
====Feature update====
epoch            class_loss      
0                0.5515571833    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.9803493023     2.4438822269     0.5364670157    
Counter({2: 260, 1: 250, 0: 186})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0244657304     0.9185351729     0.9430009127     0.0560344828     0.1156069364     0.0000000000     16.0533552170   

========ROUND 74========
====Feature update====
epoch            class_loss      
0                0.3962791860    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7947030067     2.4117236137     0.3829792738    
Counter({1: 323, 2: 205, 0: 168})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0659480169     0.8506458402     0.9165938497     0.0560344828     0.1156069364     0.0000000000     16.2933995724   

========ROUND 75========
====Feature update====
epoch            class_loss      
0                0.8001499176    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.1187057495     2.6104621887     0.5082436800    
Counter({2: 286, 0: 213, 1: 197})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2970598042     0.7711789608     1.0682387352     0.0747126437     0.0462427746     0.0000000000     16.1259655952   

========ROUND 76========
====Feature update====
epoch            class_loss      
0                0.7766081691    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.2083506584     2.6409955025     0.5673550367    
Counter({1: 266, 2: 224, 0: 206})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1861665398     0.7969518304     0.9831183553     0.0689655172     0.0520231214     0.0000000000     16.2888395786   

========ROUND 77========
====Feature update====
epoch            class_loss      
0                0.4164619446    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.2410669327     2.6868772507     0.5541896224    
Counter({1: 412, 2: 171, 0: 113})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0533184521     0.5356218815     0.5889403224     0.0718390805     0.0693641618     0.0000000000     16.1597898006   

========ROUND 78========
====Feature update====
epoch            class_loss      
0                0.7594096661    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.1163218021     2.6497154236     0.4666064084    
Counter({1: 298, 0: 255, 2: 143})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0552421696     0.8171203136     0.8723624945     0.0747126437     0.0635838150     0.0000000000     16.2506661415   

========ROUND 79========
====Feature update====
epoch            class_loss      
0                0.7890367508    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.1707012653     2.6106271744     0.5600740910    
Counter({1: 275, 2: 239, 0: 182})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0302075539     0.9135480523     0.9437556267     0.0560344828     0.1156069364     0.0000000000     16.3911876678   

========ROUND 80========
====Feature update====
epoch            class_loss      
0                0.7057315707    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.2844355106     2.8557150364     0.4287204444    
Counter({2: 380, 0: 178, 1: 138})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0492107533     0.9479033947     0.9971141219     0.0718390805     0.0809248555     0.0000000000     16.1609227657   

========ROUND 81========
====Feature update====
epoch            class_loss      
0                1.1927912235    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.1165084839     2.4961979389     0.6203105450    
Counter({1: 696})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0516070016     0.1289411783     0.1805481762     0.0747126437     0.0520231214     0.0000000000     16.1375393867   

========ROUND 82========
====Feature update====
epoch            class_loss      
0                0.1165843681    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8302175999     2.7129042149     0.1173134744    
Counter({0: 336, 1: 210, 2: 150})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0023192503     0.8101685643     0.8124878407     0.0775862069     0.0520231214     0.0000000000     16.2854690552   

========ROUND 83========
====Feature update====
epoch            class_loss      
0                0.7502564788    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.0341429710     2.4722988605     0.5618441701    
Counter({0: 324, 2: 188, 1: 184})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0393220261     0.8685293198     0.9078513384     0.0905172414     0.0578034682     0.0000000000     16.2069568634   

========ROUND 84========
====Feature update====
epoch            class_loss      
0                0.8527165055    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.9091246128     2.5794794559     0.3296450675    
Counter({2: 413, 0: 213, 1: 70})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0289318841     0.7695260048     0.7984578609     0.0747126437     0.0520231214     0.0000000000     16.1305279732   

========ROUND 85========
====Feature update====
epoch            class_loss      
0                0.7982754111    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8798139095     2.3664650917     0.5133488178    
Counter({0: 344, 2: 178, 1: 174})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0122386059     0.8268058896     0.8390445113     0.0660919540     0.0578034682     0.0000000000     16.1666898727   

========ROUND 86========
====Feature update====
epoch            class_loss      
0                0.6453142762    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.0593028069     2.5249104500     0.5343922377    
Counter({2: 338, 0: 201, 1: 157})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0116946446     0.7982024550     0.8098971248     0.0660919540     0.0578034682     0.0000000000     16.6357431412   

========ROUND 87========
====Feature update====
epoch            class_loss      
0                0.6076838374    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7914686203     2.3809792995     0.4104892015    
Counter({0: 291, 1: 213, 2: 192})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2491940111     1.0379604101     1.2871544361     0.0660919540     0.0982658960     0.0000000000     16.2850608826   

========ROUND 88========
====Feature update====
epoch            class_loss      
0                0.3522020280    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.0938491821     2.5344824791     0.5593668222    
Counter({0: 285, 1: 254, 2: 157})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0621951558     0.9737706184     1.0359658003     0.0761494253     0.0693641618     0.0000000000     16.7589817047   

========ROUND 89========
====Feature update====
epoch            class_loss      
0                0.5603527427    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.0579888821     2.6044299603     0.4535588920    
Counter({0: 443, 1: 173, 2: 80})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0211556349     0.6138639450     0.6350196004     0.0660919540     0.0982658960     0.0000000000     18.4034082890   

========ROUND 90========
====Feature update====
epoch            class_loss      
0                0.5231500268    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.2324020863     2.6453731060     0.5870289207    
Counter({0: 380, 1: 183, 2: 133})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0408275910     1.1060122252     1.1468398571     0.0675287356     0.0693641618     0.0000000000     16.7724127769   

========ROUND 91========
====Feature update====
epoch            class_loss      
0                0.4252113402    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.9441316128     2.6816186905     0.2625129223    
Counter({2: 298, 0: 227, 1: 171})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1292593628     0.9551351666     1.0843945742     0.0704022989     0.0867052023     0.0000000000     16.3364505768   

========ROUND 92========
====Feature update====
epoch            class_loss      
0                0.9668870568    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.2236855030     2.5989353657     0.6247501969    
Counter({1: 286, 2: 214, 0: 196})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0046602827     0.8714486957     0.8761090040     0.1795977011     0.0867052023     0.0000000000     16.4364645481   

========ROUND 93========
====Feature update====
epoch            class_loss      
0                0.8932102323    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.2438156605     2.6680486202     0.5757670403    
Counter({0: 281, 2: 215, 1: 200})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0353874378     1.1245902777     1.1599776745     0.0617816092     0.0346820809     0.0000000000     16.6735184193   

========ROUND 94========
====Feature update====
epoch            class_loss      
0                0.8138289452    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.2665197849     2.5541174412     0.7124022841    
Counter({1: 272, 0: 245, 2: 179})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0436117761     0.9018624425     0.9454742074     0.0718390805     0.0578034682     0.0000000000     17.7230315208   

========ROUND 95========
====Feature update====
epoch            class_loss      
0                0.9461986423    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.3193416595     2.5640256405     0.7553159595    
Counter({0: 581, 1: 87, 2: 28})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0281879921     0.3561381102     0.3843261003     0.0646551724     0.0867052023     0.0000000000     16.2265639305   

========ROUND 96========
====Feature update====
epoch            class_loss      
0                0.3558447659    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.1449654102     2.8805160522     0.2644494176    
Counter({0: 272, 2: 264, 1: 160})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0262887105     0.8044040799     0.8306927681     0.0847701149     0.0809248555     0.0000000000     16.2699551582   

========ROUND 97========
====Feature update====
epoch            class_loss      
0                0.6232748032    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8851914406     2.4196162224     0.4655752182    
Counter({0: 426, 1: 177, 2: 93})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0239850823     0.6142002344     0.6381853223     0.1005747126     0.0635838150     0.0000000000     16.6184091568   

========ROUND 98========
====Feature update====
epoch            class_loss      
0                0.4744828045    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.3498170376     2.7830150127     0.5668020844    
Counter({1: 284, 2: 265, 0: 147})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0247785896     0.8143966794     0.8391752839     0.0732758621     0.0809248555     0.0000000000     16.4231314659   

========ROUND 99========
====Feature update====
epoch            class_loss      
0                0.8704811931    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.0946233273     2.4730312824     0.6215921044    
Counter({0: 283, 1: 223, 2: 190})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0106369751     1.1652591228     1.1758960485     0.1149425287     0.0462427746     0.0000000000     16.3852572441   

========ROUND 100========
====Feature update====
epoch            class_loss      
0                1.0187486410    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.0163619518     2.4495730400     0.5667888522    
Counter({0: 287, 1: 227, 2: 182})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1223043203     1.0877313614     1.2100356817     0.0704022989     0.0693641618     0.0000000000     16.6440203190   

========ROUND 101========
====Feature update====
epoch            class_loss      
0                0.7508085370    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.9559521675     2.5437996387     0.4121524096    
Counter({1: 266, 0: 254, 2: 176})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0807005167     1.0694074631     1.1501079798     0.0704022989     0.0693641618     0.0000000000     16.5978119373   

========ROUND 102========
====Feature update====
epoch            class_loss      
0                0.8227555752    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.2351150513     2.5880420208     0.6470729709    
Counter({2: 280, 0: 236, 1: 180})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0055128778     0.7499956489     0.7555085421     0.0617816092     0.0520231214     0.0000000000     16.3824498653   

========ROUND 103========
====Feature update====
epoch            class_loss      
0                0.5958384871    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.9589178562     2.4041826725     0.5547352433    
Counter({0: 274, 2: 233, 1: 189})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0325773507     0.7915194631     0.8240967989     0.0675287356     0.0520231214     0.0000000000     16.4039988518   

========ROUND 104========
====Feature update====
epoch            class_loss      
0                0.7493906617    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.0714676380     2.6382029057     0.4332647026    
Counter({0: 301, 1: 279, 2: 116})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0054652733     1.1983242035     1.2037894726     0.0617816092     0.0520231214     0.0000000000     18.2437968254   

========ROUND 105========
====Feature update====
epoch            class_loss      
0                0.5141237378    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.0637154579     2.6841681004     0.3795473576    
Counter({0: 270, 1: 250, 2: 176})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0277663544     0.9810061455     1.0087724924     0.0704022989     0.0693641618     0.0000000000     16.3565800190   

========ROUND 106========
====Feature update====
epoch            class_loss      
0                0.7494249344    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.1459507942     2.6006472111     0.5453036427    
Counter({1: 322, 0: 209, 2: 165})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0784426555     0.8685690761     0.9470117092     0.0617816092     0.0520231214     0.0000000000     16.1176450253   

========ROUND 107========
====Feature update====
epoch            class_loss      
0                0.5286518931    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.9099316597     2.6973037720     0.2126278430    
Counter({1: 271, 0: 252, 2: 173})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0762879476     1.0124206543     1.0887086391     0.0689655172     0.0635838150     0.0000000000     16.9084434509   

========ROUND 108========
====Feature update====
epoch            class_loss      
0                0.4472086132    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.1038999557     2.5590009689     0.5448990464    
Counter({1: 477, 2: 149, 0: 70})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0448479690     1.0032011271     1.0480490923     0.0704022989     0.0693641618     0.0000000000     16.3190331459   

========ROUND 109========
====Feature update====
epoch            class_loss      
0                0.9610860944    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.1764037609     2.4805185795     0.6958852410    
Counter({1: 306, 2: 199, 0: 191})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0152814053     1.0009380579     1.0162194967     0.0617816092     0.0520231214     0.0000000000     18.1924049854   

========ROUND 110========
====Feature update====
epoch            class_loss      
0                0.8626121879    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.0911731720     2.5296089649     0.5615641475    
Counter({2: 291, 1: 261, 0: 144})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0140671590     0.6213043332     0.6353715062     0.0847701149     0.0635838150     0.0000000000     16.6131627560   

========ROUND 111========
====Feature update====
epoch            class_loss      
0                0.5218293071    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7968604565     2.3757050037     0.4211554825    
Counter({2: 413, 1: 157, 0: 126})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6872718930     0.6781534553     1.3654253483     0.1106321839     0.0520231214     0.0000000000     16.6398618221   

========ROUND 112========
====Feature update====
epoch            class_loss      
0                0.4783660471    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.2871425152     2.5573687553     0.7297737598    
Counter({2: 331, 1: 213, 0: 152})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5021659732     0.7066866755     1.2088526487     0.0704022989     0.0693641618     0.0000000000     16.5108025074   

========ROUND 113========
====Feature update====
epoch            class_loss      
0                0.6721487641    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.9926426411     2.6902387142     0.3024039567    
Counter({1: 317, 2: 231, 0: 148})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1110607386     0.6313142180     0.7423749566     0.0704022989     0.0693641618     0.0000000000     16.9529769421   

========ROUND 114========
====Feature update====
epoch            class_loss      
0                0.9166764617    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.2470037937     2.5821957588     0.6648079753    
Counter({1: 284, 0: 237, 2: 175})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0539840125     0.8292183876     0.8832023740     0.1307471264     0.0578034682     0.0000000000     16.3818213940   

========ROUND 115========
====Feature update====
epoch            class_loss      
0                0.6848674417    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.2460184097     2.5173904896     0.7286279798    
Counter({0: 280, 1: 256, 2: 160})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0163448770     0.7744240761     0.7907689810     0.0761494253     0.0693641618     0.0000000000     16.7402882576   

========ROUND 116========
====Feature update====
epoch            class_loss      
0                0.7243743539    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.2794063091     2.6385531425     0.6408531070    
Counter({0: 390, 2: 242, 1: 64})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0149496375     0.8764368892     0.8913865089     0.0704022989     0.0635838150     0.0000000000     16.4058246613   

========ROUND 117========
====Feature update====
epoch            class_loss      
0                0.9916916490    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8213124275     2.4077107906     0.4136017263    
Counter({0: 320, 1: 221, 2: 155})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0026479729     0.9879549146     0.9906029105     0.0689655172     0.0693641618     0.0000000000     17.0125041008   

========ROUND 118========
====Feature update====
epoch            class_loss      
0                0.6280871034    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7978618145     2.4497110844     0.3481506407    
Counter({2: 379, 1: 242, 0: 75})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0296539422     0.8120494485     0.8417034149     0.0905172414     0.0635838150     0.0000000000     16.3783471584   

========ROUND 119========
====Feature update====
epoch            class_loss      
0                0.6116847396    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.9955022335     2.5575568676     0.4379453361    
Counter({2: 349, 1: 220, 0: 127})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1509636194     1.0259326696     1.1768963337     0.0617816092     0.0520231214     0.0000000000     16.6938190460   
Target acc: 0.0000
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Traceback (most recent call last):
  File "C:/Program Files/JetBrains/PyCharm 2021.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 42, in main
    loss_result_dict = algorithm.update_a(data, opta)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 137, in update_a
    dt_z = self.featurizer(all_x)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\robustlearn\diversify\network\act_network.py", line 39, in forward
    x = self.conv2(self.conv1(x))
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\container.py", line 139, in forward
    input = module(input)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\batchnorm.py", line 179, in forward
    self.eps,
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\functional.py", line 2439, in batch_norm
    input, weight, bias, running_mean, running_var, training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: running_mean should contain 16 elements not 32
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Traceback (most recent call last):
  File "C:/Program Files/JetBrains/PyCharm 2021.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 42, in main
    loss_result_dict = algorithm.update_a(data, opta)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 137, in update_a
    dt_z = self.featurizer(all_x)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\robustlearn\diversify\network\act_network.py", line 39, in forward
    x = self.conv2(self.conv1(x))
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\container.py", line 139, in forward
    input = module(input)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\pooling.py", line 164, in forward
    return_indices=self.return_indices)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\_jit_internal.py", line 423, in fn
    return if_false(*args, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\functional.py", line 782, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (16x1x7992). Calculated output size: (16x0x3995). Output size is too small
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 42, in main
    loss_result_dict = algorithm.update_a(data, opta)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 137, in update_a
    dt_z = self.featurizer(all_x)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\robustlearn\diversify\network\act_network.py", line 40, in forward
    x = x.view(-1, int(x.shape[3]) * int(x.shape[1]))
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
0                3.4396059513    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.5351734161     2.6884157658     0.8467576504    
Counter({0: 696})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                2.8428728580     0.0027891553     2.8456621170     0.0747126437     0.0520231214     0.0000000000     15.8539443016   

========ROUND 1========
====Feature update====
epoch            class_loss      
0                2.8029184341    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5522000790     2.3320147991     0.2201853544    
Counter({0: 393, 2: 192, 1: 111})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                2.4277417660     0.4280615151     2.8558032513     0.1135057471     0.1156069364     0.0000000000     16.6527872086   

========ROUND 2========
====Feature update====
epoch            class_loss      
0                3.5705363750    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7997508049     2.5264737606     0.2732770741    
Counter({0: 383, 2: 179, 1: 134})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                2.8775327206     0.5100235939     3.3875563145     0.0704022989     0.0693641618     0.0000000000     15.6889731884   

========ROUND 3========
====Feature update====
epoch            class_loss      
0                3.4415018559    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5261814594     2.4302308559     0.0959506556    
Counter({1: 696})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                2.3374726772     0.0070151971     2.3444879055     0.0660919540     0.0520231214     0.0000000000     15.9964358807   

========ROUND 4========
====Feature update====
epoch            class_loss      
0                2.9547507763    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
Traceback (most recent call last):
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\popen_spawn_win32.py", line 89, in __init__
    reduction.dump(process_obj, to_child)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\reduction.py", line 60, in dump
    ForkingPickler(file, protocol).dump(obj)
BrokenPipeError: [Errno 32] Broken pipe

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 51, in main
    for data in train_loader:
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 444, in __iter__
    return self._get_iterator()
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 390, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 1077, in __init__
    w.start()
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\process.py", line 112, in start
    self._popen = self._Popen(self)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 322, in _Popen
    return Popen(process_obj)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\popen_spawn_win32.py", line 89, in __init__
    reduction.dump(process_obj, to_child)
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 25, in main
    best_valid_acc, target_acc = 0, 0
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 25, in main
    best_valid_acc, target_acc = 0, 0
KeyboardInterrupt
Traceback (most recent call last):
  File "C:/Program Files/JetBrains/PyCharm 2021.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "E:\robustlearn\diversify\train.py", line 98, in <module>
    args = get_args()
  File "E:\robustlearn\diversify\utils\util.py", line 151, in get_args
    args = act_param_init(args)
  File "E:\robustlearn\diversify\utils\util.py", line 97, in act_param_init
    args.dataset][1], tmp[args.dataset][0], tmp[args.dataset][2]
KeyError: 'dsads'
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:./data/
dataset:emg
data_dir:./data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 25, in main
    best_valid_acc, target_acc = 0, 0
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 25, in main
    best_valid_acc, target_acc = 0, 0
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 23, in main
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 39, in get_act_dataloader
    if i in args.test_envs:
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 23, in main
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 47, in get_act_dataloader
    tdata = combindataset(args, source_datasetlist)
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 23, in main
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 59, in get_act_dataloader
    return train_loader, train_loader_noshuffle, valid_loader, target_loader, tr, val, targetdata
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:./data/
dataset:emg
data_dir:./data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 23, in main
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 56, in get_act_dataloader
    train_loader, train_loader_noshuffle, valid_loader, target_loader = get_dataloader(
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:./data/
dataset:emg
data_dir:./data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 23, in main
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 46, in get_act_dataloader
    tdata = combindataset(args, source_datasetlist)
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:./data/
dataset:emg
data_dir:./data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 23, in main
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 37, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 18, in __init__
    x, cy, py, sy = loaddata_from_numpy(self.dataset, self.task, root_dir)
  File "E:\robustlearn\diversify\datautil\actdata\util.py", line 23, in loaddata_from_numpy
    return x, cy, py, sy
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:./data/
dataset:emg
data_dir:./data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 23, in main
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 56, in get_act_dataloader
    train_loader, train_loader_noshuffle, valid_loader, target_loader = get_dataloader(
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:./data/
dataset:emg
data_dir:./data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 23, in main
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 37, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 19, in __init__
    self.people_group = people_group
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 23, in main
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 40, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 19, in __init__
    self.people_group = people_group
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
0                3.4160878658    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.7852163315     2.9873478413     0.7978683710    
Counter({2: 737})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                2.9997637272     0.0062667886     3.0060305595     0.0732700136     0.0380434783     0.0476190476     38.8812785149   

========ROUND 1========
====Feature update====
epoch            class_loss      
0                3.7704036236    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.3374481201     2.5193231106     0.8181250691    
Counter({1: 372, 0: 229, 2: 136})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                2.3881452084     0.4069234431     2.7950687408     0.1099050204     0.0815217391     0.0779220779     38.6429655552   

========ROUND 2========
====Feature update====
epoch            class_loss      
0                3.2096934319    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.9643735886     2.6368479729     0.3275254965    
Counter({0: 349, 1: 268, 2: 120})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Traceback (most recent call last):
  File "C:/Program Files/JetBrains/PyCharm 2021.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 42, in main
    loss_result_dict = algorithm.update_a(data, opta)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 137, in update_a
    dt_z = self.featurizer(all_x)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\robustlearn\diversify\network\act_network.py", line 37, in forward
    x = self.conv2(self.conv1(x))
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\container.py", line 139, in forward
    input = module(input)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\conv.py", line 454, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Given groups=1, weight of size [16, 8, 1, 9], expected input[96, 5, 1, 8000] to have 8 channels, but got 5 channels instead
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 42, in main
    loss_result_dict = algorithm.update_a(data, opta)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 138, in update_a
    all_z = self.abottleneck(dt_z)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\robustlearn\diversify\network\common_network.py", line 19, in forward
    x = self.bottleneck(x)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (96x63808 and 1994x256)
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 42, in main
    loss_result_dict = algorithm.update_a(data, opta)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 137, in update_a
    dt_z = self.featurizer(all_x)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\robustlearn\diversify\network\act_network.py", line 39, in forward
    x = self.conv2(self.conv1(x))
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\container.py", line 139, in forward
    input = module(input)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\batchnorm.py", line 179, in forward
    self.eps,
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\functional.py", line 2439, in batch_norm
    input, weight, bias, running_mean, running_var, training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: running_mean should contain 32 elements not 16
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Traceback (most recent call last):
  File "C:/Program Files/JetBrains/PyCharm 2021.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 42, in main
    loss_result_dict = algorithm.update_a(data, opta)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 138, in update_a
    all_z = self.abottleneck(dt_z)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\robustlearn\diversify\network\common_network.py", line 19, in forward
    x = self.bottleneck(x)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (96x63808 and 3968x256)
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Traceback (most recent call last):
  File "C:/Program Files/JetBrains/PyCharm 2021.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 42, in main
    loss_result_dict = algorithm.update_a(data, opta)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 138, in update_a
    all_z = self.abottleneck(dt_z)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\robustlearn\diversify\network\common_network.py", line 19, in forward
    x = self.bottleneck(x)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (96x63808 and 3968x256)
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 42, in main
    loss_result_dict = algorithm.update_a(data, opta)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 138, in update_a
    all_z = self.abottleneck(dt_z)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\robustlearn\diversify\network\common_network.py", line 19, in forward
    x = self.bottleneck(x)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (96x7936 and 3968x256)
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
0                3.2925546169    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.3870692253     2.5954999924     0.7915692925    
Counter({2: 351, 0: 221, 1: 165})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                3.0245764256     0.4305031300     3.4550795555     0.0732700136     0.0380434783     0.0476190476     16.4760973454   

========ROUND 1========
====Feature update====
epoch            class_loss      
0                3.4972357750    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8801927567     2.6417415142     0.2384512573    
Counter({2: 387, 1: 219, 0: 131})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 83, in main
    acc = modelopera.accuracy(algorithm, target_loader, None)
  File "E:\robustlearn\diversify\alg\modelopera.py", line 20, in accuracy
    for data in loader:
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 444, in __iter__
    return self._get_iterator()
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 390, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 1077, in __init__
    w.start()
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\process.py", line 112, in start
    self._popen = self._Popen(self)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 322, in _Popen
    return Popen(process_obj)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\popen_spawn_win32.py", line 89, in __init__
    reduction.dump(process_obj, to_child)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\reduction.py", line 60, in dump
    ForkingPickler(file, protocol).dump(obj)
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
0                3.4205374718    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.7051997185     2.9245183468     0.7806812525    
Counter({1: 403, 0: 190, 2: 144})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                3.0198945999     0.2079900503     3.2278847694     0.0732700136     0.0380434783     0.0476190476     15.6995141506   

========ROUND 1========
====Feature update====
epoch            class_loss      
0                2.9889323711    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.0624117851     2.7364540100     0.3259578049    
Counter({1: 400, 0: 210, 2: 127})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                2.7624993324     0.2781005800     3.0405998230     0.0624151967     0.0652173913     0.0606060606     15.6441185474   

========ROUND 2========
====Feature update====
epoch            class_loss      
0                2.8906593323    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.9210221767     2.8165986538     0.1044234186    
Counter({1: 273, 0: 261, 2: 203})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                2.7394807339     0.1987025738     2.9381833076     0.0651289009     0.0652173913     0.0519480519     15.8886110783   

========ROUND 3========
====Feature update====
epoch            class_loss      
0                2.7785370350    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.1162743568     2.7388229370     0.3774514496    
Counter({1: 737})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                2.3166232109     0.0085573681     2.3251805305     0.0583446404     0.0489130435     0.0865800866     15.7844111919   

========ROUND 4========
====Feature update====
epoch            class_loss      
0                2.9030685425    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.4440181255     2.7590157986     0.6850023866    
Counter({0: 347, 2: 229, 1: 161})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                2.5001621246     0.9497269988     3.4498891830     0.0583446404     0.0489130435     0.0865800866     15.7469789982   

========ROUND 5========
====Feature update====
epoch            class_loss      
0                3.2435185909    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.2363429070     2.7396368980     0.4967059791    
Counter({1: 737})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
Traceback (most recent call last):
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\popen_spawn_win32.py", line 89, in __init__
    reduction.dump(process_obj, to_child)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\reduction.py", line 60, in dump
    ForkingPickler(file, protocol).dump(obj)
BrokenPipeError: [Errno 32] Broken pipe

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 70, in main
    for data in train_loader:
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 444, in __iter__
    return self._get_iterator()
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 390, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 1077, in __init__
    w.start()
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\process.py", line 112, in start
    self._popen = self._Popen(self)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 322, in _Popen
    return Popen(process_obj)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\popen_spawn_win32.py", line 89, in __init__
    reduction.dump(process_obj, to_child)
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
0                3.4205374718    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
0                4.1667776108    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 52, in main
    loss_result_dict = algorithm.update_d(data, optd)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 50, in update_d
    disc_out1 = self.ddiscriminator(disc_in1)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\robustlearn\diversify\network\Adver_network.py", line 39, in forward
    return self.layers(x)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\container.py", line 139, in forward
    input = module(input)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
TypeError: linear(): argument 'input' (position 1) must be Tensor, not tuple
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
0                4.1667776108    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 52, in main
    loss_result_dict = algorithm.update_d(data, optd)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 50, in update_d
    disc_out1 = self.ddiscriminator(disc_in1)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\robustlearn\diversify\network\Adver_network.py", line 39, in forward
    return self.layers(x)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\container.py", line 139, in forward
    input = module(input)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
TypeError: linear(): argument 'input' (position 1) must be Tensor, not tuple
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
0                4.1667776108    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 52, in main
    loss_result_dict = algorithm.update_d(data, optd)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 50, in update_d
    disc_out1 = self.ddiscriminator(disc_in1)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\robustlearn\diversify\network\Adver_network.py", line 39, in forward
    return self.layers(x)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\container.py", line 139, in forward
    input = module(input)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
TypeError: linear(): argument 'input' (position 1) must be Tensor, not tuple
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
0                3.4205374718    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.7051997185     2.9245183468     0.7806812525    
Counter({1: 403, 0: 190, 2: 144})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                3.0198945999     0.2079900503     3.2278847694     0.0732700136     0.0380434783     0.0476190476     15.7892408371   

========ROUND 1========
====Feature update====
epoch            class_loss      
0                2.9889323711    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
0                3.4205374718    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Traceback (most recent call last):
  File "C:/Program Files/JetBrains/PyCharm 2021.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 42, in main
    loss_result_dict = algorithm.update_a(data, opta)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 137, in update_a
    dt_z = self.featurizer(all_x)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\robustlearn\diversify\network\act_network.py", line 42, in forward
    x = self.lstm(x)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\rnn.py", line 767, in forward
    self.check_forward_args(input, hx, batch_sizes)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\rnn.py", line 692, in check_forward_args
    self.check_input(input, batch_sizes)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\rnn.py", line 207, in check_input
    self.input_size, input.size(-1)))
RuntimeError: input.size(-1) must be equal to input_size. Expected 4096, got 3968
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 25, in main
    best_valid_acc, target_acc = 0, 0
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Traceback (most recent call last):
  File "C:/Program Files/JetBrains/PyCharm 2021.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 42, in main
    loss_result_dict = algorithm.update_a(data, opta)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 137, in update_a
    dt_z = self.featurizer(all_x)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\robustlearn\diversify\network\act_network.py", line 44, in forward
    x = self.lstm(self.conv2(self.conv1(x)))
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\container.py", line 139, in forward
    input = module(input)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\rnn.py", line 767, in forward
    self.check_forward_args(input, hx, batch_sizes)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\rnn.py", line 692, in check_forward_args
    self.check_input(input, batch_sizes)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\rnn.py", line 203, in check_input
    expected_input_dim, input.dim()))
RuntimeError: input must have 3 dimensions, got 5
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 25, in main
    best_valid_acc, target_acc = 0, 0
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Traceback (most recent call last):
  File "C:/Program Files/JetBrains/PyCharm 2021.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 42, in main
    loss_result_dict = algorithm.update_a(data, opta)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 137, in update_a
    dt_z = self.featurizer(all_x)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\robustlearn\diversify\network\act_network.py", line 46, in forward
    x = self.lstm(x)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\container.py", line 139, in forward
    input = module(input)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\functional.py", line 1457, in relu
    result = torch.relu(input)
TypeError: relu(): argument 'input' (position 1) must be Tensor, not tuple
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 42, in main
    loss_result_dict = algorithm.update_a(data, opta)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 138, in update_a
    all_z = self.abottleneck(dt_z)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\robustlearn\diversify\network\common_network.py", line 19, in forward
    x = self.bottleneck(x)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (96x3968 and 1984x256)
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Traceback (most recent call last):
  File "C:/Program Files/JetBrains/PyCharm 2021.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 42, in main
    loss_result_dict = algorithm.update_a(data, opta)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 138, in update_a
    all_z = self.abottleneck(dt_z)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\robustlearn\diversify\network\common_network.py", line 19, in forward
    x = self.bottleneck(x)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (96x3968 and 1984x256)
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Traceback (most recent call last):
  File "C:/Program Files/JetBrains/PyCharm 2021.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 42, in main
    loss_result_dict = algorithm.update_a(data, opta)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 138, in update_a
    all_z = self.abottleneck(dt_z)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\robustlearn\diversify\network\common_network.py", line 19, in forward
    x = self.bottleneck(x)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (96x3968 and 1984x256)
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
0                2.9045193195    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7757287025     2.7712981701     0.0044306065    
Counter({0: 501, 1: 163, 2: 73})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                2.7787277699     0.2734543979     3.0521821976     0.0732700136     0.0380434783     0.0476190476     39.5559234619   

========ROUND 1========
====Feature update====
epoch            class_loss      
0                3.6254620552    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.7397046089     2.8632774353     0.8764270544    
Counter({2: 360, 1: 214, 0: 163})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                2.7785341740     0.3434507847     3.1219849586     0.0732700136     0.0380434783     0.0476190476     39.4115290642   

========ROUND 2========
====Feature update====
epoch            class_loss      
0                3.6733098030    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.9100666046     2.9030909538     1.0069755316    
Counter({0: 372, 1: 201, 2: 164})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                2.7762677670     1.0931087732     3.8693766594     0.0732700136     0.0380434783     0.0476190476     40.3801369667   

========ROUND 3========
====Feature update====
epoch            class_loss      
0                3.8579354286    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.8463859558     2.7779479027     1.0684380531    
Counter({0: 426, 2: 179, 1: 132})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                2.7674942017     0.4887934923     3.2562875748     0.0732700136     0.0380434783     0.0476190476     41.0467622280   

========ROUND 4========
====Feature update====
epoch            class_loss      
0                3.6738936901    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.7237834930     2.8977267742     0.8260565996    
Counter({1: 434, 2: 172, 0: 131})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                2.7782390118     0.5153111815     3.2935502529     0.0732700136     0.0380434783     0.0476190476     40.7330815792   

========ROUND 5========
====Feature update====
epoch            class_loss      
0                3.6093358994    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                3.7974774837     2.8134970665     0.9839803576    
Counter({1: 457, 2: 188, 0: 92})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                2.7667477131     0.3354687989     3.1022164822     0.0732700136     0.0380434783     0.0476190476     39.3325054646   

========ROUND 6========
====Feature update====
epoch            class_loss      
Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 41, in main
    for data in train_loader:
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 444, in __iter__
    return self._get_iterator()
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 390, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 1077, in __init__
    w.start()
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\process.py", line 112, in start
    self._popen = self._Popen(self)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 322, in _Popen
    return Popen(process_obj)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\popen_spawn_win32.py", line 89, in __init__
    reduction.dump(process_obj, to_child)
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10

Traceback (most recent call last):
  File "C:/Program Files/JetBrains/PyCharm 2021.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 23, in main
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 43, in get_act_dataloader
    args, "target", args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 21, in __init__
    self.comb_position(x, cy, py, sy)
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 40, in comb_position
    tx, tcy, tsy = x[index], cy[index], sy[index]
IndexError: index 1800 is out of bounds for axis 0 with size 231
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 23, in main
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 40, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 18, in __init__
    x, cy, py, sy = loaddata_from_numpy(self.dataset, self.task, root_dir)
  File "E:\robustlearn\diversify\datautil\actdata\util.py", line 38, in loaddata_from_numpy
    x = np.reshape(x, (x.shape[0], x.shape[2], x.shape[1]))
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
0                2.8256161213    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7631003857     2.7625243664     0.0005760256    
Counter({0: 29281, 1: 140, 2: 51})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                2.7785780430     0.0099552823     2.7885332108     0.0683699783     0.0685396308     0.0389610390     94.4945847988   

========ROUND 1========
====Feature update====
epoch            class_loss      
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
0                1.5133727789    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6690318584     2.6685934067     0.0004384684    
Counter({1: 11910, 0: 10066, 2: 7496})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3327707052     0.3027457893     1.6355165243     0.4757057546     0.4678338762     0.3797619048     24.3961212635   

========ROUND 1========
====Feature update====
epoch            class_loss      
0                1.4357308149    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6589803696     2.4669837952     0.1919966787    
Counter({1: 13867, 0: 8015, 2: 7590})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3956370354     0.2632938027     1.6589307785     0.6011807818     0.5856406080     0.4432900433     24.1363117695   

========ROUND 2========
====Feature update====
epoch            class_loss      
0                1.4466592073    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5991380215     2.4750297070     0.1241083071    
Counter({1: 14685, 0: 7439, 2: 7348})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.9810550213     0.2599587739     1.2410137653     0.6509229099     0.6260857763     0.5316017316     24.1622450352   

========ROUND 3========
====Feature update====
epoch            class_loss      
0                1.3288160563    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4690983295     2.3446149826     0.1244834140    
Counter({1: 15313, 2: 7735, 0: 6424})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.9350034595     0.3343063891     1.2693098783     0.6195711183     0.5879478827     0.4787878788     24.8250851631   

========ROUND 4========
====Feature update====
epoch            class_loss      
0                0.9744150043    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6673092842     2.3981544971     0.2691548765    
Counter({1: 14556, 2: 8142, 0: 6774})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.8624390960     0.2471789271     1.1096180677     0.6851927253     0.6453583062     0.5667748918     24.1733596325   

========ROUND 5========
====Feature update====
epoch            class_loss      
0                1.1074639559    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4866325855     2.4100058079     0.0766268671    
Counter({1: 15059, 2: 8507, 0: 5906})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.8785235286     0.3061572909     1.1846808195     0.6931324647     0.6536373507     0.5820346320     24.1346380711   

========ROUND 6========
====Feature update====
epoch            class_loss      
0                1.0107870102    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6584136486     2.5032961369     0.1551176161    
Counter({1: 15490, 2: 8231, 0: 5751})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.9123438001     0.2756070793     1.1879508495     0.7408387622     0.6920466884     0.5880952381     24.7437634468   

========ROUND 7========
====Feature update====
epoch            class_loss      
0                1.0284378529    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6834068298     2.5135357380     0.1698710173    
Counter({1: 14807, 2: 8774, 0: 5891})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7494679093     0.3424571455     1.0919250250     0.7713762215     0.7228555917     0.6006493506     24.4175374508   

========ROUND 8========
====Feature update====
epoch            class_loss      
0                0.8422617316    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5604591370     2.4372036457     0.1232555732    
Counter({1: 14881, 2: 8709, 0: 5882})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.8274168968     0.3481179178     1.1755348444     0.7515947340     0.7086047774     0.6352813853     24.1634342670   

========ROUND 9========
====Feature update====
epoch            class_loss      
0                1.1808013916    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6059384346     2.5219838619     0.0839546844    
Counter({1: 14990, 2: 8424, 0: 6058})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.8518715501     0.3377312422     1.1896028519     0.7805035288     0.7269272530     0.6183982684     24.2335748672   

========ROUND 10========
====Feature update====
epoch            class_loss      
0                1.2372045517    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4942855835     2.3813312054     0.1129543558    
Counter({1: 14903, 2: 8522, 0: 6047})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.8449978828     0.3105565012     1.1555544138     0.7756853963     0.7284201954     0.5990259740     24.0850925446   

========ROUND 11========
====Feature update====
epoch            class_loss      
0                0.9385556579    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5320475101     2.4518392086     0.0802083313    
Counter({1: 14807, 2: 8425, 0: 6240})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7229390740     0.2126968056     0.9356358647     0.7416870250     0.6959826276     0.5897186147     24.0590198040   

========ROUND 12========
====Feature update====
epoch            class_loss      
0                1.0214082003    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6932001114     2.5787718296     0.1144282818    
Counter({1: 14752, 2: 8528, 0: 6192})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.9820944667     0.2890182137     1.2711126804     0.7403976656     0.6919109663     0.5887445887     25.4965717793   

========ROUND 13========
====Feature update====
epoch            class_loss      
0                0.9274616838    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6792521477     2.4743387699     0.2049134225    
Counter({1: 14647, 2: 8454, 0: 6371})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.8040490150     0.2847030759     1.0887520313     0.7890540174     0.7289630836     0.6522727273     24.1230113506   

========ROUND 14========
====Feature update====
epoch            class_loss      
0                0.9137501121    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6452713013     2.5152637959     0.1300074160    
Counter({1: 14137, 2: 8876, 0: 6459})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.8271390796     0.2296447754     1.0567839146     0.7899701412     0.7257057546     0.6291125541     24.0382843018   

========ROUND 15========
====Feature update====
epoch            class_loss      
0                0.9378690124    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5584254265     2.4963185787     0.0621069372    
Counter({1: 13911, 2: 8771, 0: 6790})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7583370209     0.2019104958     0.9602475166     0.7950936482     0.7387350706     0.6244588745     24.1408114433   

========ROUND 16========
====Feature update====
epoch            class_loss      
0                0.8780274987    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4985654354     2.4451663494     0.0533990376    
Counter({1: 14120, 2: 8973, 0: 6379})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.8574874997     0.2998352647     1.1573227644     0.7834894137     0.7262486428     0.6415584416     24.1347496510   

========ROUND 17========
====Feature update====
epoch            class_loss      
0                0.9711043835    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5673482418     2.5459034443     0.0214448813    
Counter({1: 13973, 2: 8884, 0: 6615})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5987312198     0.4439705908     1.0427018404     0.7808767644     0.7243485342     0.6334415584     24.1683514118   

========ROUND 18========
====Feature update====
epoch            class_loss      
0                0.8312600255    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6335697174     2.5664913654     0.0670783520    
Counter({1: 14189, 2: 8717, 0: 6566})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.0414452553     0.3450672328     1.3865125179     0.7906487514     0.7293702497     0.6410173160     24.1582002640   

========ROUND 19========
====Feature update====
epoch            class_loss      
0                0.7780357003    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6361765862     2.5443749428     0.0918017253    
Counter({1: 13819, 2: 9146, 0: 6507})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7510714531     0.4505249560     1.2015963793     0.8016422367     0.7433496200     0.6431818182     26.2027070522   

========ROUND 20========
====Feature update====
epoch            class_loss      
0                0.7889303565    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4428498745     2.3919517994     0.0508980639    
Counter({1: 13838, 2: 9257, 0: 6377})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7482616901     0.3870365918     1.1352982521     0.7881378936     0.7281487514     0.6103896104     23.9042072296   

========ROUND 21========
====Feature update====
epoch            class_loss      
0                0.9512327313    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6970951557     2.5315983295     0.1654968262    
Counter({1: 13993, 2: 9139, 0: 6340})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6356644034     0.2660262883     0.9016907215     0.8155537459     0.7474212812     0.6346320346     24.3715739250   

========ROUND 22========
====Feature update====
epoch            class_loss      
0                0.8467989564    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5257804394     2.4763195515     0.0494608283    
Counter({1: 14127, 2: 9176, 0: 6169})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6609529853     0.2943111956     0.9552642107     0.7843376764     0.7204125950     0.6161255411     23.9427828789   

========ROUND 23========
====Feature update====
epoch            class_loss      
0                0.6787387729    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6117312908     2.5578937531     0.0538375825    
Counter({1: 13821, 2: 9054, 0: 6597})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5532214046     0.3510768712     0.9042983055     0.8242060261     0.7536644951     0.6440476190     23.9592430592   

========ROUND 24========
====Feature update====
epoch            class_loss      
0                0.7631590962    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4548368454     2.4053587914     0.0494781435    
Counter({1: 13729, 2: 9184, 0: 6559})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7225124240     0.2920564711     1.0145689249     0.7861359935     0.7263843648     0.6278138528     23.9499995708   

========ROUND 25========
====Feature update====
epoch            class_loss      
0                0.8846282959    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5334606171     2.4775426388     0.0559180863    
Counter({1: 13785, 2: 9244, 0: 6443})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7529119849     0.4167454243     1.1696574688     0.7981813246     0.7319489685     0.5955627706     24.0949664116   

========ROUND 26========
====Feature update====
epoch            class_loss      
0                0.6815478802    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6547203064     2.5743486881     0.0803716481    
Counter({1: 13874, 2: 9276, 0: 6322})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6807557940     0.3773545027     1.0581102371     0.8013707926     0.7338490771     0.6143939394     24.2517137527   

========ROUND 27========
====Feature update====
epoch            class_loss      
0                0.8283436894    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6411702633     2.5242714882     0.1168987677    
Counter({1: 13672, 2: 9428, 0: 6372})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.0301061869     0.3103745282     1.3404806852     0.8120589034     0.7474212812     0.6347402597     24.1716494560   

========ROUND 28========
====Feature update====
epoch            class_loss      
0                1.1516242027    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5554382801     2.4566733837     0.0987649262    
Counter({1: 13813, 2: 9286, 0: 6373})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6915324330     0.3222105205     1.0137429237     0.7966205212     0.7366992400     0.6023809524     24.1396913528   

========ROUND 29========
====Feature update====
epoch            class_loss      
0                1.3927937746    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5047647953     2.4050939083     0.0996708572    
Counter({1: 13924, 2: 9118, 0: 6430})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7852011323     0.2803858221     1.0655869246     0.8151465798     0.7489142237     0.6463203463     24.2753391266   

========ROUND 30========
====Feature update====
epoch            class_loss      
0                0.8707458973    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5900917053     2.5439026356     0.0461891145    
Counter({1: 13818, 2: 9228, 0: 6426})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6422137618     0.2029849291     0.8451986909     0.8175217155     0.7476927253     0.6316017316     24.1574730873   

========ROUND 31========
====Feature update====
epoch            class_loss      
0                0.9969734550    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6143720150     2.5334553719     0.0809166953    
Counter({1: 13393, 2: 9314, 0: 6765})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.8063756824     0.4007323682     1.2071080208     0.7549199240     0.6944896851     0.5895021645     24.2508869171   

========ROUND 32========
====Feature update====
epoch            class_loss      
0                0.7474483848    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7050247192     2.6396739483     0.0653508604    
Counter({1: 13436, 2: 9505, 0: 6531})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.8323215842     0.3665214479     1.1988430023     0.8085301303     0.7411780673     0.6104978355     24.4746897221   

========ROUND 33========
====Feature update====
epoch            class_loss      
0                0.7158660889    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5465841293     2.4233307838     0.1232534274    
Counter({1: 13394, 2: 9622, 0: 6456})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7397952676     0.3500141203     1.0898094177     0.8114142237     0.7449782845     0.6408008658     24.2219414711   

========ROUND 34========
====Feature update====
epoch            class_loss      
0                0.7929888368    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5078470707     2.4499089718     0.0579381622    
Counter({1: 13222, 2: 9740, 0: 6510})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7553176880     0.3489866555     1.1043043137     0.7773479913     0.7190553746     0.5777056277     24.1175148487   

========ROUND 35========
====Feature update====
epoch            class_loss      
0                0.9487811923    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6718156338     2.5743637085     0.0974519551    
Counter({1: 13062, 2: 9674, 0: 6736})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.8748438954     0.3509441316     1.2257879972     0.8066300217     0.7483713355     0.6148268398     24.1424109936   

========ROUND 36========
====Feature update====
epoch            class_loss      
0                0.7990071774    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5593824387     2.5038928986     0.0554894321    
Counter({1: 12705, 2: 9773, 0: 6994})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6392195821     0.4219876826     1.0612072945     0.8085979913     0.7394136808     0.6124458874     24.6493465900   

========ROUND 37========
====Feature update====
epoch            class_loss      
0                0.8188732266    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5336124897     2.4818894863     0.0517230779    
Counter({1: 12518, 2: 9901, 0: 7053})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7503798604     0.3692002296     1.1195800304     0.8063925081     0.7380564604     0.6174242424     26.6850860119   

========ROUND 38========
====Feature update====
epoch            class_loss      
0                0.9540171027    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6808516979     2.5338191986     0.1470324248    
Counter({1: 12893, 2: 9733, 0: 6846})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6433629990     0.2661314309     0.9094944000     0.8148751357     0.7500000000     0.6662337662     23.8669135571   

========ROUND 39========
====Feature update====
epoch            class_loss      
0                1.0008589029    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6296536922     2.5742230415     0.0554307513    
Counter({1: 12977, 2: 9999, 0: 6496})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5342710018     0.2539090514     0.7881800532     0.8063925081     0.7463355049     0.6577922078     23.9580070972   

========ROUND 40========
====Feature update====
epoch            class_loss      
0                0.8907799125    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5239076614     2.4739205837     0.0499871187    
Counter({1: 12611, 2: 10015, 0: 6846})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5933834910     0.3151809573     0.9085644484     0.8153501629     0.7455211726     0.6393939394     24.0801532269   

========ROUND 41========
====Feature update====
epoch            class_loss      
0                0.8058165908    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6161150932     2.5317070484     0.0844081566    
Counter({1: 12945, 2: 10057, 0: 6470})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5599998236     0.2674948871     0.8274947405     0.7975366450     0.7342562432     0.5966450216     23.9720306396   

========ROUND 42========
====Feature update====
epoch            class_loss      
0                0.8568799496    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4766952991     2.3807384968     0.0959566906    
Counter({1: 12330, 2: 10286, 0: 6856})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7248435616     0.3310950100     1.0559386015     0.8231881107     0.7552931596     0.6675324675     23.9499237537   

========ROUND 43========
====Feature update====
epoch            class_loss      
0                0.9521329403    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5528295040     2.4971892834     0.0556402542    
Counter({1: 12418, 2: 10351, 0: 6703})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6855223775     0.2523042858     0.9378266335     0.7964169381     0.7358849077     0.6160173160     23.9491064548   

========ROUND 44========
====Feature update====
epoch            class_loss      
0                0.7776367664    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7587876320     2.5656170845     0.1931705028    
Counter({1: 12719, 2: 9916, 0: 6837})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5442572832     0.2841493785     0.8284066916     0.8336726384     0.7649294245     0.6707792208     23.9129912853   

========ROUND 45========
====Feature update====
epoch            class_loss      
0                0.8038274646    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6044807434     2.5527133942     0.0517674573    
Counter({1: 12486, 2: 9643, 0: 7343})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.8061128259     0.4560178220     1.2621306181     0.7802320847     0.7136264929     0.5779220779     23.9768450260   

========ROUND 46========
====Feature update====
epoch            class_loss      
0                0.9495767951    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6176955700     2.5108821392     0.1068134829    
Counter({1: 12224, 2: 9881, 0: 7367})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.8194957376     0.3994196653     1.2189154625     0.7756175353     0.7181053203     0.6050865801     23.9056363106   

========ROUND 47========
====Feature update====
epoch            class_loss      
0                0.8346089721    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5239775181     2.4608883858     0.0630890504    
Counter({1: 12091, 2: 9802, 0: 7579})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.9056332111     0.3110234141     1.2166566849     0.8294652552     0.7567861021     0.6509740260     23.9310419559   

========ROUND 48========
====Feature update====
epoch            class_loss      
0                0.8157761097    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6487228870     2.5734639168     0.0752590075    
Counter({1: 12134, 2: 9944, 0: 7394})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6502879262     0.4153330028     1.0656208992     0.8009296960     0.7301845820     0.6207792208     23.9322597980   

========ROUND 49========
====Feature update====
epoch            class_loss      
0                0.8008971214    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4634394646     2.4493780136     0.0140613690    
Counter({1: 11693, 2: 10075, 0: 7704})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7498281002     0.3350296915     1.0848578215     0.8138572204     0.7425352877     0.6536796537     23.9761161804   

========ROUND 50========
====Feature update====
epoch            class_loss      
0                0.9018825889    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5846285820     2.4914681911     0.0931604207    
Counter({1: 11993, 2: 9824, 0: 7655})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6588465571     0.2716951668     0.9305417538     0.8117535288     0.7383279045     0.6397186147     24.8034977913   

========ROUND 51========
====Feature update====
epoch            class_loss      
0                0.9446759224    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6462504864     2.5546486378     0.0916019455    
Counter({1: 12015, 2: 9883, 0: 7574})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.8078879714     0.3158046901     1.1236926317     0.8145697611     0.7447068404     0.6287878788     24.7105391026   

========ROUND 52========
====Feature update====
epoch            class_loss      
0                0.8002937436    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4934368134     2.4130940437     0.0803428814    
Counter({1: 11632, 2: 9895, 0: 7945})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5634325743     0.3290141523     0.8924467564     0.8358781216     0.7639793702     0.6690476190     24.4942314625   

========ROUND 53========
====Feature update====
epoch            class_loss      
0                0.8449389338    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6026906967     2.5409204960     0.0617701076    
Counter({1: 11823, 2: 9864, 0: 7785})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.8175677657     0.4639143944     1.2814822197     0.7872557003     0.7295059718     0.6374458874     24.1695828438   

========ROUND 54========
====Feature update====
epoch            class_loss      
0                0.8985782266    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6863937378     2.6221909523     0.0642027780    
Counter({1: 11767, 2: 9849, 0: 7856})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5379502773     0.2811324298     0.8190827370     0.8202361564     0.7510857763     0.6346320346     24.0615417957   

========ROUND 55========
====Feature update====
epoch            class_loss      
0                0.8712230325    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7286159992     2.5786149502     0.1500010937    
Counter({1: 11666, 2: 9969, 0: 7837})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6349297166     0.4143306315     1.0492603779     0.7984866992     0.7342562432     0.6139610390     24.1797227859   

========ROUND 56========
====Feature update====
epoch            class_loss      
0                0.6165973544    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6662328243     2.5583348274     0.1078979746    
Counter({1: 11974, 2: 9605, 0: 7893})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5161753297     0.2760726511     0.7922480106     0.8206772530     0.7517643865     0.6329004329     24.1677417755   

========ROUND 57========
====Feature update====
epoch            class_loss      
0                1.0567668676    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4694123268     2.4270758629     0.0423364230    
Counter({1: 11747, 2: 9985, 0: 7740})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.8077285290     0.3830019534     1.1907304525     0.8350977199     0.7704940282     0.6650432900     24.1267380714   

========ROUND 58========
====Feature update====
epoch            class_loss      
0                0.6693673134    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5426874161     2.4340143204     0.1086730957    
Counter({1: 11313, 2: 10297, 0: 7862})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5700049400     0.4219003916     0.9919053316     0.8430374593     0.7740228013     0.6458874459     24.2181811333   

========ROUND 59========
====Feature update====
epoch            class_loss      
0                0.6616285443    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5708303452     2.4810802937     0.0897499919    
Counter({1: 11495, 2: 10097, 0: 7880})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4889178276     0.3409506977     0.8298685551     0.8146715527     0.7504071661     0.6235930736     24.3883988857   

========ROUND 60========
====Feature update====
epoch            class_loss      
0                0.8073029518    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6294858456     2.5650188923     0.0644669458    
Counter({1: 11610, 2: 10045, 0: 7817})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5090834498     0.3812119961     0.8902954459     0.8028637351     0.7301845820     0.6426406926     24.1641829014   

========ROUND 61========
====Feature update====
epoch            class_loss      
0                0.6573601365    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5266757011     2.5084512234     0.0182243790    
Counter({1: 11671, 2: 9998, 0: 7803})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5750598311     0.2976087332     0.8726685643     0.8222041260     0.7531216069     0.6477272727     24.1600368023   

========ROUND 62========
====Feature update====
epoch            class_loss      
0                1.0300213099    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5649890900     2.5225222111     0.0424668305    
Counter({1: 11640, 2: 10071, 0: 7761})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7637233138     0.3194549382     1.0831782818     0.8137554289     0.7498642780     0.6234848485     24.4087104797   

========ROUND 63========
====Feature update====
epoch            class_loss      
0                0.7887514234    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7625403404     2.5466580391     0.2158822566    
Counter({1: 11630, 2: 10161, 0: 7681})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6404348612     0.5833175778     1.2237524986     0.7973330619     0.7312703583     0.6464285714     24.1502845287   

========ROUND 64========
====Feature update====
epoch            class_loss      
0                0.8362925649    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6147203445     2.4345648289     0.1801555306    
Counter({1: 11442, 2: 10238, 0: 7792})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5831480026     0.3508647680     0.9340127707     0.8173181325     0.7514929425     0.6524891775     24.1687998772   

========ROUND 65========
====Feature update====
epoch            class_loss      
0                0.9678662419    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6359138489     2.5268571377     0.1090566888    
Counter({1: 11244, 2: 10608, 0: 7620})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5965380073     0.3983955383     0.9949335456     0.7598059175     0.7045331162     0.5762987013     24.7686340809   

========ROUND 66========
====Feature update====
epoch            class_loss      
0                0.7442620397    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7264380455     2.6491677761     0.0772703514    
Counter({1: 11282, 2: 10489, 0: 7701})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5270788074     0.4151381254     0.9422169328     0.8072407709     0.7388707926     0.6344155844     24.0920457840   

========ROUND 67========
====Feature update====
epoch            class_loss      
0                0.7777521610    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5951125622     2.5473361015     0.0477765612    
Counter({1: 11014, 2: 10581, 0: 7877})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7362462878     0.5218710303     1.2581173182     0.8200665038     0.7510857763     0.6428571429     23.9775187969   

========ROUND 68========
====Feature update====
epoch            class_loss      
0                0.9661224484    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6986520290     2.5036582947     0.1949938387    
Counter({1: 11181, 2: 10492, 0: 7799})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5319159627     0.4249554873     0.9568714499     0.8153162324     0.7467426710     0.6652597403     24.0373628139   

========ROUND 69========
====Feature update====
epoch            class_loss      
0                0.8848473430    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5086863041     2.3964438438     0.1122423485    
Counter({1: 11212, 2: 10637, 0: 7623})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6587358117     0.2201418430     0.8788776398     0.8235274159     0.7532573290     0.6431818182     24.2029156685   

========ROUND 70========
====Feature update====
epoch            class_loss      
0                0.7738506198    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5862402916     2.4498255253     0.1364146620    
Counter({1: 11098, 2: 10535, 0: 7839})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7652114034     0.3232069314     1.0884183645     0.8297706298     0.7623507058     0.6491341991     24.2513403893   

========ROUND 71========
====Feature update====
epoch            class_loss      
0                0.8685965538    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5952215195     2.5313894749     0.0638321340    
Counter({1: 11022, 2: 10471, 0: 7979})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6779401898     0.3904280961     1.0683683157     0.8217969598     0.7565146580     0.6300865801     24.1351273060   

========ROUND 72========
====Feature update====
epoch            class_loss      
0                0.7833747268    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6137347221     2.5323739052     0.0813608691    
Counter({1: 10825, 2: 10622, 0: 8025})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6488370299     0.3519293964     1.0007663965     0.8101587948     0.7468783931     0.6286796537     24.2548356056   

========ROUND 73========
====Feature update====
epoch            class_loss      
0                0.7443370223    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6439244747     2.5641968250     0.0797275528    
Counter({1: 10827, 2: 10573, 0: 8072})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7591293454     0.4029697180     1.1620991230     0.8195914767     0.7437567861     0.6632034632     24.2016062737   

========ROUND 74========
====Feature update====
epoch            class_loss      
0                0.7989475131    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6091213226     2.5024435520     0.1066776738    
Counter({1: 11157, 2: 10513, 0: 7802})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6346727610     0.3251526654     0.9598253965     0.8311278502     0.7637079262     0.6333333333     24.1207408905   

========ROUND 75========
====Feature update====
epoch            class_loss      
0                0.7055060267    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6178407669     2.5818874836     0.0359533317    
Counter({1: 10892, 2: 10645, 0: 7935})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5073003173     0.2453093082     0.7526096106     0.7993349620     0.7308631922     0.6431818182     24.3006510735   

========ROUND 76========
====Feature update====
epoch            class_loss      
0                1.1859141588    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6638870239     2.5675652027     0.0963218883    
Counter({1: 11043, 2: 10674, 0: 7755})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.8577134609     0.4759736955     1.3336871862     0.7998778502     0.7358849077     0.6002164502     24.3058869839   

========ROUND 77========
====Feature update====
epoch            class_loss      
0                0.7611697316    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5548176765     2.4598009586     0.0950167477    
Counter({1: 11300, 2: 10274, 0: 7898})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.8712389469     0.4008122385     1.2720512152     0.8362513572     0.7766015201     0.6629870130     24.0929007530   

========ROUND 78========
====Feature update====
epoch            class_loss      
0                0.6780450344    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6803369522     2.5768377781     0.1034991071    
Counter({1: 11132, 2: 10513, 0: 7827})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6649580598     0.4357705414     1.1007286310     0.8237988599     0.7546145494     0.6571428571     24.2126905918   

========ROUND 79========
====Feature update====
epoch            class_loss      
0                0.7189214826    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5459580421     2.4820218086     0.0639361367    
Counter({1: 11117, 2: 10846, 0: 7509})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6018394828     0.3672056198     0.9690451026     0.8216273073     0.7490499457     0.6589826840     24.2778952122   

========ROUND 80========
====Feature update====
epoch            class_loss      
0                0.8217270970    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5274772644     2.4404418468     0.0870354399    
Counter({1: 11196, 2: 10682, 0: 7594})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.8728987575     0.6471308470     1.5200295448     0.8013029316     0.7335776330     0.6540043290     24.1164677143   

========ROUND 81========
====Feature update====
epoch            class_loss      
0                0.8301753998    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6364302635     2.5713169575     0.0651132390    
Counter({1: 11237, 2: 10447, 0: 7788})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7679114342     0.3390685022     1.1069799662     0.7960097720     0.7308631922     0.6194805195     24.2416677475   

========ROUND 82========
====Feature update====
epoch            class_loss      
0                0.8741143346    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6691567898     2.6002290249     0.0689278468    
Counter({1: 11388, 2: 10443, 0: 7641})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5602262616     0.4035977423     0.9638240337     0.8255293160     0.7585504886     0.6476190476     24.1775102615   

========ROUND 83========
====Feature update====
epoch            class_loss      
0                0.7985289097    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5375759602     2.4776415825     0.0599343441    
Counter({1: 10894, 2: 10788, 0: 7790})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7109217048     0.3925441504     1.1034657955     0.8127714441     0.7429424539     0.6579004329     24.0286870003   

========ROUND 84========
====Feature update====
epoch            class_loss      
0                0.8874129653    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6629872322     2.5807874203     0.0821997449    
Counter({2: 11025, 1: 10754, 0: 7693})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6484267116     0.5511291027     1.1995558739     0.8278705212     0.7569218241     0.6520562771     24.0557079315   

========ROUND 85========
====Feature update====
epoch            class_loss      
0                0.9048707485    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6318631172     2.5718381405     0.0600250214    
Counter({2: 11084, 1: 10776, 0: 7612})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7640669346     0.3550028503     1.1190698147     0.8196932682     0.7476927253     0.6538961039     24.1206865311   

========ROUND 86========
====Feature update====
epoch            class_loss      
0                1.1943978071    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6085722446     2.5555675030     0.0530048572    
Counter({2: 11098, 1: 10605, 0: 7769})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7414770126     0.5652862191     1.3067631721     0.8282776873     0.7630293160     0.6562770563     24.0076441765   

========ROUND 87========
====Feature update====
epoch            class_loss      
0                0.6004081368    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6561641693     2.5864875317     0.0696765408    
Counter({2: 11256, 1: 10635, 0: 7581})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4204090536     0.4333607256     0.8537697792     0.8243756786     0.7585504886     0.6128787879     23.9741511345   

========ROUND 88========
====Feature update====
epoch            class_loss      
0                0.5815294385    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6853003502     2.5878760815     0.0974242613    
Counter({2: 11315, 1: 10845, 0: 7312})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6037624478     0.4458949566     1.0496573448     0.8402551574     0.7633007600     0.6536796537     24.0355064869   

========ROUND 89========
====Feature update====
epoch            class_loss      
0                0.6657447815    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7350754738     2.6768341064     0.0582413077    
Counter({2: 11218, 1: 11153, 0: 7101})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5462907553     0.3186965585     0.8649873137     0.8360817047     0.7627578719     0.6562770563     23.9284265041   

========ROUND 90========
====Feature update====
epoch            class_loss      
0                0.8182963729    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5301012993     2.4923183918     0.0377828814    
Counter({1: 11289, 2: 11121, 0: 7062})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6178199053     0.5249974728     1.1428173780     0.8105659609     0.7418566775     0.6755411255     23.8222308159   

========ROUND 91========
====Feature update====
epoch            class_loss      
0                0.7451525331    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5917735100     2.4869036674     0.1048699245    
Counter({1: 11091, 2: 11075, 0: 7306})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.8329985142     0.3621560037     1.1951545477     0.7923792074     0.7299131379     0.6159090909     23.9354531765   

========ROUND 92========
====Feature update====
epoch            class_loss      
0                0.7283117771    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7571523190     2.6457583904     0.1113938168    
Counter({2: 11548, 1: 10380, 0: 7544})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7338714004     0.3461323977     1.0800037384     0.8128393051     0.7444353963     0.6538961039     23.9486606121   

========ROUND 93========
====Feature update====
epoch            class_loss      
0                0.6908107400    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5797119141     2.4949595928     0.0847522616    
Counter({2: 11469, 1: 10641, 0: 7362})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5577847362     0.2707886994     0.8285734653     0.8097516287     0.7415852334     0.6384199134     23.8155007362   

========ROUND 94========
====Feature update====
epoch            class_loss      
0                0.7309233546    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6731839180     2.5527255535     0.1204584017    
Counter({2: 11524, 1: 10616, 0: 7332})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5368039012     0.3202193081     0.8570232391     0.8277347991     0.7618078176     0.6566017316     23.9166655540   

========ROUND 95========
====Feature update====
epoch            class_loss      
0                0.9898919463    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6259706020     2.5221407413     0.1038298979    
Counter({2: 11374, 1: 10789, 0: 7309})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6352686286     0.3137044609     0.9489730597     0.7837608578     0.7248914224     0.6014069264     23.9538440704   

========ROUND 96========
====Feature update====
epoch            class_loss      
0                0.7791988254    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5059318542     2.4324796200     0.0734523088    
Counter({2: 11489, 1: 10756, 0: 7227})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7992882729     0.3806872666     1.1799755096     0.7882396851     0.7282844734     0.5993506494     23.9886629581   

========ROUND 97========
====Feature update====
epoch            class_loss      
0                0.8004947305    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6207988262     2.5691907406     0.0516080856    
Counter({2: 11388, 1: 10810, 0: 7274})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6303924918     0.5327029824     1.1630954742     0.8371674810     0.7688653637     0.6702380952     23.9734702110   

========ROUND 98========
====Feature update====
epoch            class_loss      
0                0.8850303292    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7813172340     2.6726753712     0.1086417809    
Counter({2: 11542, 1: 10698, 0: 7232})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6595209837     0.4406741858     1.1001951694     0.8303474484     0.7576004343     0.6557359307     24.2364399433   

========ROUND 99========
====Feature update====
epoch            class_loss      
0                0.7871291041    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5819108486     2.5431020260     0.0388087444    
Counter({2: 11607, 1: 10628, 0: 7237})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.8035001159     0.2897861898     1.0932862759     0.8340119435     0.7620792617     0.6538961039     23.9878518581   

========ROUND 100========
====Feature update====
epoch            class_loss      
0                1.0101641417    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6570518017     2.6210508347     0.0360008813    
Counter({2: 11726, 1: 10558, 0: 7188})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7173165679     0.3789060414     1.0962226391     0.7956704669     0.7360206298     0.6309523810     24.0620126724   

========ROUND 101========
====Feature update====
epoch            class_loss      
0                0.8348207474    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7004394531     2.6303701401     0.0700693950    
Counter({2: 11422, 1: 10612, 0: 7438})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.8328301311     0.4225105941     1.2553406954     0.8262757872     0.7593648208     0.6717532468     24.0518736839   

========ROUND 102========
====Feature update====
epoch            class_loss      
0                1.0185364485    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6674098969     2.6290414333     0.0383683853    
Counter({2: 11545, 1: 10226, 0: 7701})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6806101203     0.3251037598     1.0057139397     0.8090730185     0.7421281216     0.6488095238     24.0156276226   

========ROUND 103========
====Feature update====
epoch            class_loss      
0                0.9040451646    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7093515396     2.5651471615     0.1442043334    
Counter({2: 11497, 1: 10307, 0: 7668})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.8413155675     0.4057933986     1.2471089363     0.8010314875     0.7362920738     0.6594155844     23.9478557110   

========ROUND 104========
====Feature update====
epoch            class_loss      
0                0.7691889405    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6141455173     2.5001707077     0.1139747798    
Counter({2: 11652, 1: 10491, 0: 7329})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6014660001     0.4545568228     1.0560228825     0.8280062432     0.7559717698     0.6484848485     24.0290241241   

========ROUND 105========
====Feature update====
epoch            class_loss      
0                0.9140055180    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6342036724     2.5354123116     0.0987913609    
Counter({2: 11478, 1: 10834, 0: 7160})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4871464968     0.3941687644     0.8813152313     0.7863395765     0.7220412595     0.6312770563     23.9917502403   

========ROUND 106========
====Feature update====
epoch            class_loss      
0                0.8612999916    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6176609993     2.5692474842     0.0484135933    
Counter({2: 11205, 1: 11142, 0: 7125})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4717786014     0.4194161594     0.8911947608     0.8312635722     0.7490499457     0.6415584416     23.9532821178   

========ROUND 107========
====Feature update====
epoch            class_loss      
0                0.8123772144    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6330392361     2.5337564945     0.0992828235    
Counter({2: 11528, 1: 10717, 0: 7227})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4971630871     0.5046356320     1.0017987490     0.7928881650     0.7174267101     0.6245670996     23.9491374493   

========ROUND 108========
====Feature update====
epoch            class_loss      
0                0.9643782973    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5901865959     2.5178720951     0.0723144785    
Counter({2: 11253, 1: 11208, 0: 7011})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6926519275     0.3679704666     1.0606224537     0.8339101520     0.7608577633     0.6655844156     23.9235112667   

========ROUND 109========
====Feature update====
epoch            class_loss      
0                0.7709732056    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5341882706     2.4687428474     0.0654455051    
Counter({1: 11651, 2: 10870, 0: 6951})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6347796321     0.4148072302     1.0495868921     0.8306867535     0.7609934853     0.6482683983     24.3415400982   

========ROUND 110========
====Feature update====
epoch            class_loss      
0                1.0382419825    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5855779648     2.4875824451     0.0979955122    
Counter({1: 11417, 2: 11253, 0: 6802})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6685938239     0.4113959074     1.0799896717     0.8303813789     0.7536644951     0.6683982684     24.0024971962   

========ROUND 111========
====Feature update====
epoch            class_loss      
0                0.9433684349    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6800971031     2.6137020588     0.0663951635    
Counter({2: 11631, 1: 10758, 0: 7083})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6373013854     0.4577866495     1.0950880051     0.8307885451     0.7536644951     0.6784632035     24.0417551994   

========ROUND 112========
====Feature update====
epoch            class_loss      
0                0.8162178993    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4870283604     2.4331688881     0.0538594723    
Counter({2: 11974, 1: 10587, 0: 6911})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6200131178     0.2756246924     0.8956378102     0.7888165038     0.7259771987     0.6426406926     23.8671786785   

========ROUND 113========
====Feature update====
epoch            class_loss      
0                0.7929525971    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5000641346     2.4637949467     0.0362692811    
Counter({2: 11750, 1: 10639, 0: 7083})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.0170577765     0.5054765940     1.5225343704     0.8281080347     0.7509500543     0.6420995671     23.9349181652   

========ROUND 114========
====Feature update====
epoch            class_loss      
0                0.6707174182    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5865535736     2.5320107937     0.0545427948    
Counter({2: 11803, 1: 10620, 0: 7049})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7824831009     0.4495350122     1.2320181131     0.8395086862     0.7672366992     0.6844155844     24.8475680351   

========ROUND 115========
====Feature update====
epoch            class_loss      
0                0.9908451438    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5740778446     2.5304977894     0.0435800739    
Counter({2: 11792, 1: 10345, 0: 7335})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6971862912     0.4384486675     1.1356348991     0.8220344734     0.7479641694     0.6634199134     24.1589939594   

========ROUND 116========
====Feature update====
epoch            class_loss      
0                0.7226095796    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7774081230     2.6423785686     0.1350295544    
Counter({2: 11637, 1: 10620, 0: 7215})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5534044504     0.3883889019     0.9417933226     0.8315010858     0.7597719870     0.6465367965     24.1148986816   

========ROUND 117========
====Feature update====
epoch            class_loss      
0                0.8514564633    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7147898674     2.6055989265     0.1091908216    
Counter({2: 11569, 1: 10602, 0: 7301})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7100659013     0.3582936823     1.0683596134     0.8441910966     0.7759229099     0.6895021645     24.0547776222   

========ROUND 118========
====Feature update====
epoch            class_loss      
0                0.7151387334    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6115953922     2.5812399387     0.0303554386    
Counter({2: 11590, 1: 10696, 0: 7186})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7502315640     0.4239425361     1.1741740704     0.8234934853     0.7558360478     0.6694805195     23.8345811367   

========ROUND 119========
====Feature update====
epoch            class_loss      
0                1.0092452765    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6444485188     2.5543017387     0.0901467279    
Counter({2: 12040, 1: 10213, 0: 7219})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5463092923     0.4147656858     0.9610749483     0.7936685668     0.7341205212     0.5958874459     23.7868156433   
Target acc: 0.6630
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
0                1.7450927496    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6970300674     2.6932723522     0.0037577369    
Counter({0: 12181, 2: 9192, 1: 8099})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.6352461576     0.6191233993     2.2543694973     0.3736427796     0.3710640608     0.2983766234     24.1074991226   

========ROUND 1========
====Feature update====
epoch            class_loss      
0                1.7683252096    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7156226635     2.5020561218     0.2135665268    
Counter({0: 12251, 2: 9830, 1: 7391})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.7225879431     0.3596873283     2.0822753906     0.4911102063     0.4862920738     0.3821428571     24.3037173748   

========ROUND 2========
====Feature update====
epoch            class_loss      
0                1.8255547285    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8179860115     2.5605015755     0.2574844360    
Counter({0: 12434, 2: 10119, 1: 6919})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.4781259298     0.5492370129     2.0273628235     0.4861902823     0.4769272530     0.4216450216     24.2342820168   

========ROUND 3========
====Feature update====
epoch            class_loss      
0                1.7938741446    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5909318924     2.4191467762     0.1717851907    
Counter({0: 10768, 2: 10525, 1: 8179})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.4283189774     0.3019410074     1.7302600145     0.4882600434     0.4788273616     0.4164502165     24.0393030643   

========ROUND 4========
====Feature update====
epoch            class_loss      
0                1.5451818705    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5314626694     2.3786113262     0.1528514177    
Counter({0: 11316, 2: 10805, 1: 7351})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3601387739     0.4294457436     1.7895845175     0.5376628664     0.5237513572     0.4404761905     23.9903595448   

========ROUND 5========
====Feature update====
epoch            class_loss      
0                1.3879505396    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4400696754     2.3304245472     0.1096451655    
Counter({0: 11602, 2: 10725, 1: 7145})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.6276074648     0.5762156844     2.2038230896     0.5730184582     0.5546959826     0.4704545455     24.0375709534   

========ROUND 6========
====Feature update====
epoch            class_loss      
0                1.6033042669    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8256926537     2.4495563507     0.3761362731    
Counter({2: 11043, 0: 10733, 1: 7696})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3914541006     0.3595144749     1.7509685755     0.5369163952     0.5228013029     0.4479437229     24.0027794838   

========ROUND 7========
====Feature update====
epoch            class_loss      
0                1.4579318762    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6414477825     2.4619359970     0.1795118600    
Counter({0: 10944, 2: 10730, 1: 7798})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.2268341780     0.3482879400     1.5751221180     0.5487920738     0.5337947883     0.4549783550     24.7164742947   

========ROUND 8========
====Feature update====
epoch            class_loss      
0                1.3625746965    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7802264690     2.5823805332     0.1978459358    
Counter({2: 10750, 0: 10157, 1: 8565})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.4910926819     0.3001012504     1.7911939621     0.5339983713     0.5134364821     0.4625541126     23.4697260857   

========ROUND 9========
====Feature update====
epoch            class_loss      
0                1.5534800291    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5456943512     2.4345543385     0.1111400127    
Counter({0: 10907, 2: 10273, 1: 8292})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3245495558     0.5126782060     1.8372278214     0.5277551574     0.5141150923     0.3979437229     23.4997220039   

========ROUND 10========
====Feature update====
epoch            class_loss      
0                1.5565408468    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4992809296     2.4206354618     0.0786455199    
Counter({0: 10118, 2: 9844, 1: 9510})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.4730721712     0.4935283959     1.9666005373     0.5046824104     0.4824918567     0.3841991342     23.4743504524   

========ROUND 11========
====Feature update====
epoch            class_loss      
0                1.5706213713    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5807929039     2.4283578396     0.1524349600    
Counter({0: 10142, 2: 10042, 1: 9288})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.2395087481     0.4114558399     1.6509646177     0.5662662866     0.5400380022     0.4527056277     24.0243000984   

========ROUND 12========
====Feature update====
epoch            class_loss      
0                1.3755578995    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6803536415     2.5565354824     0.1238181517    
Counter({0: 10890, 1: 9485, 2: 9097})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.5219544172     0.4149759710     1.9369304180     0.5520833333     0.5347448426     0.4471861472     23.8324267864   

========ROUND 13========
====Feature update====
epoch            class_loss      
0                1.3501644135    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5262310505     2.4119608402     0.1142702326    
Counter({2: 10162, 0: 9879, 1: 9431})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3181623220     0.4401648343     1.7583271265     0.5318946797     0.5103148751     0.4420995671     23.8446700573   

========ROUND 14========
====Feature update====
epoch            class_loss      
0                1.3501920700    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5753324032     2.4369990826     0.1383334249    
Counter({0: 10048, 2: 9983, 1: 9441})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3880376816     0.4119121730     1.7999498844     0.5648412052     0.5477741585     0.4405844156     23.9953734875   

========ROUND 15========
====Feature update====
epoch            class_loss      
0                1.5383900404    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6854009628     2.5228638649     0.1625372171    
Counter({2: 10820, 0: 9607, 1: 9045})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3211556673     0.4166225493     1.7377781868     0.5446525516     0.5302660152     0.4240259740     23.9896552563   

========ROUND 16========
====Feature update====
epoch            class_loss      
0                1.5818066597    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6408851147     2.4844839573     0.1564012021    
Counter({0: 10334, 2: 10315, 1: 8823})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.4116250277     0.3503002226     1.7619252205     0.5407505429     0.5285016287     0.4472943723     23.7992937565   

========ROUND 17========
====Feature update====
epoch            class_loss      
0                1.7427617311    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6119785309     2.4581308365     0.1538476199    
Counter({0: 10481, 2: 10027, 1: 8964})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.0977395773     0.4221831262     1.5199227333     0.5677592291     0.5612106406     0.4577922078     23.9161741734   

========ROUND 18========
====Feature update====
epoch            class_loss      
0                1.3713302612    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6131882668     2.4713275433     0.1418607533    
Counter({2: 10405, 0: 10048, 1: 9019})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.4322172403     0.4900395572     1.9222568274     0.5418702497     0.5160152009     0.4094155844     23.8930659294   

========ROUND 19========
====Feature update====
epoch            class_loss      
0                1.4224878550    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6526751518     2.4416415691     0.2110335678    
Counter({0: 10149, 2: 9869, 1: 9454})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3766032457     0.4505725801     1.8271758556     0.5390200869     0.5187296417     0.4314935065     23.9676761627   

========ROUND 20========
====Feature update====
epoch            class_loss      
0                1.3762850761    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4776647091     2.3870162964     0.0906484127    
Counter({1: 10377, 0: 9668, 2: 9427})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.1055269241     0.3789017200     1.4844286442     0.5696593377     0.5612106406     0.4686147186     23.9511938095   

========ROUND 21========
====Feature update====
epoch            class_loss      
0                1.5710296631    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6043968201     2.4708139896     0.1335828155    
Counter({0: 10121, 1: 10083, 2: 9268})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.2475817204     0.4430472851     1.6906290054     0.5758346906     0.5571389794     0.4537878788     24.0777142048   

========ROUND 22========
====Feature update====
epoch            class_loss      
0                1.4971814156    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6682116985     2.5108611584     0.1573504359    
Counter({0: 11255, 2: 10301, 1: 7916})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.2451964617     0.3944841921     1.6396806240     0.5599212812     0.5409880565     0.5063852814     23.9187252522   

========ROUND 23========
====Feature update====
epoch            class_loss      
0                1.6413774490    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7141637802     2.6162099838     0.0979537144    
Counter({0: 11353, 2: 10290, 1: 7829})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.2339266539     0.4100469649     1.6439735889     0.5849959283     0.5742399566     0.4791125541     24.8854587078   

========ROUND 24========
====Feature update====
epoch            class_loss      
0                1.3868761063    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5148079395     2.4034979343     0.1113100052    
Counter({0: 11769, 2: 9750, 1: 7953})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3498152494     0.3399418592     1.6897571087     0.5942589577     0.5810260586     0.4854978355     24.1112759113   

========ROUND 25========
====Feature update====
epoch            class_loss      
0                1.2762247324    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6036288738     2.4691333771     0.1344954520    
Counter({0: 11519, 2: 9149, 1: 8804})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.2804355621     0.4897325039     1.7701680660     0.5854709555     0.5648751357     0.4480519481     23.9366672039   

========ROUND 26========
====Feature update====
epoch            class_loss      
0                1.3676213026    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6246881485     2.4910700321     0.1336181909    
Counter({0: 11973, 2: 9005, 1: 8494})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3371076584     0.6118878722     1.9489955902     0.5642304560     0.5447882736     0.4731601732     23.9027562141   

========ROUND 27========
====Feature update====
epoch            class_loss      
0                1.5363292694    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5054841042     2.4632623196     0.0422217697    
Counter({0: 11300, 2: 9621, 1: 8551})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.5099383593     0.5284999013     2.0384383202     0.5731202497     0.5519815418     0.4806277056     23.8469886780   

========ROUND 28========
====Feature update====
epoch            class_loss      
0                1.6378861666    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5599970818     2.4736895561     0.0863074288    
Counter({0: 11427, 1: 9037, 2: 9008})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3579634428     0.3783405721     1.7363040447     0.5564264387     0.5396308360     0.4483766234     23.9859380722   

========ROUND 29========
====Feature update====
epoch            class_loss      
0                1.5823011398    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7394042015     2.5939540863     0.1454501897    
Counter({0: 11321, 2: 9296, 1: 8855})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.2447423935     0.4448393285     1.6895817518     0.5774972856     0.5578175896     0.4729437229     23.9055583477   

========ROUND 30========
====Feature update====
epoch            class_loss      
0                1.3310157061    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7220494747     2.5151565075     0.2068929523    
Counter({0: 11398, 2: 9712, 1: 8362})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.2391899824     0.4991811216     1.7383711338     0.5684039088     0.5541530945     0.4541125541     24.0051219463   

========ROUND 31========
====Feature update====
epoch            class_loss      
0                1.3476458788    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5545461178     2.4465899467     0.1079561636    
Counter({0: 11247, 2: 9960, 1: 8265})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.5531320572     0.4801916182     2.0333237648     0.5535423453     0.5389522258     0.4531385281     24.0289993286   

========ROUND 32========
====Feature update====
epoch            class_loss      
0                1.2744324207    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6463227272     2.5174100399     0.1289127469    
Counter({0: 10789, 2: 9628, 1: 9055})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.4881376028     0.3446951210     1.8328326941     0.5048181325     0.4828990228     0.3962121212     23.9871420860   

========ROUND 33========
====Feature update====
epoch            class_loss      
0                1.5077605247    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6405849457     2.4575636387     0.1830214113    
Counter({0: 10410, 1: 9584, 2: 9478})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3043837547     0.4137353003     1.7181190252     0.5594462541     0.5481813246     0.4759740260     24.3485994339   

========ROUND 34========
====Feature update====
epoch            class_loss      
0                1.5232629776    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5695500374     2.4395928383     0.1299572736    
Counter({0: 10686, 1: 9494, 2: 9292})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3226010799     0.5028061271     1.8254072666     0.6078311618     0.5884907709     0.5059523810     24.2729496956   

========ROUND 35========
====Feature update====
epoch            class_loss      
0                1.7128509283    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6789131165     2.5086305141     0.1702824980    
Counter({0: 10039, 1: 9964, 2: 9469})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.6053522825     0.4751601517     2.0805125237     0.5915105863     0.5734256243     0.5008658009     24.1457691193   

========ROUND 36========
====Feature update====
epoch            class_loss      
0                1.4992694855    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6511173248     2.5532047749     0.0979124829    
Counter({0: 10545, 2: 9769, 1: 9158})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.2347105742     0.4342578650     1.6689684391     0.5498778502     0.5428881650     0.4490259740     24.3050854206   

========ROUND 37========
====Feature update====
epoch            class_loss      
0                1.4500546455    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6391615868     2.5216073990     0.1175540760    
Counter({0: 11003, 2: 9617, 1: 8852})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.2421079874     0.3745875657     1.6166955233     0.5933767644     0.5708469055     0.4556277056     24.2472069263   

========ROUND 38========
====Feature update====
epoch            class_loss      
0                1.5022931099    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5963814259     2.5067698956     0.0896114334    
Counter({0: 11018, 2: 9711, 1: 8743})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.2050840855     0.4671735466     1.6722576618     0.5949036374     0.5723398480     0.4933982684     24.3468663692   

========ROUND 39========
====Feature update====
epoch            class_loss      
0                1.6804174185    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6518971920     2.5384604931     0.1134366691    
Counter({0: 10742, 2: 9891, 1: 8839})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3141728640     0.3562259674     1.6703988314     0.5982627579     0.5776330076     0.5006493506     24.2164077759   

========ROUND 40========
====Feature update====
epoch            class_loss      
0                1.5328623056    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7309565544     2.5259034634     0.2050531060    
Counter({0: 11203, 2: 9289, 1: 8980})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3089085817     0.5562731624     1.8651816845     0.5739345820     0.5534744843     0.4725108225     24.1935307980   

========ROUND 41========
====Feature update====
epoch            class_loss      
0                1.2569246292    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4872920513     2.4132914543     0.0740007088    
Counter({0: 11971, 2: 9307, 1: 8194})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.2729837894     0.2942197621     1.5672035217     0.5397665581     0.5252442997     0.4260822511     24.2918100357   

========ROUND 42========
====Feature update====
epoch            class_loss      
0                1.5554534197    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6421210766     2.4059734344     0.2361476421    
Counter({0: 11820, 2: 9141, 1: 8511})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.4018406868     0.4191284478     1.8209691048     0.5919516830     0.5688110749     0.5178571429     24.2204725742   

========ROUND 43========
====Feature update====
epoch            class_loss      
0                1.5607919693    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5647366047     2.4473230839     0.1174135730    
Counter({0: 11419, 2: 9217, 1: 8836})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3492269516     0.4177974463     1.7670243979     0.5594801846     0.5407166124     0.4675324675     24.5848629475   

========ROUND 44========
====Feature update====
epoch            class_loss      
0                1.4458891153    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5002298355     2.4195935726     0.0806361437    
Counter({0: 11804, 2: 9157, 1: 8511})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.1521199942     0.4943841994     1.6465041637     0.6041666667     0.5793973941     0.4821428571     24.2131624222   

========ROUND 45========
====Feature update====
epoch            class_loss      
0                1.4133726358    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5390198231     2.4583671093     0.0806526467    
Counter({0: 12121, 2: 9310, 1: 8041})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.4352864027     0.2438443452     1.6791307926     0.5257193268     0.5107220413     0.4094155844     24.1835896969   

========ROUND 46========
====Feature update====
epoch            class_loss      
0                1.5589333773    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6457362175     2.4613146782     0.1844215989    
Counter({0: 11967, 2: 9367, 1: 8138})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3634103537     0.4067793787     1.7701897621     0.5667413138     0.5479098806     0.4733766234     24.1284904480   

========ROUND 47========
====Feature update====
epoch            class_loss      
0                1.3190251589    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6408119202     2.5690624714     0.0717495307    
Counter({0: 11692, 2: 9302, 1: 8478})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3210662603     0.4297492206     1.7508155107     0.5780062432     0.5548317047     0.4450216450     24.2474308014   

========ROUND 48========
====Feature update====
epoch            class_loss      
0                1.4597436190    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5090332031     2.4059631824     0.1030701324    
Counter({0: 11915, 2: 9336, 1: 8221})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3858280182     0.4570400417     1.8428680897     0.5699986428     0.5498099891     0.4541125541     24.2367670536   

========ROUND 49========
====Feature update====
epoch            class_loss      
0                1.5272103548    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5295825005     2.4288637638     0.1007187665    
Counter({0: 11871, 2: 9112, 1: 8489})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3079546690     0.4624356031     1.7703902721     0.6130564604     0.5983984799     0.5122294372     24.2611653805   

========ROUND 50========
====Feature update====
epoch            class_loss      
0                1.6781797409    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4924619198     2.4222729206     0.0701889470    
Counter({0: 12453, 2: 9100, 1: 7919})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3332798481     0.3715645373     1.7048443556     0.5679967427     0.5525244300     0.4503246753     24.2918040752   

========ROUND 51========
====Feature update====
epoch            class_loss      
0                1.6403506994    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6872076988     2.5519115925     0.1352960914    
Counter({0: 12304, 2: 9122, 1: 8046})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.4935716391     0.4246571064     1.9182287455     0.5432953312     0.5263300760     0.4178571429     24.2497737408   

========ROUND 52========
====Feature update====
epoch            class_loss      
0                1.4319968224    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5905025005     2.5089967251     0.0815057233    
Counter({0: 12045, 2: 9458, 1: 7969})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.1463348866     0.3919724524     1.5383073092     0.5717969598     0.5576818675     0.4494588745     24.1718568802   

========ROUND 53========
====Feature update====
epoch            class_loss      
0                1.3675092459    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8453481197     2.6293356419     0.2160124183    
Counter({0: 11411, 2: 9729, 1: 8332})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.5940403938     0.4164005816     2.0104410648     0.5489617264     0.5247014115     0.4409090909     24.2794172764   

========ROUND 54========
====Feature update====
epoch            class_loss      
0                1.4154757261    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5840232372     2.5170648098     0.0669584498    
Counter({0: 11679, 2: 9615, 1: 8178})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.2457838058     0.3857876360     1.6315714121     0.5880157438     0.5651465798     0.4745670996     24.2311215401   

========ROUND 55========
====Feature update====
epoch            class_loss      
0                1.5869331360    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6062076092     2.4903061390     0.1159015000    
Counter({0: 12303, 2: 9321, 1: 7848})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.1417227983     0.4488652647     1.5905880928     0.5584961998     0.5392236699     0.4283549784     24.1745338440   

========ROUND 56========
====Feature update====
epoch            class_loss      
0                1.4461079836    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6920261383     2.6075656414     0.0844604596    
Counter({0: 12468, 2: 9182, 1: 7822})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3471511602     0.4687459171     1.8158971071     0.5321661238     0.5181867535     0.4540043290     24.1129522324   

========ROUND 57========
====Feature update====
epoch            class_loss      
0                1.3576213121    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5547871590     2.4350607395     0.1197263896    
Counter({0: 12565, 2: 8945, 1: 7962})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.6351423264     0.5507913232     2.1859335899     0.5816368078     0.5666395223     0.4698051948     24.2955644131   

========ROUND 58========
====Feature update====
epoch            class_loss      
0                1.4566472769    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5241961479     2.4076423645     0.1165538728    
Counter({0: 12155, 2: 9152, 1: 8165})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.2093604803     0.4308811128     1.6402416229     0.5824172096     0.5639250814     0.4448051948     24.3428196907   

========ROUND 59========
====Feature update====
epoch            class_loss      
0                1.3540726900    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5490844250     2.4473536015     0.1017307863    
Counter({0: 12198, 2: 8721, 1: 8553})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.1940391064     0.4420585632     1.6360976696     0.5154383822     0.5116720955     0.4037878788     24.3191587925   

========ROUND 60========
====Feature update====
epoch            class_loss      
0                1.4194787741    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6409885883     2.5588147640     0.0821737722    
Counter({0: 12188, 1: 8653, 2: 8631})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.0552507639     0.3204859197     1.3757367134     0.5687771444     0.5542888165     0.4655844156     24.2460556030   

========ROUND 61========
====Feature update====
epoch            class_loss      
0                1.1814882755    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6155419350     2.5348424911     0.0806995109    
Counter({0: 11828, 1: 9045, 2: 8599})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.2898545265     0.3450346291     1.6348891258     0.5652483713     0.5545602606     0.4358225108     24.2509212494   

========ROUND 62========
====Feature update====
epoch            class_loss      
0                1.6392675638    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6215195656     2.4860496521     0.1354698688    
Counter({0: 11769, 1: 8933, 2: 8770})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.4853361845     0.4336059391     1.9189420938     0.6142779587     0.5994842562     0.5122294372     24.2225687504   

========ROUND 63========
====Feature update====
epoch            class_loss      
0                1.4259039164    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6022541523     2.4729423523     0.1293118000    
Counter({0: 11587, 1: 9381, 2: 8504})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.1472634077     0.5091398954     1.6564033031     0.5491313789     0.5370521173     0.4537878788     24.3127505779   

========ROUND 64========
====Feature update====
epoch            class_loss      
0                1.7569519281    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8116257191     2.5621938705     0.2494318932    
Counter({0: 11317, 1: 9798, 2: 8357})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.1668053865     0.3410798013     1.5078852177     0.5949375679     0.5712540717     0.5167748918     24.1405773163   

========ROUND 65========
====Feature update====
epoch            class_loss      
0                1.4789503813    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6244032383     2.5255789757     0.0988242254    
Counter({0: 11108, 1: 9934, 2: 8430})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.2158304453     0.3950784206     1.6109088659     0.5916802389     0.5705754615     0.4775974026     24.2943890095   

========ROUND 66========
====Feature update====
epoch            class_loss      
0                1.5384167433    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5509426594     2.5002388954     0.0507037379    
Counter({0: 11857, 1: 9271, 2: 8344})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.0690326691     0.3204333484     1.3894660473     0.5135722041     0.5092290988     0.4480519481     24.2558388710   

========ROUND 67========
====Feature update====
epoch            class_loss      
0                1.4329193830    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5163464546     2.4515159130     0.0648304224    
Counter({0: 11605, 1: 9084, 2: 8783})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.5165303946     0.4146007597     1.9311311245     0.5703379479     0.5529315961     0.4757575758     24.2378408909   

========ROUND 68========
====Feature update====
epoch            class_loss      
0                1.5798290968    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5920743942     2.5236852169     0.0683890954    
Counter({0: 12131, 1: 9038, 2: 8303})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.2485686541     0.4332070351     1.6817756891     0.5783455483     0.5652823018     0.4673160173     24.2561464310   

========ROUND 69========
====Feature update====
epoch            class_loss      
0                1.5896395445    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4570899010     2.3515398502     0.1055499613    
Counter({0: 13422, 2: 8440, 1: 7610})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3078382015     0.4529901743     1.7608283758     0.5535084148     0.5408523344     0.4571428571     24.1892240047   

========ROUND 70========
====Feature update====
epoch            class_loss      
0                1.4109615088    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5538411140     2.4547154903     0.0991255119    
Counter({0: 11968, 1: 8888, 2: 8616})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.4457077980     0.4043545723     1.8500623703     0.5394272530     0.5299945711     0.4438311688     24.2941009998   

========ROUND 71========
====Feature update====
epoch            class_loss      
0                1.4525852203    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5531442165     2.4916443825     0.0614998303    
Counter({0: 12374, 1: 8777, 2: 8321})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.0325864553     0.4154265225     1.4480129480     0.5755632465     0.5544245385     0.4633116883     24.2440376282   

========ROUND 72========
====Feature update====
epoch            class_loss      
0                1.4627770185    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6135675907     2.4849469662     0.1286206394    
Counter({0: 12978, 1: 8808, 2: 7686})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.1519480944     0.3535239995     1.5054720640     0.6049131379     0.5811617807     0.4805194805     24.2742190361   

========ROUND 73========
====Feature update====
epoch            class_loss      
0                1.5532497168    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5104179382     2.4405686855     0.0698492303    
Counter({0: 13170, 1: 8545, 2: 7757})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.2655047178     0.3999468386     1.6654515266     0.6138029316     0.5973127036     0.5081168831     24.3323569298   

========ROUND 74========
====Feature update====
epoch            class_loss      
0                1.4456495047    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6836559772     2.5600683689     0.1235876009    
Counter({0: 12562, 1: 9292, 2: 7618})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3371363878     0.3541020155     1.6912384033     0.5154723127     0.4983713355     0.3922077922     24.1846828461   

========ROUND 75========
====Feature update====
epoch            class_loss      
0                1.3494275808    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5746181011     2.5064175129     0.0682006925    
Counter({0: 12412, 1: 9264, 2: 7796})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.1116821766     0.3291718662     1.4408540726     0.5295195440     0.5027144408     0.4518398268     24.1903975010   

========ROUND 76========
====Feature update====
epoch            class_loss      
0                1.7843875885    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6112651825     2.5185897350     0.0926754475    
Counter({0: 11962, 1: 9520, 2: 7990})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.4203680754     0.3579944670     1.7783625126     0.6038273616     0.5807546145     0.4804112554     24.2677044868   

========ROUND 77========
====Feature update====
epoch            class_loss      
0                1.4493989944    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4901974201     2.3941748142     0.0960226431    
Counter({0: 12451, 1: 8801, 2: 8220})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3595341444     0.6137140393     1.9732482433     0.5599891422     0.5332519001     0.4679653680     24.2499074936   

========ROUND 78========
====Feature update====
epoch            class_loss      
0                1.3918277025    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7458643913     2.5855886936     0.1602758020    
Counter({0: 12647, 1: 8496, 2: 8329})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3743609190     0.5993475318     1.9737083912     0.5527619435     0.5343376764     0.4809523810     24.2961790562   

========ROUND 79========
====Feature update====
epoch            class_loss      
0                1.4438875914    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5206260681     2.4312422276     0.0893838406    
Counter({0: 13069, 1: 8373, 2: 8030})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.1869131327     0.3234808445     1.5103939772     0.5379003800     0.5177795874     0.4217532468     24.1584720612   

========ROUND 80========
====Feature update====
epoch            class_loss      
0                1.2814825773    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6517734528     2.4577586651     0.1940148026    
Counter({0: 12480, 1: 8862, 2: 8130})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.5150965452     0.5215829015     2.0366795063     0.5958876221     0.5728827362     0.4916666667     24.1804254055   

========ROUND 81========
====Feature update====
epoch            class_loss      
0                1.4545658827    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6590108871     2.4372653961     0.2217454463    
Counter({0: 11969, 1: 9591, 2: 7912})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.4663888216     0.4553780556     1.9217668772     0.5694218241     0.5523887079     0.4411255411     24.2057266235   

========ROUND 82========
====Feature update====
epoch            class_loss      
0                1.5406061411    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5754666328     2.4550509453     0.1204157770    
Counter({0: 12517, 1: 8674, 2: 8281})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.2898389101     0.3576332629     1.6474721432     0.6046077633     0.5830618893     0.4873376623     24.2145743370   

========ROUND 83========
====Feature update====
epoch            class_loss      
0                1.5706907511    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5987792015     2.4292163849     0.1695627421    
Counter({0: 12266, 1: 8674, 2: 8532})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.4411309958     0.3767037690     1.8178347349     0.5345751900     0.5176438654     0.4138528139     24.4673883915   

========ROUND 84========
====Feature update====
epoch            class_loss      
0                1.4154596329    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5665173531     2.4282889366     0.1382284611    
Counter({0: 12900, 1: 8774, 2: 7798})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.1757332087     0.2955478728     1.4712810516     0.5824850706     0.5527958740     0.4584415584     24.1592800617   

========ROUND 85========
====Feature update====
epoch            class_loss      
0                1.4535465240    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6213984489     2.5125524998     0.1088458896    
Counter({0: 12910, 1: 8461, 2: 8101})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3243070841     0.4193542898     1.7436614037     0.5633821933     0.5446525516     0.4595238095     24.1361193657   

========ROUND 86========
====Feature update====
epoch            class_loss      
0                1.4482928514    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5888435841     2.5158751011     0.0729684159    
Counter({0: 12203, 1: 9255, 2: 8014})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3696346283     0.4832867086     1.8529213667     0.5762079262     0.5557817590     0.4714285714     24.2282865047   

========ROUND 87========
====Feature update====
epoch            class_loss      
0                1.3345671892    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6117935181     2.4805891514     0.1312043965    
Counter({0: 11558, 1: 10036, 2: 7878})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.0771427155     0.3833222389     1.4604649544     0.5008482628     0.4835776330     0.3796536797     24.2283728123   

========ROUND 88========
====Feature update====
epoch            class_loss      
0                1.2815718651    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7007942200     2.6264629364     0.0743311718    
Counter({0: 11940, 1: 9809, 2: 7723})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.1991928816     0.4511703551     1.6503632069     0.5430917481     0.5278230185     0.4318181818     24.2333052158   

========ROUND 89========
====Feature update====
epoch            class_loss      
0                1.3157823086    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5529961586     2.4618341923     0.0911620855    
Counter({0: 11792, 1: 9632, 2: 8048})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.2202516794     0.4688489437     1.6891006231     0.5667413138     0.5367806732     0.4647186147     24.2782385349   

========ROUND 90========
====Feature update====
epoch            class_loss      
0                1.2854760885    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6778731346     2.5326526165     0.1452205777    
Counter({0: 11541, 1: 10171, 2: 7760})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.2007831335     0.4444818795     1.6452649832     0.5420059718     0.5207654723     0.4556277056     24.3212749958   

========ROUND 91========
====Feature update====
epoch            class_loss      
0                1.3588809967    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6979165077     2.5004444122     0.1974720806    
Counter({0: 11881, 1: 9499, 2: 8092})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.2375860214     0.5059239864     1.7435100079     0.5809921281     0.5610749186     0.4857142857     24.1895546913   

========ROUND 92========
====Feature update====
epoch            class_loss      
0                1.3884787560    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6826534271     2.5999529362     0.0827005431    
Counter({0: 11706, 1: 9586, 2: 8180})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3396962881     0.5669713020     1.9066675901     0.5788545060     0.5597176982     0.4801948052     24.2374939919   

========ROUND 93========
====Feature update====
epoch            class_loss      
0                1.4199633598    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5305380821     2.4720494747     0.0584886372    
Counter({0: 11955, 1: 9296, 2: 8221})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.2650692463     0.4668149054     1.7318841219     0.5560871336     0.5371878393     0.4264069264     24.1852812767   

========ROUND 94========
====Feature update====
epoch            class_loss      
0                1.3507651091    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5066342354     2.4213585854     0.0852756277    
Counter({0: 13272, 2: 8491, 1: 7709})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.1381825209     0.5247282386     1.6629106998     0.5007464712     0.4876492942     0.4245670996     24.5935549736   

========ROUND 95========
====Feature update====
epoch            class_loss      
0                1.5878912210    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6800482273     2.5637943745     0.1162539497    
Counter({0: 13605, 2: 8576, 1: 7291})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.2285666466     0.4128515720     1.6414182186     0.5577836591     0.5371878393     0.4284632035     24.2757472992   

========ROUND 96========
====Feature update====
epoch            class_loss      
0                1.5467652082    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6860013008     2.5274627209     0.1585385948    
Counter({0: 12464, 2: 8583, 1: 8425})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3460248709     0.3585578203     1.7045826912     0.5255496743     0.5092290988     0.4044372294     24.3622953892   

========ROUND 97========
====Feature update====
epoch            class_loss      
0                1.8384963274    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6414527893     2.5715944767     0.0698583499    
Counter({0: 13031, 2: 8712, 1: 7729})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.2757955790     0.5055084825     1.7813041210     0.6188585776     0.5912052117     0.4755411255     24.1520366669   

========ROUND 98========
====Feature update====
epoch            class_loss      
0                1.2954258919    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6156249046     2.5449299812     0.0706948265    
Counter({0: 12715, 2: 8915, 1: 7842})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.2959401608     0.3195237815     1.6154639721     0.5819082519     0.5675895765     0.4586580087     24.2631537914   

========ROUND 99========
====Feature update====
epoch            class_loss      
0                1.2632516623    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5489115715     2.4250695705     0.1238420680    
Counter({0: 11743, 2: 9024, 1: 8705})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.4578038454     0.4608038664     1.9186077118     0.5704058089     0.5565960912     0.4438311688     24.2233674526   

========ROUND 100========
====Feature update====
epoch            class_loss      
0                1.5389636755    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6080229282     2.4750084877     0.1330145001    
Counter({0: 11256, 2: 9142, 1: 9074})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3555139303     0.6426437497     1.9981577396     0.5639590119     0.5370521173     0.4275974026     24.1783146858   

========ROUND 101========
====Feature update====
epoch            class_loss      
0                1.4385398626    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6062812805     2.5049536228     0.1013275385    
Counter({0: 11546, 1: 9490, 2: 8436})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.4447828531     0.4162429273     1.8610258102     0.5938178610     0.5739685125     0.4780303030     24.7085168362   

========ROUND 102========
====Feature update====
epoch            class_loss      
0                1.6635575294    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5555691719     2.4291300774     0.1264391094    
Counter({0: 11708, 1: 9296, 2: 8468})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3043651581     0.4371202886     1.7414854765     0.5947339848     0.5684039088     0.4410173160     24.3098237514   

========ROUND 103========
====Feature update====
epoch            class_loss      
0                1.4461432695    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6162843704     2.5062363148     0.1100481376    
Counter({0: 11257, 1: 9541, 2: 8674})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3093011379     0.3991650045     1.7084661722     0.5447882736     0.5282301846     0.4900432900     24.2016069889   

========ROUND 104========
====Feature update====
epoch            class_loss      
0                1.4234880209    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8440692425     2.5894892216     0.2545801103    
Counter({1: 10329, 0: 10289, 2: 8854})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.2873089314     0.4652104378     1.7525193691     0.5339983713     0.5204940282     0.3981601732     24.1477413177   

========ROUND 105========
====Feature update====
epoch            class_loss      
0                1.4591212273    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7298443317     2.6454465389     0.0843977332    
Counter({0: 11523, 1: 9184, 2: 8765})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.1621097326     0.3770295680     1.5391392708     0.5350162866     0.5150651466     0.4379870130     24.2468132973   

========ROUND 106========
====Feature update====
epoch            class_loss      
0                1.6015433073    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6673243046     2.5770728588     0.0902514085    
Counter({0: 11751, 1: 9010, 2: 8711})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.1531374454     0.5495739579     1.7027113438     0.5234459826     0.5019001086     0.4457792208     24.2185742855   

========ROUND 107========
====Feature update====
epoch            class_loss      
0                1.5942562819    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5391631126     2.4245915413     0.1145716235    
Counter({0: 11467, 1: 9069, 2: 8936})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3267713785     0.3801789284     1.7069503069     0.5574104235     0.5416666667     0.4832251082     24.3419141769   

========ROUND 108========
====Feature update====
epoch            class_loss      
0                1.5223726034    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7343115807     2.4923479557     0.2419636995    
Counter({0: 10553, 1: 9545, 2: 9374})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.2362946272     0.4611217082     1.6974163055     0.5635518458     0.5499457112     0.4220779221     24.2853441238   

========ROUND 109========
====Feature update====
epoch            class_loss      
0                1.5331654549    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5513803959     2.4771530628     0.0742273927    
Counter({0: 10748, 1: 9725, 2: 8999})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3354004622     0.3950345218     1.7304350138     0.5818743214     0.5670466884     0.4792207792     24.1940338612   

========ROUND 110========
====Feature update====
epoch            class_loss      
0                1.5629997253    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5791003704     2.4824130535     0.0966872275    
Counter({0: 10367, 1: 9945, 2: 9160})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.5033122301     0.3438376188     1.8471498489     0.5896783388     0.5621606949     0.4846320346     24.4851660728   

========ROUND 111========
====Feature update====
epoch            class_loss      
0                1.4633997679    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5576062202     2.4379222393     0.1196840182    
Counter({0: 11759, 2: 9743, 1: 7970})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.2387332916     0.4295080602     1.6682413816     0.5947339848     0.5673181325     0.4930735931     24.3312962055   

========ROUND 112========
====Feature update====
epoch            class_loss      
0                1.4004586935    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6062297821     2.5175955296     0.0886342153    
Counter({0: 10886, 2: 9897, 1: 8689})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.0970126390     0.4049045742     1.5019172430     0.5384432682     0.5185939197     0.4611471861     24.2857885361   

========ROUND 113========
====Feature update====
epoch            class_loss      
0                1.4775772095    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5945689678     2.4662191868     0.1283498704    
Counter({0: 11559, 2: 9587, 1: 8326})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.6202071905     0.4064002037     2.0266075134     0.5552049403     0.5317589577     0.4720779221     24.2593209743   

========ROUND 114========
====Feature update====
epoch            class_loss      
0                1.6334609985    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6082906723     2.4723346233     0.1359560192    
Counter({0: 11775, 2: 9021, 1: 8676})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.1612508297     0.5349825025     1.6962332726     0.5905605320     0.5677252986     0.4807359307     24.2659292221   

========ROUND 115========
====Feature update====
epoch            class_loss      
0                1.3820797205    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6573789120     2.4785726070     0.1788062304    
Counter({0: 11664, 2: 9302, 1: 8506})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.2725619078     0.4506814480     1.7232433558     0.5351180782     0.5156080347     0.4598484848     24.1929793358   

========ROUND 116========
====Feature update====
epoch            class_loss      
0                1.4890718460    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6056587696     2.4867899418     0.1188688576    
Counter({0: 11499, 2: 9587, 1: 8386})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.2876790762     0.5324980617     1.8201770782     0.5867603149     0.5688110749     0.4768398268     24.2100677490   

========ROUND 117========
====Feature update====
epoch            class_loss      
0                1.5655642748    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7888889313     2.6191008091     0.1697880775    
Counter({0: 12223, 2: 9371, 1: 7878})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3814777136     0.6080236435     1.9895013571     0.5673181325     0.5409880565     0.4889610390     24.1498057842   

========ROUND 118========
====Feature update====
epoch            class_loss      
0                1.3364170790    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7983636856     2.6356489658     0.1627146453    
Counter({0: 12196, 2: 9010, 1: 8266})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.5068696737     0.5569993854     2.0638689995     0.5291802389     0.5073289902     0.4488095238     24.1949887276   

========ROUND 119========
====Feature update====
epoch            class_loss      
0                1.4248341322    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5533599854     2.4665393829     0.0868205354    
Counter({0: 12108, 2: 9195, 1: 8169})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.0409122705     0.5371251702     1.5780375004     0.6076615092     0.5868621064     0.4340909091     24.1298139095   
Target acc: 0.5122
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:0.0001
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
0                1.5637092590    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6149911880     2.6149713993     0.0000197444    
Counter({0: 19341, 1: 5146, 2: 4985})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3044060469     0.2755374312     1.5799434185     0.5161848534     0.4975570033     0.4063852814     24.2365958691   

========ROUND 1========
====Feature update====
epoch            class_loss      
0                1.3107260466    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5111057758     2.4130909443     0.0980148017    
Counter({0: 17783, 2: 5922, 1: 5767})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.3243726492     0.1519863158     1.4763590097     0.6535355592     0.6281216069     0.4811688312     24.1641438007   

========ROUND 2========
====Feature update====
epoch            class_loss      
0                1.1873111725    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5927913189     2.4270796776     0.1657116115    
Counter({0: 16990, 1: 6447, 2: 6035})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7818305492     0.2681472600     1.0499777794     0.7060260586     0.6673452769     0.5628787879     24.3451759815   

========ROUND 3========
====Feature update====
epoch            class_loss      
0                1.0307095051    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4080183506     2.3629419804     0.0450764298    
Counter({0: 16455, 1: 6540, 2: 6477})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.8702005744     0.2093812227     1.0795817375     0.7317114549     0.6867535288     0.5895021645     24.2848787308   

========ROUND 4========
====Feature update====
epoch            class_loss      
0                0.8791518807    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4306252003     2.3435494900     0.0870755985    
Counter({0: 16314, 1: 6859, 2: 6299})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6440563798     0.2056139857     0.8496703506     0.7385654180     0.6763029316     0.5946969697     24.9599909782   

========ROUND 5========
====Feature update====
epoch            class_loss      
0                1.0202528238    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4676053524     2.3912918568     0.0763134062    
Counter({0: 15660, 1: 7407, 2: 6405})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7932736278     0.1602190286     0.9534926414     0.7621471227     0.7098262758     0.6068181818     24.3024744987   

========ROUND 6========
====Feature update====
epoch            class_loss      
0                0.7867898345    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7393922806     2.4820349216     0.2573574185    
Counter({0: 15268, 1: 7682, 2: 6522})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7891064286     0.3133722842     1.1024787426     0.8161644951     0.7483713355     0.6335497835     24.1907014847   

========ROUND 7========
====Feature update====
epoch            class_loss      
0                0.7011455894    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5911352634     2.4449412823     0.1461939216    
Counter({0: 14942, 1: 7954, 2: 6576})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7108165622     0.2043566704     0.9151732326     0.8096498371     0.7472855592     0.6301948052     24.2163820267   

========ROUND 8========
====Feature update====
epoch            class_loss      
0                0.6485188603    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4249279499     2.3384885788     0.0864394084    
Counter({0: 15236, 1: 8099, 2: 6137})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7900774479     0.3612363040     1.1513137817     0.8028976656     0.7394136808     0.6495670996     24.1977031231   

========ROUND 9========
====Feature update====
epoch            class_loss      
0                0.8547430634    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4173300266     2.3488233089     0.0685067251    
Counter({0: 14845, 1: 8285, 2: 6342})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7272605300     0.1643680036     0.8916285038     0.8247489142     0.7502714441     0.6242424242     24.2267973423   

========ROUND 10========
====Feature update====
epoch            class_loss      
0                0.7404561639    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5035130978     2.3771693707     0.1263436973    
Counter({0: 14870, 1: 8184, 2: 6418})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6185988784     0.1807468981     0.7993457913     0.8236631379     0.7486427796     0.6390692641     24.1867537498   

========ROUND 11========
====Feature update====
epoch            class_loss      
0                0.6063978076    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4885435104     2.4068062305     0.0817373320    
Counter({0: 14925, 1: 8088, 2: 6459})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5504049063     0.1465616375     0.6969665289     0.8214576547     0.7407709012     0.6489177489     24.1091887951   

========ROUND 12========
====Feature update====
epoch            class_loss      
0                0.6683982015    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5736982822     2.4879407883     0.0857574344    
Counter({0: 14809, 1: 8241, 2: 6422})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.8000842929     0.4337008297     1.2337851524     0.8260043431     0.7432138979     0.6442640693     24.1516029835   

========ROUND 13========
====Feature update====
epoch            class_loss      
0                0.6703922153    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.3995623589     2.3538599014     0.0457025580    
Counter({0: 14748, 1: 8289, 2: 6435})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7344551086     0.2686868012     1.0031418800     0.8473466341     0.7566503800     0.6748917749     24.1039888859   

========ROUND 14========
====Feature update====
epoch            class_loss      
0                0.7870385051    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6082432270     2.5073530674     0.1008902490    
Counter({0: 14776, 1: 8397, 2: 6299})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5483153462     0.1973414421     0.7456567883     0.8521308360     0.7595005429     0.6743506494     24.3848612309   

========ROUND 15========
====Feature update====
epoch            class_loss      
0                0.6591508985    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4750573635     2.3709852695     0.1040722057    
Counter({0: 14759, 1: 8312, 2: 6401})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6911211014     0.3047656119     0.9958866835     0.8363870793     0.7441639522     0.6273809524     24.1467831135   

========ROUND 16========
====Feature update====
epoch            class_loss      
0                0.6036714315    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4216885567     2.3013684750     0.1203199700    
Counter({0: 14742, 1: 8409, 2: 6321})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6137792468     0.1990568787     0.8128361106     0.8324172096     0.7453854506     0.6562770563     24.1386351585   

========ROUND 17========
====Feature update====
epoch            class_loss      
0                0.7926282883    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5418169498     2.4832308292     0.0585861802    
Counter({0: 14349, 1: 8730, 2: 6393})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4001037180     0.3230398893     0.7231435776     0.8666530945     0.7741585233     0.6713203463     24.3569340706   

========ROUND 18========
====Feature update====
epoch            class_loss      
0                0.8346319795    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5035886765     2.4734189510     0.0301698148    
Counter({0: 14516, 1: 8605, 2: 6351})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7363638878     0.3536946774     1.0900585651     0.8411034202     0.7508143322     0.6547619048     24.2091395855   

========ROUND 19========
====Feature update====
epoch            class_loss      
0                0.5084621906    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6295044422     2.4793560505     0.1501483172    
Counter({0: 14697, 1: 8580, 2: 6195})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6426665187     0.3133298457     0.9559963942     0.8325529316     0.7368349620     0.6390692641     24.1630849838   

========ROUND 20========
====Feature update====
epoch            class_loss      
0                0.6522238851    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4489419460     2.4046821594     0.0442598127    
Counter({0: 14719, 1: 8568, 2: 6185})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5301160216     0.2775648832     0.8076809049     0.8814807275     0.7760586319     0.6661255411     24.1358795166   

========ROUND 21========
====Feature update====
epoch            class_loss      
0                0.5175670981    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5843484402     2.4838564396     0.1004921123    
Counter({0: 14063, 1: 8833, 2: 6576})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5804409385     0.2936938405     0.8741347790     0.8563721498     0.7524429967     0.6555194805     24.1435883045   

========ROUND 22========
====Feature update====
epoch            class_loss      
0                0.5327851176    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5087051392     2.4837746620     0.0249303635    
Counter({0: 14230, 1: 8754, 2: 6488})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5114385486     0.2660131156     0.7774516344     0.8396104777     0.7414495114     0.6506493506     24.3425681591   

========ROUND 23========
====Feature update====
epoch            class_loss      
0                0.4272145033    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6229126453     2.5659904480     0.0569221228    
Counter({0: 14188, 1: 8715, 2: 6569})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4351884127     0.3299245536     0.7651129961     0.8537255700     0.7501357220     0.6451298701     24.1136596203   

========ROUND 24========
====Feature update====
epoch            class_loss      
0                0.5398575664    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4131691456     2.3464658260     0.0667033568    
Counter({0: 14572, 1: 8509, 2: 6391})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5836089253     0.1592166871     0.7428256273     0.8580008143     0.7592290988     0.6759740260     24.2908890247   

========ROUND 25========
====Feature update====
epoch            class_loss      
0                0.7548181415    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.3826203346     2.3319852352     0.0506350659    
Counter({0: 14561, 1: 8506, 2: 6405})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5965167284     0.3200331926     0.9165499210     0.8401194354     0.7326275787     0.6196969697     24.1682910919   

========ROUND 26========
====Feature update====
epoch            class_loss      
0                0.4980724156    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5296664238     2.4814922810     0.0481740795    
Counter({0: 14659, 1: 8546, 2: 6267})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5997497439     0.2757476568     0.8754974008     0.8680442454     0.7661509229     0.6610389610     24.1150920391   

========ROUND 27========
====Feature update====
epoch            class_loss      
0                0.5685235858    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5514686108     2.4436450005     0.1078236327    
Counter({0: 14483, 1: 8839, 2: 6150})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7963910103     0.3507416248     1.1471326351     0.8594598263     0.7569218241     0.6517316017     24.1789529324   

========ROUND 28========
====Feature update====
epoch            class_loss      
0                0.8465108871    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5680563450     2.4484639168     0.1195925400    
Counter({0: 14655, 1: 8670, 2: 6147})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4412490427     0.3454636037     0.7867126465     0.8604777416     0.7607220413     0.6627705628     24.1378371716   

========ROUND 29========
====Feature update====
epoch            class_loss      
0                0.9979817867    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7810020447     2.5807206631     0.2002813667    
Counter({0: 14348, 1: 8898, 2: 6226})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5298253894     0.3977160156     0.9275413752     0.8720480456     0.7687296417     0.6516233766     24.1852757931   

========ROUND 30========
====Feature update====
epoch            class_loss      
0                0.6737151742    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5048837662     2.4699926376     0.0348911770    
Counter({0: 14332, 1: 9022, 2: 6118})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4023082554     0.2876052856     0.6899135113     0.8729641694     0.7607220413     0.6696969697     24.1743917465   

========ROUND 31========
====Feature update====
epoch            class_loss      
0                0.6843560338    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5528419018     2.4872162342     0.0656257048    
Counter({0: 14214, 1: 9093, 2: 6165})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6760854125     0.4175102711     1.0935957432     0.8647869164     0.7612649294     0.6594155844     24.2064304352   

========ROUND 32========
====Feature update====
epoch            class_loss      
0                0.3977824152    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5748038292     2.5273230076     0.0474808179    
Counter({0: 14242, 1: 9119, 2: 6111})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5412203670     0.1901331097     0.7313534617     0.8796145494     0.7633007600     0.6681818182     24.2145638466   

========ROUND 33========
====Feature update====
epoch            class_loss      
0                0.4130904675    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5501301289     2.3877189159     0.1624111384    
Counter({0: 14182, 1: 9125, 2: 6165})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.8204218745     0.2898982167     1.1103200912     0.8515540174     0.7460640608     0.6625541126     24.3100357056   

========ROUND 34========
====Feature update====
epoch            class_loss      
0                0.6038673520    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4754142761     2.4171221256     0.0582921803    
Counter({0: 14179, 1: 9188, 2: 6105})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5636644363     0.2339111567     0.7975755930     0.8528773073     0.7519001086     0.6336580087     24.1098790169   

========ROUND 35========
====Feature update====
epoch            class_loss      
0                0.6739351153    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5815303326     2.4899525642     0.0915777087    
Counter({0: 14354, 1: 9063, 2: 6055})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7020586133     0.3586796820     1.0607383251     0.8661780673     0.7580076004     0.6398268398     24.2064933777   

========ROUND 36========
====Feature update====
epoch            class_loss      
0                0.5947911143    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4018571377     2.3353259563     0.0665311143    
Counter({0: 14340, 1: 9147, 2: 5985})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4039912224     0.1541480273     0.5581392646     0.8710640608     0.7603148751     0.6449134199     24.1187748909   

========ROUND 37========
====Feature update====
epoch            class_loss      
0                0.5146153569    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6246385574     2.5712411404     0.0533973128    
Counter({0: 14328, 1: 9175, 2: 5969})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4898457527     0.2387238294     0.7285695672     0.8648547774     0.7494571118     0.6661255411     24.1433379650   

========ROUND 38========
====Feature update====
epoch            class_loss      
0                0.5887308717    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.3647222519     2.3038625717     0.0608596988    
Counter({0: 14709, 1: 9013, 2: 5750})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5003888607     0.2573607862     0.7577496767     0.8752035831     0.7627578719     0.6744588745     24.2365920544   

========ROUND 39========
====Feature update====
epoch            class_loss      
0                0.6743205190    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5130217075     2.4542267323     0.0587948598    
Counter({0: 14663, 1: 8902, 2: 5907})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4120881557     0.3205267191     0.7326148748     0.8817861021     0.7683224756     0.6886363636     24.1616299152   

========ROUND 40========
====Feature update====
epoch            class_loss      
0                0.6281610727    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5784873962     2.4985215664     0.0799657181    
Counter({0: 14594, 1: 8987, 2: 5891})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5271437168     0.1966421753     0.7237858772     0.8769679696     0.7679153094     0.6380952381     24.3132684231   

========ROUND 41========
====Feature update====
epoch            class_loss      
0                0.5412877798    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5579307079     2.5315971375     0.0263336003    
Counter({0: 14568, 1: 9073, 2: 5831})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3220586777     0.3341297209     0.6561883688     0.8538952226     0.7571932682     0.6471861472     24.2820749283   

========ROUND 42========
====Feature update====
epoch            class_loss      
0                0.5449720025    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5504236221     2.4702541828     0.0801694244    
Counter({0: 14689, 1: 8979, 2: 5804})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5009971261     0.3966297805     0.8976268768     0.8625135722     0.7551574376     0.6531385281     24.1650066376   

========ROUND 43========
====Feature update====
epoch            class_loss      
0                0.5964153409    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5696690083     2.5379836559     0.0316853561    
Counter({0: 14397, 1: 9095, 2: 5980})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3975323737     0.4542543590     0.8517867327     0.8839915852     0.7745656895     0.6672077922     24.1439609528   

========ROUND 44========
====Feature update====
epoch            class_loss      
0                0.5525955558    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6057116985     2.4550507069     0.1506608874    
Counter({0: 14599, 1: 9065, 2: 5808})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4327054322     0.3212656081     0.7539710402     0.8806324647     0.7713083605     0.6770562771     24.3103961945   

========ROUND 45========
====Feature update====
epoch            class_loss      
0                0.4766200483    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7479090691     2.7308266163     0.0170824900    
Counter({0: 14492, 1: 9010, 2: 5970})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6358295679     0.2772086263     0.9130381942     0.8947136265     0.7747014115     0.6838744589     24.3121087551   

========ROUND 46========
====Feature update====
epoch            class_loss      
0                0.7112974524    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5572793484     2.4890096188     0.0682696179    
Counter({0: 14422, 1: 9053, 2: 5997})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5147473216     0.2849567235     0.7997040749     0.8908455483     0.7763300760     0.6891774892     24.1493260860   

========ROUND 47========
====Feature update====
epoch            class_loss      
0                0.5256549120    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6229081154     2.5132052898     0.1097028926    
Counter({0: 14470, 1: 9106, 2: 5896})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4412733018     0.3644165695     0.8056898713     0.8874864278     0.7683224756     0.6912337662     24.1453073025   

========ROUND 48========
====Feature update====
epoch            class_loss      
0                0.5883070827    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4960372448     2.4413237572     0.0547134541    
Counter({0: 14569, 1: 9100, 2: 5803})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4202327430     0.4648993015     0.8851320744     0.8780198154     0.7626221498     0.6354978355     24.4463448524   

========ROUND 49========
====Feature update====
epoch            class_loss      
0                0.5448331833    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4178209305     2.3733193874     0.0445014387    
Traceback (most recent call last):
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\popen_spawn_win32.py", line 89, in __init__
    reduction.dump(process_obj, to_child)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\reduction.py", line 60, in dump
    ForkingPickler(file, protocol).dump(obj)
BrokenPipeError: [Errno 32] Broken pipe

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 99, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 56, in main
    algorithm.set_dlabel(train_loader)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 68, in set_dlabel
    iter_test = iter(loader)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 444, in __iter__
    return self._get_iterator()
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 390, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 1077, in __init__
    w.start()
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\process.py", line 112, in start
    self._popen = self._Popen(self)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 322, in _Popen
    return Popen(process_obj)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\popen_spawn_win32.py", line 89, in __init__
    reduction.dump(process_obj, to_child)
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:1e-05
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
0                1.4113305807    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5491721630     2.5491704941     0.0000016118    
Counter({0: 21702, 1: 5148, 2: 2622})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.1784845591     0.1677416116     1.3462262154     0.5492331705     0.5301302932     0.4127705628     25.0014739037   

========ROUND 1========
====Feature update====
epoch            class_loss      
0                1.2309918404    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.2025175095     2.1394715309     0.0630458668    
Counter({0: 20616, 1: 6002, 2: 2854})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.2719976902     0.2753049433     1.5473026037     0.6646986971     0.6372149837     0.5175324675     25.1599044800   

========ROUND 2========
====Feature update====
epoch            class_loss      
0                1.2218555212    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4609298706     2.4049942493     0.0559356846    
Counter({0: 20423, 1: 6073, 2: 2976})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6915774345     0.2230378985     0.9146153331     0.6927252986     0.6497014115     0.5520562771     25.0059573650   

========ROUND 3========
====Feature update====
epoch            class_loss      
0                0.9787246585    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.3777179718     2.3454611301     0.0322568193    
Counter({0: 20311, 1: 6089, 2: 3072})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.8360258937     0.2836592495     1.1196851730     0.7210912052     0.6606948969     0.5595238095     24.9959924221   

========ROUND 4========
====Feature update====
epoch            class_loss      
0                0.7059726119    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4264981747     2.2922801971     0.1342179924    
Counter({0: 20037, 1: 6219, 2: 3216})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6012148261     0.0786379725     0.6798527837     0.7550556460     0.6900108578     0.6196969697     25.1424231529   

========ROUND 5========
====Feature update====
epoch            class_loss      
0                0.8614211679    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.2789354324     2.2462651730     0.0326701887    
Counter({0: 19292, 1: 6612, 2: 3568})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7898299694     0.0901800916     0.8800100684     0.7628596634     0.7052117264     0.6490259740     25.0648801327   

========ROUND 6========
====Feature update====
epoch            class_loss      
0                0.9483342171    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4124944210     2.3809964657     0.0314978659    
Counter({0: 18984, 1: 6701, 2: 3787})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7219242454     0.1416129917     0.8635372519     0.7962472856     0.7193268187     0.6343073593     25.0626890659   

========ROUND 7========
====Feature update====
epoch            class_loss      
0                0.5424703956    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4677903652     2.3753788471     0.0924114585    
Counter({0: 17869, 1: 7382, 2: 4221})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.8416666985     0.3925442696     1.2342109680     0.8290580890     0.7486427796     0.6464285714     25.1264727116   

========ROUND 8========
====Feature update====
epoch            class_loss      
0                0.5259312987    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4732697010     2.3238155842     0.1494541317    
Counter({0: 17490, 1: 7357, 2: 4625})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7273788452     0.2358736843     0.9632525444     0.8034744843     0.7357491857     0.6361471861     25.1075582504   

========ROUND 9========
====Feature update====
epoch            class_loss      
0                0.8200232983    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6390423775     2.4645946026     0.1744478494    
Counter({0: 16852, 1: 7907, 2: 4713})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6497717500     0.2942528427     0.9440245628     0.8222380565     0.7417209555     0.6282467532     25.9818377495   

========ROUND 10========
====Feature update====
epoch            class_loss      
0                0.8681018949    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4624488354     2.4165990353     0.0458498299    
Counter({0: 16835, 1: 7796, 2: 4841})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5778667331     0.1321538836     0.7100206017     0.8492467427     0.7626221498     0.6391774892     24.5035197735   

========ROUND 11========
====Feature update====
epoch            class_loss      
0                0.8082206845    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6178934574     2.5317521095     0.0861413181    
Counter({0: 16865, 1: 7618, 2: 4989})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5170131326     0.2598342001     0.7768473625     0.8466340934     0.7523072747     0.6489177489     24.4091765881   

========ROUND 12========
====Feature update====
epoch            class_loss      
0                0.7119493484    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6242940426     2.4999828339     0.1243112087    
Counter({0: 16770, 1: 7647, 2: 5055})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6888307929     0.2797158062     0.9685466290     0.8350298588     0.7504071661     0.6417748918     24.6740248203   

========ROUND 13========
====Feature update====
epoch            class_loss      
0                0.5539110899    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6840307713     2.5611717701     0.1228589416    
Counter({0: 16748, 1: 7408, 2: 5316})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6052269340     0.2389838248     0.8442107439     0.8449375679     0.7521715527     0.6670995671     24.0477249622   

========ROUND 14========
====Feature update====
epoch            class_loss      
0                0.4774124622    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.3928518295     2.3546011448     0.0382506289    
Counter({0: 16518, 1: 7583, 2: 5371})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6509056091     0.2441072464     0.8950128555     0.8317385993     0.7433496200     0.6142857143     24.0617511272   

========ROUND 15========
====Feature update====
epoch            class_loss      
0                0.6659194231    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5617251396     2.4433362484     0.1183887795    
Counter({0: 16540, 1: 7519, 2: 5413})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4747174978     0.2503651381     0.7250826359     0.8723873507     0.7643865364     0.6435064935     24.1265447140   

========ROUND 16========
====Feature update====
epoch            class_loss      
0                0.7281396389    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5195653439     2.4631469250     0.0564183332    
Counter({0: 16751, 1: 7133, 2: 5588})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6644272208     0.3983399868     1.0627672672     0.8617331705     0.7551574376     0.6545454545     24.1275045872   

========ROUND 17========
====Feature update====
epoch            class_loss      
0                0.7230973840    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6971561909     2.5591809750     0.1379751265    
Counter({0: 16077, 1: 7693, 2: 5702})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3124360144     0.3096348047     0.6220707893     0.8747964169     0.7657437568     0.6480519481     24.0954554081   

========ROUND 18========
====Feature update====
epoch            class_loss      
0                0.5254145265    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6459126472     2.5642888546     0.0816238001    
Counter({0: 15153, 1: 8514, 2: 5805})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6221122742     0.3628742695     0.9849865437     0.8716408795     0.7634364821     0.6603896104     24.1922991276   

========ROUND 19========
====Feature update====
epoch            class_loss      
0                0.6767406464    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5365955830     2.4434001446     0.0931953862    
Counter({0: 14097, 1: 9370, 2: 6005})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5660648942     0.3995988071     0.9656636715     0.8763911509     0.7633007600     0.6481601732     24.1317424774   

========ROUND 20========
====Feature update====
epoch            class_loss      
0                0.6799128652    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5932934284     2.4583842754     0.1349091232    
Counter({0: 12985, 1: 9908, 2: 6579})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5086594224     0.4187954962     0.9274549484     0.8832451140     0.7687296417     0.6331168831     24.0743708611   

========ROUND 21========
====Feature update====
epoch            class_loss      
0                0.5887519121    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5544967651     2.4708340168     0.0836628005    
Counter({0: 12621, 1: 9982, 2: 6869})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4501344264     0.4336770475     0.8838114738     0.8824307818     0.7719869707     0.6415584416     25.0313141346   

========ROUND 22========
====Feature update====
epoch            class_loss      
0                0.5300646424    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7526390553     2.6199839115     0.1326552480    
Counter({0: 12301, 1: 10047, 2: 7124})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5338290334     0.4598404169     0.9936694503     0.8712337134     0.7612649294     0.6469696970     24.0069978237   

========ROUND 23========
====Feature update====
epoch            class_loss      
0                0.6414744258    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7364401817     2.5177526474     0.2186874747    
Counter({0: 11745, 1: 10613, 2: 7114})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4102519453     0.5735575557     0.9838094711     0.8929831705     0.7706297503     0.6518398268     24.0908589363   

========ROUND 24========
====Feature update====
epoch            class_loss      
0                0.5653211474    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5909881592     2.4870853424     0.1039029285    
Counter({1: 11620, 0: 10854, 2: 6998})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5653150678     0.5941501260     1.1594651937     0.8825665038     0.7677795874     0.6643939394     24.1468505859   

========ROUND 25========
====Feature update====
epoch            class_loss      
0                0.5474699736    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6761586666     2.5883615017     0.0877972767    
Counter({1: 11479, 0: 10752, 2: 7241})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4503196776     0.5505893826     1.0009090900     0.8817521716     0.7600434311     0.6408008658     24.0800781250   

========ROUND 26========
====Feature update====
epoch            class_loss      
0                0.6748437285    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7471773624     2.6469655037     0.1002117768    
Counter({1: 11042, 0: 11024, 2: 7406})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5806774497     0.5003464818     1.0810239315     0.8972584148     0.7766015201     0.6615800866     24.1383109093   

========ROUND 27========
====Feature update====
epoch            class_loss      
0                0.6521807909    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7199656963     2.5538296700     0.1661361307    
Counter({1: 11357, 0: 10921, 2: 7194})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6048457026     0.5359497666     1.1407954693     0.8904044517     0.7679153094     0.6686147186     24.2021427155   

========ROUND 28========
====Feature update====
epoch            class_loss      
0                0.8500149250    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8238725662     2.6382706165     0.1856019497    
Counter({1: 11522, 0: 10689, 2: 7261})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3753988445     0.5268579125     0.9022567272     0.8987513572     0.7764657980     0.6555194805     24.2066683769   

========ROUND 29========
====Feature update====
epoch            class_loss      
0                0.7187736630    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.9823977947     2.6838636398     0.2985342145    
Counter({1: 11783, 0: 10389, 2: 7300})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4232874811     0.4980633557     0.9213508368     0.9050285016     0.7846091205     0.6584415584     24.0847368240   

========ROUND 30========
====Feature update====
epoch            class_loss      
0                0.5763960481    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6368753910     2.5692231655     0.0676521212    
Counter({1: 12089, 0: 10331, 2: 7052})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3171359897     0.5486614108     0.8657974005     0.8994638979     0.7706297503     0.6679653680     24.2038581371   

========ROUND 31========
====Feature update====
epoch            class_loss      
0                0.6124186516    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8053743839     2.6711778641     0.1341965646    
Counter({1: 11838, 0: 10424, 2: 7210})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4337007999     0.5402339101     0.9739347100     0.9008550489     0.7711726384     0.6497835498     24.0131909847   

========ROUND 32========
====Feature update====
epoch            class_loss      
0                0.4646001160    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7744374275     2.6809368134     0.0935005844    
Counter({1: 11850, 0: 10300, 2: 7322})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4065990150     0.5780011415     0.9846001863     0.9032641151     0.7749728556     0.6602813853     24.8249523640   

========ROUND 33========
====Feature update====
epoch            class_loss      
0                0.5847490430    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6077096462     2.4853086472     0.1224010810    
Counter({1: 11487, 0: 10577, 2: 7408})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4689941108     0.6704779267     1.1394720078     0.9074036374     0.7690010858     0.6544372294     24.0099315643   

========ROUND 34========
====Feature update====
epoch            class_loss      
0                0.4453594685    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6641190052     2.5383269787     0.1257919967    
Counter({1: 12498, 0: 9693, 2: 7281})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4468840361     0.6957025528     1.1425865889     0.8909812704     0.7642508143     0.6385281385     24.1408195496   

========ROUND 35========
====Feature update====
epoch            class_loss      
0                0.7647406459    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7368178368     2.6062481403     0.1305697411    
Counter({1: 12071, 0: 10002, 2: 7399})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5885378718     0.6908418536     1.2793797255     0.9136129207     0.7756514658     0.6496753247     24.6606314182   

========ROUND 36========
====Feature update====
epoch            class_loss      
0                0.5392710567    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5949163437     2.5046827793     0.0902335569    
Counter({1: 11595, 0: 10310, 2: 7567})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3510404527     0.4789198637     0.8299603462     0.8869435396     0.7600434311     0.6406926407     24.1910910606   

========ROUND 37========
====Feature update====
epoch            class_loss      
0                0.3591150939    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7651107311     2.6916463375     0.0734644458    
Counter({1: 11332, 0: 10535, 2: 7605})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3991975784     0.5076341629     0.9068317413     0.9023140608     0.7694082519     0.6655844156     24.1981618404   

========ROUND 38========
====Feature update====
epoch            class_loss      
0                0.5945835114    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7136940956     2.6271595955     0.0865344405    
Counter({1: 11549, 0: 10765, 2: 7158})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3821717203     0.4811836779     0.8633553982     0.9066232356     0.7738870793     0.6785714286     24.1036369801   

========ROUND 39========
====Feature update====
epoch            class_loss      
0                0.5208224654    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6537575722     2.5766015053     0.0771560520    
Counter({1: 11264, 0: 10779, 2: 7429})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3335151374     0.6285412312     0.9620563984     0.9206704669     0.7847448426     0.6761904762     24.1371662617   

========ROUND 40========
====Feature update====
epoch            class_loss      
0                0.4210762680    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7097206116     2.6315999031     0.0781207457    
Counter({1: 11829, 0: 10521, 2: 7122})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3842511177     0.4581276476     0.8423787355     0.9203650923     0.7752442997     0.6623376623     24.0821905136   

========ROUND 41========
====Feature update====
epoch            class_loss      
0                0.3526630104    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6862931252     2.5645298958     0.1217632592    
Counter({1: 12256, 0: 10022, 2: 7194})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2638559043     0.4867745936     0.7506304979     0.9061142780     0.7721226927     0.6542207792     24.1831982136   

========ROUND 42========
====Feature update====
epoch            class_loss      
0                0.4610665143    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6548361778     2.5264871120     0.1283491552    
Counter({1: 11680, 0: 10328, 2: 7464})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3266523778     0.4475379288     0.7741903067     0.9144611835     0.7703583062     0.6668831169     24.1305279732   

========ROUND 43========
====Feature update====
epoch            class_loss      
0                0.4658856094    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.9001636505     2.6775627136     0.2226010412    
Counter({1: 11479, 0: 10319, 2: 7674})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3265021443     0.5497226715     0.8762248158     0.9116110206     0.7798588491     0.6506493506     24.0852096081   

========ROUND 44========
====Feature update====
epoch            class_loss      
0                0.6150268912    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5417401791     2.4391925335     0.1025475487    
Counter({1: 11585, 0: 9942, 2: 7945})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2773503065     0.5448164940     0.8221668005     0.9243010315     0.7844733985     0.6681818182     24.1197166443   

========ROUND 45========
====Feature update====
epoch            class_loss      
0                0.4275420904    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4712541103     2.4114134312     0.0598406903    
Counter({1: 11151, 0: 10063, 2: 8258})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5005230904     0.4425290823     0.9430521727     0.9118146037     0.7732084691     0.6575757576     24.1299600601   

========ROUND 46========
====Feature update====
epoch            class_loss      
0                0.4765376747    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4281065464     2.3594779968     0.0686284378    
Counter({1: 11485, 0: 9522, 2: 8465})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5835292935     0.4732503891     1.0567796230     0.9180917481     0.7801302932     0.6566017316     24.1783866882   

========ROUND 47========
====Feature update====
epoch            class_loss      
0                0.5265207887    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5807151794     2.3899109364     0.1908041984    
Counter({1: 10929, 0: 9350, 2: 9193})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3476004601     0.6045752168     0.9521756768     0.9253868078     0.7816232356     0.6745670996     24.1169888973   

========ROUND 48========
====Feature update====
epoch            class_loss      
0                0.5875456929    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5791530609     2.4418494701     0.1373036355    
Counter({1: 10949, 0: 9507, 2: 9016})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2281128615     0.6371037364     0.8652166128     0.9156148208     0.7747014115     0.6596320346     24.0239219666   

========ROUND 49========
====Feature update====
epoch            class_loss      
0                0.3898900449    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5797464848     2.5031201839     0.0766263083    
Counter({1: 11113, 2: 9192, 0: 9167})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3108060658     0.5950612426     0.9058673382     0.9296959826     0.7836590662     0.6707792208     24.3042380810   

========ROUND 50========
====Feature update====
epoch            class_loss      
0                0.4295184910    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5684812069     2.4684188366     0.1000624597    
Counter({1: 10902, 0: 9287, 2: 9283})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3194190562     0.6486521959     0.9680712223     0.9270833333     0.7797231270     0.6716450216     24.4178416729   

========ROUND 51========
====Feature update====
epoch            class_loss      
0                0.7676210403    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4759464264     2.4166545868     0.0592917204    
Counter({1: 11014, 2: 9492, 0: 8966})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6038824916     0.5478158593     1.1516983509     0.9346498371     0.7878664495     0.6681818182     24.2384696007   

========ROUND 52========
====Feature update====
epoch            class_loss      
0                0.5042491555    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6587634087     2.5645177364     0.0942455828    
Counter({1: 10899, 0: 9423, 2: 9150})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3339515924     0.6892442107     1.0231957436     0.9254207383     0.7782301846     0.6792207792     24.1167769432   

========ROUND 53========
====Feature update====
epoch            class_loss      
0                0.4575569630    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7922527790     2.6341817379     0.1580711156    
Counter({1: 10634, 2: 9705, 0: 9133})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3922924995     0.4784808159     0.8707733154     0.9324443540     0.7820304017     0.6758658009     24.2163705826   

========ROUND 54========
====Feature update====
epoch            class_loss      
0                0.5413751006    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5660548210     2.4288609028     0.1371939927    
Counter({1: 10640, 2: 10037, 0: 8795})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2041418701     0.6462871432     0.8504289985     0.9347516287     0.7881378936     0.6791125541     24.2206368446   

========ROUND 55========
====Feature update====
epoch            class_loss      
0                0.6398332715    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8063242435     2.6004827023     0.2058414966    
Counter({2: 10933, 1: 10253, 0: 8286})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3925165832     0.8047506809     1.1972672939     0.9292548860     0.7837947883     0.6624458874     24.1811201572   

========ROUND 56========
====Feature update====
epoch            class_loss      
0                0.3242061436    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8098402023     2.6874454021     0.1223946884    
Counter({2: 11390, 1: 9879, 0: 8203})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4602544308     0.5691383481     1.0293927193     0.9153433768     0.7734799131     0.6475108225     24.1834259033   

========ROUND 57========
====Feature update====
epoch            class_loss      
0                0.5958920717    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5874633789     2.5038208961     0.0836425424    
Counter({2: 11304, 1: 9926, 0: 8242})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3201945722     0.5612457395     0.8814402819     0.9175149294     0.7757871878     0.6680735931     24.2818374634   

========ROUND 58========
====Feature update====
epoch            class_loss      
0                0.4379213750    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6673908234     2.5650136471     0.1023771390    
Counter({2: 11777, 1: 9770, 0: 7925})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2665036619     0.5390205979     0.8055242300     0.9263707926     0.7817589577     0.6656926407     24.2194499969   

========ROUND 59========
====Feature update====
epoch            class_loss      
0                0.3779992163    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7130913734     2.6090536118     0.1040378138    
Counter({2: 11997, 1: 9379, 0: 8096})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2714731395     0.5277137160     0.7991868258     0.9329533116     0.7810803474     0.6767316017     24.2888529301   

========ROUND 60========
====Feature update====
epoch            class_loss      
0                0.6558352113    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7692534924     2.6826355457     0.0866179243    
Counter({2: 11960, 1: 9356, 0: 8156})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3593955338     0.5372421145     0.8966376781     0.9310192725     0.7843376764     0.6768398268     24.2182881832   

========ROUND 61========
====Feature update====
epoch            class_loss      
0                0.3775236607    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8382427692     2.6514625549     0.1867802292    
Counter({2: 12144, 1: 9429, 0: 7899})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2699178755     0.5569625497     0.8268804550     0.9252510858     0.7793159609     0.6664502165     24.8618314266   

========ROUND 62========
====Feature update====
epoch            class_loss      
0                0.3750217855    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7862949371     2.6916620731     0.0946329609    
Counter({2: 11402, 1: 9529, 0: 8541})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3836804628     0.5989507437     0.9826312065     0.9424538545     0.7871878393     0.6799783550     23.9281597137   

========ROUND 63========
====Feature update====
epoch            class_loss      
0                0.4982790053    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8179934025     2.6049020290     0.2130914778    
Counter({2: 11197, 1: 9626, 0: 8649})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2934967577     0.7760561109     1.0695528984     0.9310192725     0.7782301846     0.6610389610     24.0469238758   

========ROUND 64========
====Feature update====
epoch            class_loss      
0                0.7166920304    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7905607224     2.6450831890     0.1454774886    
Counter({2: 10977, 1: 9440, 0: 9055})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3150916398     0.5948459506     0.9099376202     0.9231813246     0.7741585233     0.6834415584     23.9651219845   

========ROUND 65========
====Feature update====
epoch            class_loss      
0                0.4588736296    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6924471855     2.5992419720     0.0932053253    
Counter({2: 11494, 1: 9450, 0: 8528})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2181702405     0.5315442681     0.7497144938     0.9161577090     0.7709011944     0.6656926407     23.9120111465   

========ROUND 66========
====Feature update====
epoch            class_loss      
0                0.3894305229    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6974089146     2.6027860641     0.0946228281    
Counter({2: 11499, 1: 9272, 0: 8701})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4043705165     0.5730882287     0.9774587154     0.9268797503     0.7780944625     0.6617965368     23.9795780182   

========ROUND 67========
====Feature update====
epoch            class_loss      
0                0.4117927253    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8131465912     2.6671037674     0.1460427791    
Counter({2: 11518, 1: 9280, 0: 8674})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5325889587     0.7696070671     1.3021960258     0.9313585776     0.7809446254     0.6820346320     23.9858453274   

========ROUND 68========
====Feature update====
epoch            class_loss      
0                0.5940369368    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7485566139     2.6479494572     0.1006071791    
Counter({2: 11400, 1: 9487, 0: 8585})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3622473776     0.6117153168     0.9739626646     0.9339372964     0.7836590662     0.6833333333     23.9926657677   

========ROUND 69========
====Feature update====
epoch            class_loss      
0                0.3456135690    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6809852123     2.5791680813     0.1018172130    
Counter({2: 11240, 1: 9476, 0: 8756})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2279207110     0.4447106421     0.6726313829     0.9418431053     0.7859663409     0.6783549784     23.8714928627   

========ROUND 70========
====Feature update====
epoch            class_loss      
0                0.4293191433    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6942706108     2.5877664089     0.1065042615    
Counter({2: 11449, 1: 9709, 0: 8314})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4667080939     0.5602392554     1.0269473791     0.9321729099     0.7820304017     0.6728354978     24.1339280605   

========ROUND 71========
====Feature update====
epoch            class_loss      
0                0.2480831295    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7843914032     2.6680910587     0.1163002253    
Counter({2: 11415, 1: 9491, 0: 8566})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2549451590     0.5801661015     0.8351112604     0.9359731270     0.7813517915     0.6624458874     23.9814376831   

========ROUND 72========
====Feature update====
epoch            class_loss      
0                0.4083526433    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6900346279     2.5929195881     0.0971149281    
Counter({2: 11568, 1: 9615, 0: 8289})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2701479197     0.7371299863     1.0072779655     0.9285084148     0.7759229099     0.6572510823     24.0676474571   

========ROUND 73========
====Feature update====
epoch            class_loss      
0                0.3234480917    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7833354473     2.6352651119     0.1480704397    
Counter({2: 11436, 1: 9537, 0: 8499})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3499487936     0.4913434088     0.8412922025     0.9414698697     0.7823018458     0.6839826840     23.9355421066   

========ROUND 74========
====Feature update====
epoch            class_loss      
0                0.3148912489    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7542936802     2.6479873657     0.1063063443    
Counter({2: 11285, 1: 9578, 0: 8609})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3398747444     0.5715845823     0.9114593267     0.9325800760     0.7786373507     0.6703463203     23.9452431202   

========ROUND 75========
====Feature update====
epoch            class_loss      
0                0.3891254961    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6472783089     2.5800094604     0.0672689304    
Counter({2: 11011, 1: 9720, 0: 8741})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2445316762     0.5760073066     0.8205389977     0.9305442454     0.7732084691     0.6658008658     23.8541843891   

========ROUND 76========
====Feature update====
epoch            class_loss      
0                0.6864356399    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7978506088     2.6311662197     0.1666842848    
Counter({2: 10991, 1: 9446, 0: 9035})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4916590154     0.5128355026     1.0044945478     0.9395019001     0.7858306189     0.6674242424     24.0258588791   

========ROUND 77========
====Feature update====
epoch            class_loss      
0                0.2755688727    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7218105793     2.5643484592     0.1574621350    
Counter({2: 10862, 0: 9307, 1: 9303})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4034079015     0.5954677463     0.9988756180     0.9341069490     0.7771444083     0.6700216450     24.5368180275   

========ROUND 78========
====Feature update====
epoch            class_loss      
0                0.3994104564    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6889317036     2.5986750126     0.0902567804    
Counter({2: 10931, 1: 9489, 0: 9052})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2773542106     0.5140548348     0.7914090157     0.9451004343     0.7911237785     0.6748917749     24.3947710991   

========ROUND 79========
====Feature update====
epoch            class_loss      
0                0.3176493347    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7555298805     2.6575949192     0.0979350507    
Counter({2: 11088, 0: 9226, 1: 9158})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3714100122     0.5010858178     0.8724958301     0.9341408795     0.7810803474     0.6753246753     24.3322184086   

========ROUND 80========
====Feature update====
epoch            class_loss      
0                0.2962521613    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7869930267     2.5790319443     0.2079609632    
Counter({2: 10870, 1: 9468, 0: 9134})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5560178161     0.6635910869     1.2196089029     0.9331229642     0.7748371336     0.6836580087     24.2912645340   

========ROUND 81========
====Feature update====
epoch            class_loss      
0                0.4225839674    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6425864697     2.5810062885     0.0615800656    
Counter({2: 10736, 1: 9644, 0: 9092})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4636554718     0.5230292678     0.9866847396     0.9422502714     0.7804017372     0.6741341991     24.2769310474   

========ROUND 82========
====Feature update====
epoch            class_loss      
0                0.2490063757    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6976816654     2.6587345600     0.0389470570    
Counter({2: 10529, 0: 9551, 1: 9392})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3503905833     0.6507866979     1.0011773109     0.9368892508     0.7809446254     0.6579004329     24.6936917305   

========ROUND 83========
====Feature update====
epoch            class_loss      
0                0.3188367188    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6431381702     2.5932912827     0.0498469137    
Counter({2: 10642, 0: 9616, 1: 9214})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2952578366     0.4961942434     0.7914520502     0.9253528773     0.7673724213     0.6632034632     24.0988979340   

========ROUND 84========
====Feature update====
epoch            class_loss      
0                0.3921604455    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7290723324     2.5490920544     0.1799802780    
Counter({2: 10676, 0: 9685, 1: 9111})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3791657686     0.5071483850     0.8863141537     0.9208401194     0.7671009772     0.6613636364     23.9981148243   

========ROUND 85========
====Feature update====
epoch            class_loss      
0                0.1804105490    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6274063587     2.5626981258     0.0647082701    
Counter({2: 10523, 0: 10172, 1: 8777})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3549429476     0.4852353334     0.8401782513     0.9384161238     0.7771444083     0.6770562771     24.5578598976   

========ROUND 86========
====Feature update====
epoch            class_loss      
0                0.4876078665    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7924129963     2.6276614666     0.1647515297    
Counter({2: 10601, 0: 10030, 1: 8841})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3757295609     0.8610207438     1.2367503643     0.9393661781     0.7847448426     0.6699134199     24.4684879780   

========ROUND 87========
====Feature update====
epoch            class_loss      
0                0.2619878352    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7326390743     2.6681487560     0.0644903257    
Counter({2: 10490, 0: 10023, 1: 8959})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2170038372     0.5314906836     0.7484945059     0.9392304560     0.7802660152     0.6653679654     24.5798857212   

========ROUND 88========
====Feature update====
epoch            class_loss      
0                0.2965283096    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8275713921     2.6555538177     0.1720176488    
Counter({2: 10258, 0: 10231, 1: 8983})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3747046292     0.5921201110     0.9668247700     0.9390608035     0.7778230185     0.6610389610     24.7092940807   

========ROUND 89========
====Feature update====
epoch            class_loss      
0                0.2759552896    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6753802299     2.6214897633     0.0538904630    
Counter({0: 10589, 2: 10083, 1: 8800})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3469554484     0.5351075530     0.8820630312     0.9446593377     0.7768729642     0.6744588745     24.4091334343   

========ROUND 90========
====Feature update====
epoch            class_loss      
0                0.5030139089    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6719164848     2.5931751728     0.0787413940    
Counter({0: 10565, 2: 10182, 1: 8725})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3346847594     0.6758756042     1.0105603933     0.9425217155     0.7766015201     0.6812770563     24.4557991028   

========ROUND 91========
====Feature update====
epoch            class_loss      
0                0.4836484492    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6650536060     2.5690977573     0.0959558412    
Counter({0: 10908, 2: 10002, 1: 8562})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2769287229     0.5766394734     0.8535681963     0.9477130836     0.7866449511     0.6735930736     24.0383481979   

========ROUND 92========
====Feature update====
epoch            class_loss      
0                0.2591603398    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7626099586     2.6355915070     0.1270183325    
Counter({0: 10900, 2: 9951, 1: 8621})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3870555162     0.5602900386     0.9473455548     0.9329533116     0.7711726384     0.6599567100     24.3269510269   

========ROUND 93========
====Feature update====
epoch            class_loss      
0                0.4068953693    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7144823074     2.6526446342     0.0618377179    
Counter({0: 10646, 2: 10177, 1: 8649})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2260121852     0.6433795094     0.8693916798     0.9438450054     0.7867806732     0.6660173160     24.3272707462   

========ROUND 94========
====Feature update====
epoch            class_loss      
0                0.3514759243    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6950790882     2.6180534363     0.0770255551    
Counter({0: 11002, 2: 9843, 1: 8627})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1664312333     0.4962700605     0.6627013087     0.9394679696     0.7723941368     0.6621212121     24.1628110409   

========ROUND 95========
====Feature update====
epoch            class_loss      
0                0.4363745153    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6023414135     2.5446014404     0.0577399246    
Counter({0: 10670, 2: 10059, 1: 8743})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3007638454     0.6322863698     0.9330502152     0.9430985342     0.7837947883     0.6759740260     24.1118955612   

========ROUND 96========
====Feature update====
epoch            class_loss      
0                0.3236129582    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6047494411     2.5648174286     0.0399320759    
Counter({0: 10646, 2: 10197, 1: 8629})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5201271176     0.6443402767     1.1644673347     0.9271511944     0.7681867535     0.6590909091     24.0978643894   

========ROUND 97========
====Feature update====
epoch            class_loss      
0                0.5738243461    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7446813583     2.5979063511     0.1467750669    
Counter({0: 10648, 2: 10279, 1: 8545})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2711934745     0.5633486509     0.8345421553     0.9435057003     0.7785016287     0.6743506494     24.0983350277   

========ROUND 98========
====Feature update====
epoch            class_loss      
0                0.3480475843    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6816036701     2.6051840782     0.0764196590    
Counter({0: 11023, 2: 10032, 1: 8417})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2606359720     0.5965254903     0.8571614623     0.9416734528     0.7742942454     0.6622294372     24.3561160564   

========ROUND 99========
====Feature update====
epoch            class_loss      
0                0.3268188238    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.9312911034     2.7685317993     0.1627593189    
Counter({0: 11017, 2: 10103, 1: 8352})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3275258839     0.5986115932     0.9261374474     0.9314603692     0.7729370250     0.6586580087     24.3711175919   

========ROUND 100========
====Feature update====
epoch            class_loss      
0                0.5496939421    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6943733692     2.6211931705     0.0731802657    
Counter({0: 11244, 2: 10012, 1: 8216})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2876162827     0.6417469978     0.9293632507     0.9422502714     0.7785016287     0.6687229437     24.3876204491   

========ROUND 101========
====Feature update====
epoch            class_loss      
0                0.4553429186    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8356068134     2.7506601810     0.0849466845    
Counter({0: 11283, 2: 9941, 1: 8248})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2649540007     0.5819565654     0.8469105959     0.9308835505     0.7691368078     0.6619047619     24.4178981781   

========ROUND 102========
====Feature update====
epoch            class_loss      
0                0.8020923138    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7218210697     2.6032574177     0.1185636222    
Counter({0: 11052, 2: 9845, 1: 8575})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3311297894     0.5988475680     0.9299773574     0.9384839848     0.7745656895     0.6717532468     24.3283829689   

========ROUND 103========
====Feature update====
epoch            class_loss      
0                0.2859421372    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6511189938     2.5587437153     0.0923752561    
Counter({0: 10998, 2: 10080, 1: 8394})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4349625409     0.5908227563     1.0257853270     0.9477130836     0.7791802389     0.6833333333     24.3049774170   

========ROUND 104========
====Feature update====
epoch            class_loss      
0                0.4475880563    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6250884533     2.5298626423     0.0952256992    
Counter({0: 11135, 2: 9907, 1: 8430})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3483605385     0.5783261657     0.9266867042     0.9393661781     0.7757871878     0.6612554113     24.2279400826   

========ROUND 105========
====Feature update====
epoch            class_loss      
0                0.3654239476    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7154438496     2.6625983715     0.0528455228    
Counter({0: 11296, 2: 9912, 1: 8264})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2063518912     0.5181064010     0.7244582772     0.9308835505     0.7780944625     0.6617965368     24.3563804626   

========ROUND 106========
====Feature update====
epoch            class_loss      
0                0.4668048322    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6340939999     2.5982532501     0.0358408578    
Counter({0: 11155, 2: 10067, 1: 8250})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2926972210     0.8121604323     1.1048576832     0.9363124321     0.7744299674     0.6675324675     24.2416360378   

========ROUND 107========
====Feature update====
epoch            class_loss      
0                0.3507852852    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7137877941     2.6272912025     0.0864966735    
Counter({0: 11511, 2: 9767, 1: 8194})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4240694940     0.5960897207     1.0201592445     0.9305103149     0.7728013029     0.6649350649     24.3392198086   

========ROUND 108========
====Feature update====
epoch            class_loss      
0                0.5149777532    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8477017879     2.6671259403     0.1805758476    
Counter({0: 11590, 2: 9863, 1: 8019})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2742144465     0.5310116410     0.8052260876     0.9451343648     0.7778230185     0.6859307359     24.4232339859   

========ROUND 109========
====Feature update====
epoch            class_loss      
0                0.3721275330    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4855377674     2.4472644329     0.0382732563    
Counter({0: 11403, 2: 9889, 1: 8180})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2345452905     0.6639969945     0.8985422850     0.9378732356     0.7749728556     0.6622294372     24.1794819832   

========ROUND 110========
====Feature update====
epoch            class_loss      
0                0.4481630325    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7815828323     2.5438189507     0.2377638072    
Counter({0: 11260, 2: 9980, 1: 8232})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2876576483     0.4960621297     0.7837197781     0.9394001086     0.7711726384     0.6660173160     24.2647655010   

========ROUND 111========
====Feature update====
epoch            class_loss      
0                0.6784070134    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6076881886     2.5654881001     0.0422000475    
Counter({0: 11745, 2: 9575, 1: 8152})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3247255385     0.5283435583     0.8530690670     0.9458469055     0.7816232356     0.6738095238     24.1962168217   

========ROUND 112========
====Feature update====
epoch            class_loss      
0                0.4335859716    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6600942612     2.5856111050     0.0744830891    
Counter({0: 11503, 2: 9682, 1: 8287})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2538418472     0.5655207634     0.8193626404     0.9183631922     0.7612649294     0.6635281385     24.1066913605   

========ROUND 113========
====Feature update====
epoch            class_loss      
0                0.7492325902    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6505293846     2.4801216125     0.1704077125    
Counter({0: 11330, 2: 9834, 1: 8308})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5280225873     0.6675159335     1.1955385208     0.9430985342     0.7760586319     0.6709956710     24.1792552471   

========ROUND 114========
====Feature update====
epoch            class_loss      
0                0.3659163415    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8747267723     2.7962830067     0.0784438252    
Counter({0: 11618, 2: 9785, 1: 8069})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4140107632     0.6910056472     1.1050164700     0.9281012486     0.7684581976     0.6729437229     24.0561881065   

========ROUND 115========
====Feature update====
epoch            class_loss      
0                0.2096120566    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7898736000     2.6710813046     0.1187923551    
Counter({0: 11638, 2: 9614, 1: 8220})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4089560509     0.6852238774     1.0941798687     0.9337676439     0.7707654723     0.6689393939     24.1507625580   

========ROUND 116========
====Feature update====
epoch            class_loss      
0                0.2936457992    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6863358021     2.6087520123     0.0775837675    
Counter({0: 11941, 2: 9500, 1: 8031})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3602293730     0.5598244071     0.9200537801     0.9449307818     0.7775515744     0.6658008658     24.1010119915   

========ROUND 117========
====Feature update====
epoch            class_loss      
0                0.3122650981    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7282919884     2.6508414745     0.0774504840    
Counter({0: 11900, 2: 9539, 1: 8033})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3822760880     0.6220620275     1.0043381453     0.9492399566     0.7791802389     0.6800865801     24.0535376072   

========ROUND 118========
====Feature update====
epoch            class_loss      
0                0.2106516808    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7120368481     2.5958178043     0.1162190214    
Counter({0: 12054, 2: 9390, 1: 8028})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2828211188     0.5487912893     0.8316124082     0.9385857763     0.7759229099     0.6688311688     24.0338921547   

========ROUND 119========
====Feature update====
epoch            class_loss      
0                0.3778638542    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7527647018     2.7033755779     0.0493890531    
Counter({0: 12190, 2: 9337, 1: 7945})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1681128740     0.5496399403     0.7177528143     0.9476452226     0.7760586319     0.6603896104     24.0862472057   
Target acc: 0.6749
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:1e-05
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
0                1.4113305807    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5491721630     2.5491704941     0.0000016118    
Counter({0: 21702, 1: 5148, 2: 2622})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.1784845591     0.1677416116     1.3462262154     0.5492331705     0.5301302932     0.4127705628     24.3618314266   

========ROUND 1========
====Feature update====
epoch            class_loss      
0                1.2309918404    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.2025175095     2.1394715309     0.0630458668    
Counter({0: 20616, 1: 6002, 2: 2854})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.2719976902     0.2753049433     1.5473026037     0.6646986971     0.6372149837     0.5175324675     24.4447929859   

========ROUND 2========
====Feature update====
epoch            class_loss      
0                1.2218555212    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4609298706     2.4049942493     0.0559356846    
Counter({0: 20423, 1: 6073, 2: 2976})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6915774345     0.2230378985     0.9146153331     0.6927252986     0.6497014115     0.5520562771     24.2511687279   

========ROUND 3========
====Feature update====
epoch            class_loss      
0                0.9787246585    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.3777179718     2.3454611301     0.0322568193    
Counter({0: 20311, 1: 6089, 2: 3072})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.8360258937     0.2836592495     1.1196851730     0.7210912052     0.6606948969     0.5595238095     24.2448482513   

========ROUND 4========
====Feature update====
epoch            class_loss      
0                0.7059726119    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4264981747     2.2922801971     0.1342179924    
Counter({0: 20037, 1: 6219, 2: 3216})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6012148261     0.0786379725     0.6798527837     0.7550556460     0.6900108578     0.6196969697     24.3628752232   

========ROUND 5========
====Feature update====
epoch            class_loss      
0                0.8614211679    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.2789354324     2.2462651730     0.0326701887    
Counter({0: 19292, 1: 6612, 2: 3568})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7898299694     0.0901800916     0.8800100684     0.7628596634     0.7052117264     0.6490259740     24.3899173737   

========ROUND 6========
====Feature update====
epoch            class_loss      
0                0.9483342171    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4124944210     2.3809964657     0.0314978659    
Counter({0: 18984, 1: 6701, 2: 3787})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7219242454     0.1416129917     0.8635372519     0.7962472856     0.7193268187     0.6343073593     24.1923913956   

========ROUND 7========
====Feature update====
epoch            class_loss      
0                0.5424703956    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4677903652     2.3753788471     0.0924114585    
Counter({0: 17869, 1: 7382, 2: 4221})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.8416666985     0.3925442696     1.2342109680     0.8290580890     0.7486427796     0.6464285714     24.1087739468   

========ROUND 8========
====Feature update====
epoch            class_loss      
0                0.5259312987    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4732697010     2.3238155842     0.1494541317    
Counter({0: 17490, 1: 7357, 2: 4625})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7273788452     0.2358736843     0.9632525444     0.8034744843     0.7357491857     0.6361471861     24.2072303295   

========ROUND 9========
====Feature update====
epoch            class_loss      
0                0.8200232983    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6390423775     2.4645946026     0.1744478494    
Counter({0: 16852, 1: 7907, 2: 4713})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6497717500     0.2942528427     0.9440245628     0.8222380565     0.7417209555     0.6282467532     24.1986589432   

========ROUND 10========
====Feature update====
epoch            class_loss      
0                0.8681018949    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4624488354     2.4165990353     0.0458498299    
Counter({0: 16835, 1: 7796, 2: 4841})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5778667331     0.1321538836     0.7100206017     0.8492467427     0.7626221498     0.6391774892     24.1974234581   

========ROUND 11========
====Feature update====
epoch            class_loss      
0                0.8082206845    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6178934574     2.5317521095     0.0861413181    
Counter({0: 16865, 1: 7618, 2: 4989})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5170131326     0.2598342001     0.7768473625     0.8466340934     0.7523072747     0.6489177489     24.4325487614   

========ROUND 12========
====Feature update====
epoch            class_loss      
0                0.7119493484    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6242940426     2.4999828339     0.1243112087    
Counter({0: 16770, 1: 7647, 2: 5055})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6888307929     0.2797158062     0.9685466290     0.8350298588     0.7504071661     0.6417748918     24.2129013538   

========ROUND 13========
====Feature update====
epoch            class_loss      
0                0.5539110899    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6840307713     2.5611717701     0.1228589416    
Counter({0: 16748, 1: 7408, 2: 5316})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6052269340     0.2389838248     0.8442107439     0.8449375679     0.7521715527     0.6670995671     24.5316858292   

========ROUND 14========
====Feature update====
epoch            class_loss      
0                0.4774124622    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.3928518295     2.3546011448     0.0382506289    
Counter({0: 16518, 1: 7583, 2: 5371})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6509056091     0.2441072464     0.8950128555     0.8317385993     0.7433496200     0.6142857143     24.2077879906   

========ROUND 15========
====Feature update====
epoch            class_loss      
0                0.6659194231    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5617251396     2.4433362484     0.1183887795    
Counter({0: 16540, 1: 7519, 2: 5413})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4747174978     0.2503651381     0.7250826359     0.8723873507     0.7643865364     0.6435064935     24.2993209362   

========ROUND 16========
====Feature update====
epoch            class_loss      
0                0.7281396389    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5195653439     2.4631469250     0.0564183332    
Counter({0: 16751, 1: 7133, 2: 5588})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6644272208     0.3983399868     1.0627672672     0.8617331705     0.7551574376     0.6545454545     24.2978167534   

========ROUND 17========
====Feature update====
epoch            class_loss      
0                0.7230973840    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6971561909     2.5591809750     0.1379751265    
Counter({0: 16077, 1: 7693, 2: 5702})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3124360144     0.3096348047     0.6220707893     0.8747964169     0.7657437568     0.6480519481     24.1905505657   

========ROUND 18========
====Feature update====
epoch            class_loss      
0                0.5254145265    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6459126472     2.5642888546     0.0816238001    
Counter({0: 15153, 1: 8514, 2: 5805})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6221122742     0.3628742695     0.9849865437     0.8716408795     0.7634364821     0.6603896104     24.3093574047   

========ROUND 19========
====Feature update====
epoch            class_loss      
0                0.6767406464    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5365955830     2.4434001446     0.0931953862    
Counter({0: 14097, 1: 9370, 2: 6005})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5660648942     0.3995988071     0.9656636715     0.8763911509     0.7633007600     0.6481601732     24.2693793774   

========ROUND 20========
====Feature update====
epoch            class_loss      
0                0.6799128652    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5932934284     2.4583842754     0.1349091232    
Counter({0: 12985, 1: 9908, 2: 6579})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5086594224     0.4187954962     0.9274549484     0.8832451140     0.7687296417     0.6331168831     24.2507042885   

========ROUND 21========
====Feature update====
epoch            class_loss      
0                0.5887519121    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5544967651     2.4708340168     0.0836628005    
Counter({0: 12621, 1: 9982, 2: 6869})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4501344264     0.4336770475     0.8838114738     0.8824307818     0.7719869707     0.6415584416     24.3340628147   

========ROUND 22========
====Feature update====
epoch            class_loss      
0                0.5300646424    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7526390553     2.6199839115     0.1326552480    
Counter({0: 12301, 1: 10047, 2: 7124})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5338290334     0.4598404169     0.9936694503     0.8712337134     0.7612649294     0.6469696970     24.2343192101   

========ROUND 23========
====Feature update====
epoch            class_loss      
0                0.6414744258    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7364401817     2.5177526474     0.2186874747    
Counter({0: 11745, 1: 10613, 2: 7114})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4102519453     0.5735575557     0.9838094711     0.8929831705     0.7706297503     0.6518398268     24.3115653992   

========ROUND 24========
====Feature update====
epoch            class_loss      
0                0.5653211474    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5909881592     2.4870853424     0.1039029285    
Counter({1: 11620, 0: 10854, 2: 6998})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5653150678     0.5941501260     1.1594651937     0.8825665038     0.7677795874     0.6643939394     24.3462843895   

========ROUND 25========
====Feature update====
epoch            class_loss      
0                0.5474699736    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6761586666     2.5883615017     0.0877972767    
Counter({1: 11479, 0: 10752, 2: 7241})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4503196776     0.5505893826     1.0009090900     0.8817521716     0.7600434311     0.6408008658     24.2661778927   

========ROUND 26========
====Feature update====
epoch            class_loss      
0                0.6748437285    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7471773624     2.6469655037     0.1002117768    
Counter({1: 11042, 0: 11024, 2: 7406})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5806774497     0.5003464818     1.0810239315     0.8972584148     0.7766015201     0.6615800866     24.1351535320   

========ROUND 27========
====Feature update====
epoch            class_loss      
0                0.6521807909    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7199656963     2.5538296700     0.1661361307    
Counter({1: 11357, 0: 10921, 2: 7194})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6048457026     0.5359497666     1.1407954693     0.8904044517     0.7679153094     0.6686147186     24.2068531513   

========ROUND 28========
====Feature update====
epoch            class_loss      
0                0.8500149250    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8238725662     2.6382706165     0.1856019497    
Counter({1: 11522, 0: 10689, 2: 7261})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3753988445     0.5268579125     0.9022567272     0.8987513572     0.7764657980     0.6555194805     24.2185511589   

========ROUND 29========
====Feature update====
epoch            class_loss      
0                0.7187736630    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.9823977947     2.6838636398     0.2985342145    
Counter({1: 11783, 0: 10389, 2: 7300})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4232874811     0.4980633557     0.9213508368     0.9050285016     0.7846091205     0.6584415584     24.2811110020   

========ROUND 30========
====Feature update====
epoch            class_loss      
0                0.5763960481    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6368753910     2.5692231655     0.0676521212    
Counter({1: 12089, 0: 10331, 2: 7052})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3171359897     0.5486614108     0.8657974005     0.8994638979     0.7706297503     0.6679653680     24.2497072220   

========ROUND 31========
====Feature update====
epoch            class_loss      
0                0.6124186516    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8053743839     2.6711778641     0.1341965646    
Counter({1: 11838, 0: 10424, 2: 7210})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4337007999     0.5402339101     0.9739347100     0.9008550489     0.7711726384     0.6497835498     24.2574915886   

========ROUND 32========
====Feature update====
epoch            class_loss      
0                0.4646001160    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7744374275     2.6809368134     0.0935005844    
Counter({1: 11850, 0: 10300, 2: 7322})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4065990150     0.5780011415     0.9846001863     0.9032641151     0.7749728556     0.6602813853     24.2474467754   

========ROUND 33========
====Feature update====
epoch            class_loss      
0                0.5847490430    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6077096462     2.4853086472     0.1224010810    
Counter({1: 11487, 0: 10577, 2: 7408})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4689941108     0.6704779267     1.1394720078     0.9074036374     0.7690010858     0.6544372294     24.2395756245   

========ROUND 34========
====Feature update====
epoch            class_loss      
0                0.4453594685    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6641190052     2.5383269787     0.1257919967    
Counter({1: 12498, 0: 9693, 2: 7281})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4468840361     0.6957025528     1.1425865889     0.8909812704     0.7642508143     0.6385281385     24.3912065029   

========ROUND 35========
====Feature update====
epoch            class_loss      
0                0.7647406459    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7368178368     2.6062481403     0.1305697411    
Counter({1: 12071, 0: 10002, 2: 7399})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5885378718     0.6908418536     1.2793797255     0.9136129207     0.7756514658     0.6496753247     24.2407410145   

========ROUND 36========
====Feature update====
epoch            class_loss      
0                0.5392710567    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5949163437     2.5046827793     0.0902335569    
Counter({1: 11595, 0: 10310, 2: 7567})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3510404527     0.4789198637     0.8299603462     0.8869435396     0.7600434311     0.6406926407     24.1385195255   

========ROUND 37========
====Feature update====
epoch            class_loss      
0                0.3591150939    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7651107311     2.6916463375     0.0734644458    
Counter({1: 11332, 0: 10535, 2: 7605})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3991975784     0.5076341629     0.9068317413     0.9023140608     0.7694082519     0.6655844156     24.2798161507   

========ROUND 38========
====Feature update====
epoch            class_loss      
0                0.5945835114    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7136940956     2.6271595955     0.0865344405    
Counter({1: 11549, 0: 10765, 2: 7158})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3821717203     0.4811836779     0.8633553982     0.9066232356     0.7738870793     0.6785714286     24.2726352215   

========ROUND 39========
====Feature update====
epoch            class_loss      
0                0.5208224654    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6537575722     2.5766015053     0.0771560520    
Counter({1: 11264, 0: 10779, 2: 7429})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3335151374     0.6285412312     0.9620563984     0.9206704669     0.7847448426     0.6761904762     24.2461674213   

========ROUND 40========
====Feature update====
epoch            class_loss      
0                0.4210762680    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7097206116     2.6315999031     0.0781207457    
Counter({1: 11829, 0: 10521, 2: 7122})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3842511177     0.4581276476     0.8423787355     0.9203650923     0.7752442997     0.6623376623     24.3810396194   

========ROUND 41========
====Feature update====
epoch            class_loss      
0                0.3526630104    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6862931252     2.5645298958     0.1217632592    
Counter({1: 12256, 0: 10022, 2: 7194})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2638559043     0.4867745936     0.7506304979     0.9061142780     0.7721226927     0.6542207792     24.3068227768   

========ROUND 42========
====Feature update====
epoch            class_loss      
0                0.4610665143    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6548361778     2.5264871120     0.1283491552    
Counter({1: 11680, 0: 10328, 2: 7464})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3266523778     0.4475379288     0.7741903067     0.9144611835     0.7703583062     0.6668831169     24.2866168022   

========ROUND 43========
====Feature update====
epoch            class_loss      
0                0.4658856094    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.9001636505     2.6775627136     0.2226010412    
Counter({1: 11479, 0: 10319, 2: 7674})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3265021443     0.5497226715     0.8762248158     0.9116110206     0.7798588491     0.6506493506     24.1731071472   

========ROUND 44========
====Feature update====
epoch            class_loss      
0                0.6150268912    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5417401791     2.4391925335     0.1025475487    
Counter({1: 11585, 0: 9942, 2: 7945})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2773503065     0.5448164940     0.8221668005     0.9243010315     0.7844733985     0.6681818182     24.1797890663   

========ROUND 45========
====Feature update====
epoch            class_loss      
0                0.4275420904    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4712541103     2.4114134312     0.0598406903    
Counter({1: 11151, 0: 10063, 2: 8258})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5005230904     0.4425290823     0.9430521727     0.9118146037     0.7732084691     0.6575757576     24.2531743050   

========ROUND 46========
====Feature update====
epoch            class_loss      
0                0.4765376747    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4281065464     2.3594779968     0.0686284378    
Counter({1: 11485, 0: 9522, 2: 8465})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5835292935     0.4732503891     1.0567796230     0.9180917481     0.7801302932     0.6566017316     24.1732079983   

========ROUND 47========
====Feature update====
epoch            class_loss      
0                0.5265207887    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5807151794     2.3899109364     0.1908041984    
Counter({1: 10929, 0: 9350, 2: 9193})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3476004601     0.6045752168     0.9521756768     0.9253868078     0.7816232356     0.6745670996     24.1785726547   

========ROUND 48========
====Feature update====
epoch            class_loss      
0                0.5875456929    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5791530609     2.4418494701     0.1373036355    
Counter({1: 10949, 0: 9507, 2: 9016})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2281128615     0.6371037364     0.8652166128     0.9156148208     0.7747014115     0.6596320346     24.1348485947   

========ROUND 49========
====Feature update====
epoch            class_loss      
0                0.3898900449    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5797464848     2.5031201839     0.0766263083    
Counter({1: 11113, 2: 9192, 0: 9167})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3108060658     0.5950612426     0.9058673382     0.9296959826     0.7836590662     0.6707792208     24.2446157932   

========ROUND 50========
====Feature update====
epoch            class_loss      
0                0.4295184910    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5684812069     2.4684188366     0.1000624597    
Counter({1: 10902, 0: 9287, 2: 9283})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3194190562     0.6486521959     0.9680712223     0.9270833333     0.7797231270     0.6716450216     24.3928477764   

========ROUND 51========
====Feature update====
epoch            class_loss      
0                0.7676210403    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4759464264     2.4166545868     0.0592917204    
Counter({1: 11014, 2: 9492, 0: 8966})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6038824916     0.5478158593     1.1516983509     0.9346498371     0.7878664495     0.6681818182     24.4791684151   

========ROUND 52========
====Feature update====
epoch            class_loss      
0                0.5042491555    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6587634087     2.5645177364     0.0942455828    
Counter({1: 10899, 0: 9423, 2: 9150})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3339515924     0.6892442107     1.0231957436     0.9254207383     0.7782301846     0.6792207792     24.2884354591   

========ROUND 53========
====Feature update====
epoch            class_loss      
0                0.4575569630    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7922527790     2.6341817379     0.1580711156    
Counter({1: 10634, 2: 9705, 0: 9133})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3922924995     0.4784808159     0.8707733154     0.9324443540     0.7820304017     0.6758658009     24.2675342560   

========ROUND 54========
====Feature update====
epoch            class_loss      
0                0.5413751006    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5660548210     2.4288609028     0.1371939927    
Counter({1: 10640, 2: 10037, 0: 8795})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2041418701     0.6462871432     0.8504289985     0.9347516287     0.7881378936     0.6791125541     24.2251076698   

========ROUND 55========
====Feature update====
epoch            class_loss      
0                0.6398332715    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8063242435     2.6004827023     0.2058414966    
Counter({2: 10933, 1: 10253, 0: 8286})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3925165832     0.8047506809     1.1972672939     0.9292548860     0.7837947883     0.6624458874     24.3038678169   

========ROUND 56========
====Feature update====
epoch            class_loss      
0                0.3242061436    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8098402023     2.6874454021     0.1223946884    
Counter({2: 11390, 1: 9879, 0: 8203})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4602544308     0.5691383481     1.0293927193     0.9153433768     0.7734799131     0.6475108225     24.2586967945   

========ROUND 57========
====Feature update====
epoch            class_loss      
0                0.5958920717    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5874633789     2.5038208961     0.0836425424    
Counter({2: 11304, 1: 9926, 0: 8242})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3201945722     0.5612457395     0.8814402819     0.9175149294     0.7757871878     0.6680735931     24.2387051582   

========ROUND 58========
====Feature update====
epoch            class_loss      
0                0.4379213750    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6673908234     2.5650136471     0.1023771390    
Counter({2: 11777, 1: 9770, 0: 7925})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2665036619     0.5390205979     0.8055242300     0.9263707926     0.7817589577     0.6656926407     24.2451288700   

========ROUND 59========
====Feature update====
epoch            class_loss      
0                0.3779992163    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7130913734     2.6090536118     0.1040378138    
Counter({2: 11997, 1: 9379, 0: 8096})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2714731395     0.5277137160     0.7991868258     0.9329533116     0.7810803474     0.6767316017     24.2673723698   

========ROUND 60========
====Feature update====
epoch            class_loss      
0                0.6558352113    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7692534924     2.6826355457     0.0866179243    
Counter({2: 11960, 1: 9356, 0: 8156})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3593955338     0.5372421145     0.8966376781     0.9310192725     0.7843376764     0.6768398268     24.3136847019   

========ROUND 61========
====Feature update====
epoch            class_loss      
0                0.3775236607    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8382427692     2.6514625549     0.1867802292    
Counter({2: 12144, 1: 9429, 0: 7899})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2699178755     0.5569625497     0.8268804550     0.9252510858     0.7793159609     0.6664502165     24.2115819454   

========ROUND 62========
====Feature update====
epoch            class_loss      
0                0.3750217855    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7862949371     2.6916620731     0.0946329609    
Counter({2: 11402, 1: 9529, 0: 8541})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3836804628     0.5989507437     0.9826312065     0.9424538545     0.7871878393     0.6799783550     24.2978127003   

========ROUND 63========
====Feature update====
epoch            class_loss      
0                0.4982790053    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8179934025     2.6049020290     0.2130914778    
Counter({2: 11197, 1: 9626, 0: 8649})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2934967577     0.7760561109     1.0695528984     0.9310192725     0.7782301846     0.6610389610     24.3351435661   

========ROUND 64========
====Feature update====
epoch            class_loss      
0                0.7166920304    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7905607224     2.6450831890     0.1454774886    
Counter({2: 10977, 1: 9440, 0: 9055})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3150916398     0.5948459506     0.9099376202     0.9231813246     0.7741585233     0.6834415584     24.2068924904   

========ROUND 65========
====Feature update====
epoch            class_loss      
0                0.4588736296    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6924471855     2.5992419720     0.0932053253    
Counter({2: 11494, 1: 9450, 0: 8528})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2181702405     0.5315442681     0.7497144938     0.9161577090     0.7709011944     0.6656926407     24.2714138031   

========ROUND 66========
====Feature update====
epoch            class_loss      
0                0.3894305229    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6974089146     2.6027860641     0.0946228281    
Counter({2: 11499, 1: 9272, 0: 8701})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4043705165     0.5730882287     0.9774587154     0.9268797503     0.7780944625     0.6617965368     24.1580672264   

========ROUND 67========
====Feature update====
epoch            class_loss      
0                0.4117927253    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8131465912     2.6671037674     0.1460427791    
Counter({2: 11518, 1: 9280, 0: 8674})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5325889587     0.7696070671     1.3021960258     0.9313585776     0.7809446254     0.6820346320     24.2008512020   

========ROUND 68========
====Feature update====
epoch            class_loss      
0                0.5940369368    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7485566139     2.6479494572     0.1006071791    
Counter({2: 11400, 1: 9487, 0: 8585})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3622473776     0.6117153168     0.9739626646     0.9339372964     0.7836590662     0.6833333333     24.2307183743   

========ROUND 69========
====Feature update====
epoch            class_loss      
0                0.3456135690    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6809852123     2.5791680813     0.1018172130    
Counter({2: 11240, 1: 9476, 0: 8756})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2279207110     0.4447106421     0.6726313829     0.9418431053     0.7859663409     0.6783549784     24.2800958157   

========ROUND 70========
====Feature update====
epoch            class_loss      
0                0.4293191433    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6942706108     2.5877664089     0.1065042615    
Counter({2: 11449, 1: 9709, 0: 8314})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4667080939     0.5602392554     1.0269473791     0.9321729099     0.7820304017     0.6728354978     24.2667324543   

========ROUND 71========
====Feature update====
epoch            class_loss      
0                0.2480831295    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7843914032     2.6680910587     0.1163002253    
Counter({2: 11415, 1: 9491, 0: 8566})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2549451590     0.5801661015     0.8351112604     0.9359731270     0.7813517915     0.6624458874     24.2193949223   

========ROUND 72========
====Feature update====
epoch            class_loss      
0                0.4083526433    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6900346279     2.5929195881     0.0971149281    
Counter({2: 11568, 1: 9615, 0: 8289})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2701479197     0.7371299863     1.0072779655     0.9285084148     0.7759229099     0.6572510823     24.2580754757   

========ROUND 73========
====Feature update====
epoch            class_loss      
0                0.3234480917    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7833354473     2.6352651119     0.1480704397    
Counter({2: 11436, 1: 9537, 0: 8499})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3499487936     0.4913434088     0.8412922025     0.9414698697     0.7823018458     0.6839826840     24.2411830425   

========ROUND 74========
====Feature update====
epoch            class_loss      
0                0.3148912489    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7542936802     2.6479873657     0.1063063443    
Counter({2: 11285, 1: 9578, 0: 8609})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3398747444     0.5715845823     0.9114593267     0.9325800760     0.7786373507     0.6703463203     24.2409906387   

========ROUND 75========
====Feature update====
epoch            class_loss      
0                0.3891254961    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6472783089     2.5800094604     0.0672689304    
Counter({2: 11011, 1: 9720, 0: 8741})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2445316762     0.5760073066     0.8205389977     0.9305442454     0.7732084691     0.6658008658     24.2238874435   

========ROUND 76========
====Feature update====
epoch            class_loss      
0                0.6864356399    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7978506088     2.6311662197     0.1666842848    
Counter({2: 10991, 1: 9446, 0: 9035})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4916590154     0.5128355026     1.0044945478     0.9395019001     0.7858306189     0.6674242424     24.3099315166   

========ROUND 77========
====Feature update====
epoch            class_loss      
0                0.2755688727    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7218105793     2.5643484592     0.1574621350    
Counter({2: 10862, 0: 9307, 1: 9303})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4034079015     0.5954677463     0.9988756180     0.9341069490     0.7771444083     0.6700216450     24.2917687893   

========ROUND 78========
====Feature update====
epoch            class_loss      
0                0.3994104564    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6889317036     2.5986750126     0.0902567804    
Counter({2: 10931, 1: 9489, 0: 9052})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2773542106     0.5140548348     0.7914090157     0.9451004343     0.7911237785     0.6748917749     24.1668417454   

========ROUND 79========
====Feature update====
epoch            class_loss      
0                0.3176493347    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7555298805     2.6575949192     0.0979350507    
Counter({2: 11088, 0: 9226, 1: 9158})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3714100122     0.5010858178     0.8724958301     0.9341408795     0.7810803474     0.6753246753     24.2535831928   

========ROUND 80========
====Feature update====
epoch            class_loss      
0                0.2962521613    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7869930267     2.5790319443     0.2079609632    
Counter({2: 10870, 1: 9468, 0: 9134})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5560178161     0.6635910869     1.2196089029     0.9331229642     0.7748371336     0.6836580087     24.1614367962   

========ROUND 81========
====Feature update====
epoch            class_loss      
0                0.4225839674    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6425864697     2.5810062885     0.0615800656    
Counter({2: 10736, 1: 9644, 0: 9092})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4636554718     0.5230292678     0.9866847396     0.9422502714     0.7804017372     0.6741341991     24.2296659946   

========ROUND 82========
====Feature update====
epoch            class_loss      
0                0.2490063757    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6976816654     2.6587345600     0.0389470570    
Counter({2: 10529, 0: 9551, 1: 9392})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3503905833     0.6507866979     1.0011773109     0.9368892508     0.7809446254     0.6579004329     24.2600989342   

========ROUND 83========
====Feature update====
epoch            class_loss      
0                0.3188367188    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6431381702     2.5932912827     0.0498469137    
Counter({2: 10642, 0: 9616, 1: 9214})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2952578366     0.4961942434     0.7914520502     0.9253528773     0.7673724213     0.6632034632     24.2395980358   

========ROUND 84========
====Feature update====
epoch            class_loss      
0                0.3921604455    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7290723324     2.5490920544     0.1799802780    
Counter({2: 10676, 0: 9685, 1: 9111})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3791657686     0.5071483850     0.8863141537     0.9208401194     0.7671009772     0.6613636364     24.1473135948   

========ROUND 85========
====Feature update====
epoch            class_loss      
0                0.1804105490    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6274063587     2.5626981258     0.0647082701    
Counter({2: 10523, 0: 10172, 1: 8777})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3549429476     0.4852353334     0.8401782513     0.9384161238     0.7771444083     0.6770562771     24.2150068283   

========ROUND 86========
====Feature update====
epoch            class_loss      
0                0.4876078665    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7924129963     2.6276614666     0.1647515297    
Counter({2: 10601, 0: 10030, 1: 8841})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3757295609     0.8610207438     1.2367503643     0.9393661781     0.7847448426     0.6699134199     24.2080709934   

========ROUND 87========
====Feature update====
epoch            class_loss      
0                0.2619878352    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7326390743     2.6681487560     0.0644903257    
Counter({2: 10490, 0: 10023, 1: 8959})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2170038372     0.5314906836     0.7484945059     0.9392304560     0.7802660152     0.6653679654     24.1352221966   

========ROUND 88========
====Feature update====
epoch            class_loss      
0                0.2965283096    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8275713921     2.6555538177     0.1720176488    
Counter({2: 10258, 0: 10231, 1: 8983})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3747046292     0.5921201110     0.9668247700     0.9390608035     0.7778230185     0.6610389610     24.2757048607   

========ROUND 89========
====Feature update====
epoch            class_loss      
0                0.2759552896    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6753802299     2.6214897633     0.0538904630    
Counter({0: 10589, 2: 10083, 1: 8800})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3469554484     0.5351075530     0.8820630312     0.9446593377     0.7768729642     0.6744588745     24.1597192287   

========ROUND 90========
====Feature update====
epoch            class_loss      
0                0.5030139089    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6719164848     2.5931751728     0.0787413940    
Counter({0: 10565, 2: 10182, 1: 8725})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3346847594     0.6758756042     1.0105603933     0.9425217155     0.7766015201     0.6812770563     25.0999989510   

========ROUND 91========
====Feature update====
epoch            class_loss      
0                0.4836484492    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6650536060     2.5690977573     0.0959558412    
Counter({0: 10908, 2: 10002, 1: 8562})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2769287229     0.5766394734     0.8535681963     0.9477130836     0.7866449511     0.6735930736     24.0949149132   

========ROUND 92========
====Feature update====
epoch            class_loss      
0                0.2591603398    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7626099586     2.6355915070     0.1270183325    
Counter({0: 10900, 2: 9951, 1: 8621})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3870555162     0.5602900386     0.9473455548     0.9329533116     0.7711726384     0.6599567100     24.2506229877   

========ROUND 93========
====Feature update====
epoch            class_loss      
0                0.4068953693    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7144823074     2.6526446342     0.0618377179    
Counter({0: 10646, 2: 10177, 1: 8649})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2260121852     0.6433795094     0.8693916798     0.9438450054     0.7867806732     0.6660173160     24.2642171383   

========ROUND 94========
====Feature update====
epoch            class_loss      
0                0.3514759243    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6950790882     2.6180534363     0.0770255551    
Counter({0: 11002, 2: 9843, 1: 8627})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1664312333     0.4962700605     0.6627013087     0.9394679696     0.7723941368     0.6621212121     24.2110817432   

========ROUND 95========
====Feature update====
epoch            class_loss      
0                0.4363745153    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6023414135     2.5446014404     0.0577399246    
Counter({0: 10670, 2: 10059, 1: 8743})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3007638454     0.6322863698     0.9330502152     0.9430985342     0.7837947883     0.6759740260     24.2578735352   

========ROUND 96========
====Feature update====
epoch            class_loss      
0                0.3236129582    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6047494411     2.5648174286     0.0399320759    
Counter({0: 10646, 2: 10197, 1: 8629})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5201271176     0.6443402767     1.1644673347     0.9271511944     0.7681867535     0.6590909091     24.2680671215   

========ROUND 97========
====Feature update====
epoch            class_loss      
0                0.5738243461    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7446813583     2.5979063511     0.1467750669    
Counter({0: 10648, 2: 10279, 1: 8545})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2711934745     0.5633486509     0.8345421553     0.9435057003     0.7785016287     0.6743506494     24.1855952740   

========ROUND 98========
====Feature update====
epoch            class_loss      
0                0.3480475843    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6816036701     2.6051840782     0.0764196590    
Counter({0: 11023, 2: 10032, 1: 8417})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2606359720     0.5965254903     0.8571614623     0.9416734528     0.7742942454     0.6622294372     24.1589663029   

========ROUND 99========
====Feature update====
epoch            class_loss      
0                0.3268188238    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.9312911034     2.7685317993     0.1627593189    
Counter({0: 11017, 2: 10103, 1: 8352})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3275258839     0.5986115932     0.9261374474     0.9314603692     0.7729370250     0.6586580087     24.2362339497   

========ROUND 100========
====Feature update====
epoch            class_loss      
0                0.5496939421    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6943733692     2.6211931705     0.0731802657    
Counter({0: 11244, 2: 10012, 1: 8216})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2876162827     0.6417469978     0.9293632507     0.9422502714     0.7785016287     0.6687229437     24.2561638355   

========ROUND 101========
====Feature update====
epoch            class_loss      
0                0.4553429186    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8356068134     2.7506601810     0.0849466845    
Counter({0: 11283, 2: 9941, 1: 8248})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2649540007     0.5819565654     0.8469105959     0.9308835505     0.7691368078     0.6619047619     24.1570706367   

========ROUND 102========
====Feature update====
epoch            class_loss      
0                0.8020923138    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7218210697     2.6032574177     0.1185636222    
Counter({0: 11052, 2: 9845, 1: 8575})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3311297894     0.5988475680     0.9299773574     0.9384839848     0.7745656895     0.6717532468     24.4475071430   

========ROUND 103========
====Feature update====
epoch            class_loss      
0                0.2859421372    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6511189938     2.5587437153     0.0923752561    
Counter({0: 10998, 2: 10080, 1: 8394})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4349625409     0.5908227563     1.0257853270     0.9477130836     0.7791802389     0.6833333333     24.2523021698   

========ROUND 104========
====Feature update====
epoch            class_loss      
0                0.4475880563    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6250884533     2.5298626423     0.0952256992    
Counter({0: 11135, 2: 9907, 1: 8430})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3483605385     0.5783261657     0.9266867042     0.9393661781     0.7757871878     0.6612554113     24.2424552441   

========ROUND 105========
====Feature update====
epoch            class_loss      
0                0.3654239476    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7154438496     2.6625983715     0.0528455228    
Counter({0: 11296, 2: 9912, 1: 8264})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2063518912     0.5181064010     0.7244582772     0.9308835505     0.7780944625     0.6617965368     24.2381916046   

========ROUND 106========
====Feature update====
epoch            class_loss      
0                0.4668048322    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6340939999     2.5982532501     0.0358408578    
Counter({0: 11155, 2: 10067, 1: 8250})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2926972210     0.8121604323     1.1048576832     0.9363124321     0.7744299674     0.6675324675     24.2050719261   

========ROUND 107========
====Feature update====
epoch            class_loss      
0                0.3507852852    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7137877941     2.6272912025     0.0864966735    
Counter({0: 11511, 2: 9767, 1: 8194})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4240694940     0.5960897207     1.0201592445     0.9305103149     0.7728013029     0.6649350649     24.2209761143   

========ROUND 108========
====Feature update====
epoch            class_loss      
0                0.5149777532    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8477017879     2.6671259403     0.1805758476    
Counter({0: 11590, 2: 9863, 1: 8019})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2742144465     0.5310116410     0.8052260876     0.9451343648     0.7778230185     0.6859307359     24.3473954201   

========ROUND 109========
====Feature update====
epoch            class_loss      
0                0.3721275330    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4855377674     2.4472644329     0.0382732563    
Counter({0: 11403, 2: 9889, 1: 8180})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2345452905     0.6639969945     0.8985422850     0.9378732356     0.7749728556     0.6622294372     24.1554157734   

========ROUND 110========
====Feature update====
epoch            class_loss      
0                0.4481630325    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7815828323     2.5438189507     0.2377638072    
Counter({0: 11260, 2: 9980, 1: 8232})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2876576483     0.4960621297     0.7837197781     0.9394001086     0.7711726384     0.6660173160     24.0989909172   

========ROUND 111========
====Feature update====
epoch            class_loss      
0                0.6784070134    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6076881886     2.5654881001     0.0422000475    
Counter({0: 11745, 2: 9575, 1: 8152})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3247255385     0.5283435583     0.8530690670     0.9458469055     0.7816232356     0.6738095238     24.2357769012   

========ROUND 112========
====Feature update====
epoch            class_loss      
0                0.4335859716    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6600942612     2.5856111050     0.0744830891    
Counter({0: 11503, 2: 9682, 1: 8287})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2538418472     0.5655207634     0.8193626404     0.9183631922     0.7612649294     0.6635281385     24.3542087078   

========ROUND 113========
====Feature update====
epoch            class_loss      
0                0.7492325902    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6505293846     2.4801216125     0.1704077125    
Counter({0: 11330, 2: 9834, 1: 8308})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5280225873     0.6675159335     1.1955385208     0.9430985342     0.7760586319     0.6709956710     24.3250246048   

========ROUND 114========
====Feature update====
epoch            class_loss      
0                0.3659163415    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8747267723     2.7962830067     0.0784438252    
Counter({0: 11618, 2: 9785, 1: 8069})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4140107632     0.6910056472     1.1050164700     0.9281012486     0.7684581976     0.6729437229     24.3276560307   

========ROUND 115========
====Feature update====
epoch            class_loss      
0                0.2096120566    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7898736000     2.6710813046     0.1187923551    
Counter({0: 11638, 2: 9614, 1: 8220})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4089560509     0.6852238774     1.0941798687     0.9337676439     0.7707654723     0.6689393939     24.2696583271   

========ROUND 116========
====Feature update====
epoch            class_loss      
0                0.2936457992    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6863358021     2.6087520123     0.0775837675    
Counter({0: 11941, 2: 9500, 1: 8031})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3602293730     0.5598244071     0.9200537801     0.9449307818     0.7775515744     0.6658008658     24.3947603703   

========ROUND 117========
====Feature update====
epoch            class_loss      
0                0.3122650981    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7282919884     2.6508414745     0.0774504840    
Counter({0: 11900, 2: 9539, 1: 8033})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3822760880     0.6220620275     1.0043381453     0.9492399566     0.7791802389     0.6800865801     24.1549329758   

========ROUND 118========
====Feature update====
epoch            class_loss      
0                0.2106516808    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7120368481     2.5958178043     0.1162190214    
Counter({0: 12054, 2: 9390, 1: 8028})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2828211188     0.5487912893     0.8316124082     0.9385857763     0.7759229099     0.6688311688     24.2186980247   

========ROUND 119========
====Feature update====
epoch            class_loss      
0                0.3778638542    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7527647018     2.7033755779     0.0493890531    
Counter({0: 12190, 2: 9337, 1: 7945})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1681128740     0.5496399403     0.7177528143     0.9476452226     0.7760586319     0.6603896104     24.1813681126   
Target acc: 0.6749
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:1e-05
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
0                1.4113305807    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5491721630     2.5491704941     0.0000016118    
Counter({0: 21702, 1: 5148, 2: 2622})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.1784845591     0.1677416116     1.3462262154     0.5492331705     0.5301302932     0.4127705628     53.5447587967   

========ROUND 1========
====Feature update====
epoch            class_loss      
0                1.2309918404    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.2025175095     2.1394715309     0.0630458668    
Counter({0: 20616, 1: 6002, 2: 2854})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.2719976902     0.2753049433     1.5473026037     0.6646986971     0.6372149837     0.5175324675     52.6268160343   

========ROUND 2========
====Feature update====
epoch            class_loss      
0                1.2218555212    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4609298706     2.4049942493     0.0559356846    
Counter({0: 20423, 1: 6073, 2: 2976})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6915774345     0.2230378985     0.9146153331     0.6927252986     0.6497014115     0.5520562771     52.7087774277   

========ROUND 3========
====Feature update====
epoch            class_loss      
0                0.9787246585    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.3777179718     2.3454611301     0.0322568193    
Counter({0: 20311, 1: 6089, 2: 3072})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.8360258937     0.2836592495     1.1196851730     0.7210912052     0.6606948969     0.5595238095     55.0949506760   

========ROUND 4========
====Feature update====
epoch            class_loss      
0                0.7059726119    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4264981747     2.2922801971     0.1342179924    
Counter({0: 20037, 1: 6219, 2: 3216})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6012148261     0.0786379725     0.6798527837     0.7550556460     0.6900108578     0.6196969697     53.3739993572   

========ROUND 5========
====Feature update====
epoch            class_loss      
0                0.8614211679    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.2789354324     2.2462651730     0.0326701887    
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:1e-05
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Traceback (most recent call last):
  File "C:/Program Files/JetBrains/PyCharm 2021.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "E:\robustlearn\diversify\train.py", line 103, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 45, in main
    loss_result_dict = algorithm.update_a(data, opta)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 137, in update_a
    dt_z = self.featurizer(all_x)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\robustlearn\diversify\network\act_network.py", line 40, in forward
    plt.plot(x.to('cpu').numpy())
RuntimeError: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:1e-05
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Traceback (most recent call last):
  File "C:/Program Files/JetBrains/PyCharm 2021.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "E:\robustlearn\diversify\train.py", line 103, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 45, in main
    loss_result_dict = algorithm.update_a(data, opta)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 137, in update_a
    dt_z = self.featurizer(all_x)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\robustlearn\diversify\network\act_network.py", line 41, in forward
    plt.plot(x.to('cpu').numpy())
RuntimeError: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:1e-05
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Traceback (most recent call last):
  File "C:/Program Files/JetBrains/PyCharm 2021.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "E:\robustlearn\diversify\train.py", line 103, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 45, in main
    loss_result_dict = algorithm.update_a(data, opta)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 137, in update_a
    dt_z = self.featurizer(all_x)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\robustlearn\diversify\network\act_network.py", line 41, in forward
    plt.plot(x.detach().numpy())
TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:1e-05
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:1e-05
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:1e-05
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:1e-05
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      

Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 8, in <module>
    output = model(train_loader)
TypeError: 'collections.OrderedDict' object is not callable
Traceback (most recent call last):
  File "<string>", line 1, in <module>
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 8, in <module>
    for data in train_loader:
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 444, in __iter__
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\spawn.py", line 105, in spawn_main
    exitcode = _main(fd)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\spawn.py", line 114, in _main
    prepare(preparation_data)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\spawn.py", line 225, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\spawn.py", line 277, in _fixup_main_from_path
    run_name="__mp_main__")
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\runpy.py", line 263, in run_path
    pkg_name=pkg_name, script_name=fname)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\runpy.py", line 96, in _run_module_code
    mod_name, mod_spec, pkg_name, script_name)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "E:\robustlearn\diversify\test.py", line 8, in <module>
    for data in train_loader:
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 444, in __iter__
    return self._get_iterator()
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 390, in _get_iterator
    return self._get_iterator()
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 390, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 1077, in __init__
    return _MultiProcessingDataLoaderIter(self)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 1077, in __init__
    w.start()
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\process.py", line 112, in start
    w.start()
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\process.py", line 112, in start
        self._popen = self._Popen(self)
lf._popen = self._Popen(self)  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 223, in _Popen
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 223, in _Popen
        return _default_context.get_context().Process._Popen(process_obj)return _default_context.get_context().Process._Popen(process_obj)

  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 322, in _Popen
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 322, in _Popen
        rn Popen(process_obj)return Popen(process_obj)
File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\popen_spawn_win32.py", line 46, in __init__
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\popen_spawn_win32.py", line 89, in __init__
        prep_data = spawn.get_preparation_data(process_obj._name)reduction.dump(process_obj, to_child)

  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\spawn.py", line 143, in get_preparation_data
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\reduction.py", line 60, in dump
    _check_not_importing_main()
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\spawn.py", line 136, in _check_not_importing_main
    is not going to be frozen to produce an executable.''')
RuntimeError: 
        An attempt has been made to start a new process before the
        current process has finished its bootstrapping phase.

        This probably means that you are not using fork to start your
        child processes and you have forgotten to use the proper idiom
        in the main module:

            if __name__ == '__main__':
                freeze_support()
                ...

        The "freeze_support()" line can be omitted if the program
        is not going to be frozen to produce an executable.
    ForkingPickler(file, protocol).dump(obj)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 7, in <module>
    model.load_state_dict(torch.load("model"))
TypeError: load_state_dict() missing 1 required positional argument: 'state_dict'
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:1e-05
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 103, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 31, in main
    algorithm = algorithm_class(args).cuda()
KeyboardInterrupt
Traceback (most recent call last):
  File "C:/Program Files/JetBrains/PyCharm 2021.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "E:\robustlearn\diversify\test.py", line 7, in <module>
    model.load_state_dict(torch.load("model"), strict=False)
TypeError: load_state_dict() missing 1 required positional argument: 'state_dict'
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:1e-05
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      



















































































































































































































































































































0                1.4113305807    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        













































































































Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:1e-05
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Traceback (most recent call last):
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\popen_spawn_win32.py", line 89, in __init__
    reduction.dump(process_obj, to_child)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\reduction.py", line 60, in dump
    ForkingPickler(file, protocol).dump(obj)
BrokenPipeError: [Errno 32] Broken pipe

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 103, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 44, in main
    for data in train_loader:
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 444, in __iter__
    return self._get_iterator()
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 390, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 1077, in __init__
    w.start()
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\process.py", line 112, in start
    self._popen = self._Popen(self)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 322, in _Popen
    return Popen(process_obj)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\popen_spawn_win32.py", line 89, in __init__
    reduction.dump(process_obj, to_child)
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:1e-05
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
0                1.4113305807    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5491721630     2.5491704941     0.0000016118    
Counter({0: 21702, 1: 5148, 2: 2622})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
Traceback (most recent call last):
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\popen_spawn_win32.py", line 89, in __init__
    reduction.dump(process_obj, to_child)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\reduction.py", line 60, in dump
    ForkingPickler(file, protocol).dump(obj)
BrokenPipeError: [Errno 32] Broken pipe

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\robustlearn\diversify\train.py", line 103, in <module>
    main(args)
  File "E:\robustlearn\diversify\train.py", line 73, in main
    for data in train_loader:
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 444, in __iter__
    return self._get_iterator()
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 390, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 1077, in __init__
    w.start()
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\process.py", line 112, in start
    self._popen = self._Popen(self)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 322, in _Popen
    return Popen(process_obj)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\popen_spawn_win32.py", line 89, in __init__
    reduction.dump(process_obj, to_child)
KeyboardInterrupt
Environment:
	Python: 3.7.9
	PyTorch: 1.12.1+cu113
	Torchvision: 0.13.1+cu113
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.21.6
	PIL: 9.2.0
==========================================
algorithm:diversify
alpha:0.1
alpha1:0.1
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:3
local_epoch:1
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:120
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:train_output
weight_decay:1e-05
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]}
num_classes:16
input_shape:(5, 1, 8000)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
0                1.4113305807    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5491721630     2.5491704941     0.0000016118    
Counter({0: 21702, 1: 5148, 2: 2622})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.1784845591     0.1677416116     1.3462262154     0.5492331705     0.5301302932     0.4127705628     35.4656932354   

========ROUND 1========
====Feature update====
epoch            class_loss      
0                1.2309918404    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.2025175095     2.1394715309     0.0630458668    
Counter({0: 20616, 1: 6002, 2: 2854})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                1.2719976902     0.2753049433     1.5473026037     0.6646986971     0.6372149837     0.5175324675     36.9794478416   

========ROUND 2========
====Feature update====
epoch            class_loss      
Traceback (most recent call last):
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "E:\robustlearn\diversify\test.py", line 13, in <module>
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\spawn.py", line 105, in spawn_main
    for data in train_loader:
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 444, in __iter__
    exitcode = _main(fd)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\spawn.py", line 114, in _main
    prepare(preparation_data)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\spawn.py", line 225, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\spawn.py", line 277, in _fixup_main_from_path
    return self._get_iterator()
      File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 390, in _get_iterator
run_name="__mp_main__")
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\runpy.py", line 263, in run_path
    return _MultiProcessingDataLoaderIter(self)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 1077, in __init__
    pkg_name=pkg_name, script_name=fname)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\runpy.py", line 96, in _run_module_code
        mod_name, mod_spec, pkg_name, script_name)w.start()

  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\process.py", line 112, in start
    exec(code, run_globals)
  File "E:\robustlearn\diversify\test.py", line 13, in <module>
    for data in train_loader:
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 444, in __iter__
    self._popen = self._Popen(self)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 223, in _Popen
    return self._get_iterator()
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 390, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
    le "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 1077, in __init__
return _default_context.get_context().Process._Popen(process_obj)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 322, in _Popen
    return Popen(process_obj)    
w.start()
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\popen_spawn_win32.py", line 89, in __init__
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\process.py", line 112, in start
    self._popen = self._Popen(self)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 223, in _Popen
    reduction.dump(process_obj, to_child)
    return _default_context.get_context().Process._Popen(process_obj)\multiprocessing\reduction.py", line 60, in dump

  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 322, in _Popen
    return Popen(process_obj)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\popen_spawn_win32.py", line 46, in __init__
    prep_data = spawn.get_preparation_data(process_obj._name)      File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\spawn.py", line 143, in get_preparation_data
ForkingPickler(file, protocol).dump(obj)
BrokenPipeError: [Errno 32] Broken pipe
    _check_not_importing_main()
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\spawn.py", line 136, in _check_not_importing_main
    is not going to be frozen to produce an executable.''')
RuntimeError: 
        An attempt has been made to start a new process before the
        current process has finished its bootstrapping phase.

        This probably means that you are not using fork to start your
        child processes and you have forgotten to use the proper idiom
        in the main module:

            if __name__ == '__main__':
                freeze_support()
                ...

        The "freeze_support()" line can be omitted if the program
        is not going to be frozen to produce an executable.
0                1.2218555212    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4609298706     2.4049942493     0.0559356846    
Counter({0: 20423, 1: 6073, 2: 2976})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 13, in <module>
    for data in train_loader:
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 444, in __iter__
    return self._get_iterator()
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 390, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 1077, in __init__
    w.start()
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\process.py", line 112, in start
    self._popen = self._Popen(self)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 322, in _Popen
    return Popen(process_obj)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\popen_spawn_win32.py", line 89, in __init__
    reduction.dump(process_obj, to_child)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\reduction.py", line 60, in dump
    ForkingPickler(file, protocol).dump(obj)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\spawn.py", line 105, in spawn_main
    exitcode = _main(fd)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\spawn.py", line 114, in _main
    prepare(preparation_data)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\spawn.py", line 225, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\spawn.py", line 277, in _fixup_main_from_path
    run_name="__mp_main__")
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\runpy.py", line 263, in run_path
    pkg_name=pkg_name, script_name=fname)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\runpy.py", line 96, in _run_module_code
    mod_name, mod_spec, pkg_name, script_name)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "E:\robustlearn\diversify\test.py", line 13, in <module>
    for data in train_loader:
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 444, in __iter__
    return self._get_iterator()
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 390, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 1077, in __init__
    w.start()
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\process.py", line 112, in start
    self._popen = self._Popen(self)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 322, in _Popen
    return Popen(process_obj)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\popen_spawn_win32.py", line 46, in __init__
    prep_data = spawn.get_preparation_data(process_obj._name)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\spawn.py", line 143, in get_preparation_data
    _check_not_importing_main()
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\spawn.py", line 136, in _check_not_importing_main
    is not going to be frozen to produce an executable.''')
RuntimeError: 
        An attempt has been made to start a new process before the
        current process has finished its bootstrapping phase.

        This probably means that you are not using fork to start your
        child processes and you have forgotten to use the proper idiom
        in the main module:

            if __name__ == '__main__':
                freeze_support()
                ...

        The "freeze_support()" line can be omitted if the program
        is not going to be frozen to produce an executable.
0                0.6915774345     0.2230378985     0.9146153331     0.6927252986     0.6497014115     0.5520562771     41.2829966545   

========ROUND 3========
====Feature update====
epoch            class_loss      
0                0.9787246585    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.3777179718     2.3454611301     0.0322568193    
Counter({0: 20311, 1: 6089, 2: 3072})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.8360258937     0.2836592495     1.1196851730     0.7210912052     0.6606948969     0.5595238095     32.9099535942   

========ROUND 4========
====Feature update====
epoch            class_loss      
0                0.7059726119    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4264981747     2.2922801971     0.1342179924    
Counter({0: 20037, 1: 6219, 2: 3216})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6012148261     0.0786379725     0.6798527837     0.7550556460     0.6900108578     0.6196969697     34.4758019447   

========ROUND 5========
====Feature update====
epoch            class_loss      
0                0.8614211679    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.2789354324     2.2462651730     0.0326701887    
Counter({0: 19292, 1: 6612, 2: 3568})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7898299694     0.0901800916     0.8800100684     0.7628596634     0.7052117264     0.6490259740     36.8928613663   

========ROUND 6========
====Feature update====
epoch            class_loss      
0                0.9483342171    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4124944210     2.3809964657     0.0314978659    
Counter({0: 18984, 1: 6701, 2: 3787})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7219242454     0.1416129917     0.8635372519     0.7962472856     0.7193268187     0.6343073593     34.2168197632   

========ROUND 7========
====Feature update====
epoch            class_loss      
0                0.5424703956    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4677903652     2.3753788471     0.0924114585    
Counter({0: 17869, 1: 7382, 2: 4221})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.8416666985     0.3925442696     1.2342109680     0.8290580890     0.7486427796     0.6464285714     34.3122336864   

========ROUND 8========
====Feature update====
epoch            class_loss      
0                0.5259312987    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4732697010     2.3238155842     0.1494541317    
Counter({0: 17490, 1: 7357, 2: 4625})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.7273788452     0.2358736843     0.9632525444     0.8034744843     0.7357491857     0.6361471861     33.9838080406   

========ROUND 9========
====Feature update====
epoch            class_loss      
0                0.8200232983    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6390423775     2.4645946026     0.1744478494    
Counter({0: 16852, 1: 7907, 2: 4713})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6497717500     0.2942528427     0.9440245628     0.8222380565     0.7417209555     0.6282467532     34.2586841583   

========ROUND 10========
====Feature update====
epoch            class_loss      
0                0.8681018949    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4624488354     2.4165990353     0.0458498299    
Counter({0: 16835, 1: 7796, 2: 4841})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5778667331     0.1321538836     0.7100206017     0.8492467427     0.7626221498     0.6391774892     35.3106713295   

========ROUND 11========
====Feature update====
epoch            class_loss      
0                0.8082206845    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6178934574     2.5317521095     0.0861413181    
Counter({0: 16865, 1: 7618, 2: 4989})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5170131326     0.2598342001     0.7768473625     0.8466340934     0.7523072747     0.6489177489     34.6559195518   

========ROUND 12========
====Feature update====
epoch            class_loss      
0                0.7119493484    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6242940426     2.4999828339     0.1243112087    
Counter({0: 16770, 1: 7647, 2: 5055})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6888307929     0.2797158062     0.9685466290     0.8350298588     0.7504071661     0.6417748918     33.6624417305   

========ROUND 13========
====Feature update====
epoch            class_loss      
0                0.5539110899    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6840307713     2.5611717701     0.1228589416    
Counter({0: 16748, 1: 7408, 2: 5316})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6052269340     0.2389838248     0.8442107439     0.8449375679     0.7521715527     0.6670995671     34.7870028019   

========ROUND 14========
====Feature update====
epoch            class_loss      
0                0.4774124622    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.3928518295     2.3546011448     0.0382506289    
Counter({0: 16518, 1: 7583, 2: 5371})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6509056091     0.2441072464     0.8950128555     0.8317385993     0.7433496200     0.6142857143     33.9506824017   

========ROUND 15========
====Feature update====
epoch            class_loss      
0                0.6659194231    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5617251396     2.4433362484     0.1183887795    
Counter({0: 16540, 1: 7519, 2: 5413})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4747174978     0.2503651381     0.7250826359     0.8723873507     0.7643865364     0.6435064935     35.0670206547   

========ROUND 16========
====Feature update====
epoch            class_loss      
0                0.7281396389    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5195653439     2.4631469250     0.0564183332    
Counter({0: 16751, 1: 7133, 2: 5588})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6644272208     0.3983399868     1.0627672672     0.8617331705     0.7551574376     0.6545454545     34.7031638622   

========ROUND 17========
====Feature update====
epoch            class_loss      
0                0.7230973840    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6971561909     2.5591809750     0.1379751265    
Counter({0: 16077, 1: 7693, 2: 5702})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3124360144     0.3096348047     0.6220707893     0.8747964169     0.7657437568     0.6480519481     33.6428964138   

========ROUND 18========
====Feature update====
epoch            class_loss      
0                0.5254145265    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6459126472     2.5642888546     0.0816238001    
Counter({0: 15153, 1: 8514, 2: 5805})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6221122742     0.3628742695     0.9849865437     0.8716408795     0.7634364821     0.6603896104     35.2803757191   

========ROUND 19========
====Feature update====
epoch            class_loss      
0                0.6767406464    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5365955830     2.4434001446     0.0931953862    
Counter({0: 14097, 1: 9370, 2: 6005})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5660648942     0.3995988071     0.9656636715     0.8763911509     0.7633007600     0.6481601732     34.5046632290   

========ROUND 20========
====Feature update====
epoch            class_loss      
0                0.6799128652    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5932934284     2.4583842754     0.1349091232    
Counter({0: 12985, 1: 9908, 2: 6579})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5086594224     0.4187954962     0.9274549484     0.8832451140     0.7687296417     0.6331168831     33.7461783886   

========ROUND 21========
====Feature update====
epoch            class_loss      
0                0.5887519121    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5544967651     2.4708340168     0.0836628005    
Counter({0: 12621, 1: 9982, 2: 6869})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4501344264     0.4336770475     0.8838114738     0.8824307818     0.7719869707     0.6415584416     35.1840260029   

========ROUND 22========
====Feature update====
epoch            class_loss      
0                0.5300646424    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7526390553     2.6199839115     0.1326552480    
Counter({0: 12301, 1: 10047, 2: 7124})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5338290334     0.4598404169     0.9936694503     0.8712337134     0.7612649294     0.6469696970     34.7892107964   

========ROUND 23========
====Feature update====
epoch            class_loss      
0                0.6414744258    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7364401817     2.5177526474     0.2186874747    
Counter({0: 11745, 1: 10613, 2: 7114})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4102519453     0.5735575557     0.9838094711     0.8929831705     0.7706297503     0.6518398268     34.3047482967   

========ROUND 24========
====Feature update====
epoch            class_loss      
0                0.5653211474    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5909881592     2.4870853424     0.1039029285    
Counter({1: 11620, 0: 10854, 2: 6998})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5653150678     0.5941501260     1.1594651937     0.8825665038     0.7677795874     0.6643939394     34.3696131706   

========ROUND 25========
====Feature update====
epoch            class_loss      
0                0.5474699736    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6761586666     2.5883615017     0.0877972767    
Counter({1: 11479, 0: 10752, 2: 7241})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4503196776     0.5505893826     1.0009090900     0.8817521716     0.7600434311     0.6408008658     34.5034759045   

========ROUND 26========
====Feature update====
epoch            class_loss      
0                0.6748437285    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7471773624     2.6469655037     0.1002117768    
Counter({1: 11042, 0: 11024, 2: 7406})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5806774497     0.5003464818     1.0810239315     0.8972584148     0.7766015201     0.6615800866     35.0305469036   

========ROUND 27========
====Feature update====
epoch            class_loss      
0                0.6521807909    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7199656963     2.5538296700     0.1661361307    
Counter({1: 11357, 0: 10921, 2: 7194})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6048457026     0.5359497666     1.1407954693     0.8904044517     0.7679153094     0.6686147186     35.1853172779   

========ROUND 28========
====Feature update====
epoch            class_loss      
0                0.8500149250    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8238725662     2.6382706165     0.1856019497    
Counter({1: 11522, 0: 10689, 2: 7261})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3753988445     0.5268579125     0.9022567272     0.8987513572     0.7764657980     0.6555194805     34.0776760578   

========ROUND 29========
====Feature update====
epoch            class_loss      
0                0.7187736630    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.9823977947     2.6838636398     0.2985342145    
Counter({1: 11783, 0: 10389, 2: 7300})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4232874811     0.4980633557     0.9213508368     0.9050285016     0.7846091205     0.6584415584     34.3270287514   

========ROUND 30========
====Feature update====
epoch            class_loss      
0                0.5763960481    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6368753910     2.5692231655     0.0676521212    
Counter({1: 12089, 0: 10331, 2: 7052})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3171359897     0.5486614108     0.8657974005     0.8994638979     0.7706297503     0.6679653680     34.2449841499   

========ROUND 31========
====Feature update====
epoch            class_loss      
0                0.6124186516    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8053743839     2.6711778641     0.1341965646    
Counter({1: 11838, 0: 10424, 2: 7210})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4337007999     0.5402339101     0.9739347100     0.9008550489     0.7711726384     0.6497835498     33.8251402378   

========ROUND 32========
====Feature update====
epoch            class_loss      
0                0.4646001160    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7744374275     2.6809368134     0.0935005844    
Counter({1: 11850, 0: 10300, 2: 7322})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4065990150     0.5780011415     0.9846001863     0.9032641151     0.7749728556     0.6602813853     35.5361223221   

========ROUND 33========
====Feature update====
epoch            class_loss      
0                0.5847490430    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6077096462     2.4853086472     0.1224010810    
Counter({1: 11487, 0: 10577, 2: 7408})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4689941108     0.6704779267     1.1394720078     0.9074036374     0.7690010858     0.6544372294     34.4410829544   

========ROUND 34========
====Feature update====
epoch            class_loss      
0                0.4453594685    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6641190052     2.5383269787     0.1257919967    
Counter({1: 12498, 0: 9693, 2: 7281})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4468840361     0.6957025528     1.1425865889     0.8909812704     0.7642508143     0.6385281385     33.8168478012   

========ROUND 35========
====Feature update====
epoch            class_loss      
0                0.7647406459    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7368178368     2.6062481403     0.1305697411    
Counter({1: 12071, 0: 10002, 2: 7399})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5885378718     0.6908418536     1.2793797255     0.9136129207     0.7756514658     0.6496753247     34.5394711494   

========ROUND 36========
====Feature update====
epoch            class_loss      
0                0.5392710567    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5949163437     2.5046827793     0.0902335569    
Counter({1: 11595, 0: 10310, 2: 7567})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3510404527     0.4789198637     0.8299603462     0.8869435396     0.7600434311     0.6406926407     33.8727576733   

========ROUND 37========
====Feature update====
epoch            class_loss      
0                0.3591150939    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7651107311     2.6916463375     0.0734644458    
Counter({1: 11332, 0: 10535, 2: 7605})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3991975784     0.5076341629     0.9068317413     0.9023140608     0.7694082519     0.6655844156     33.8455295563   

========ROUND 38========
====Feature update====
epoch            class_loss      
0                0.5945835114    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7136940956     2.6271595955     0.0865344405    
Counter({1: 11549, 0: 10765, 2: 7158})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3821717203     0.4811836779     0.8633553982     0.9066232356     0.7738870793     0.6785714286     36.3454153538   

========ROUND 39========
====Feature update====
epoch            class_loss      
0                0.5208224654    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6537575722     2.5766015053     0.0771560520    
Counter({1: 11264, 0: 10779, 2: 7429})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3335151374     0.6285412312     0.9620563984     0.9206704669     0.7847448426     0.6761904762     34.8827693462   

========ROUND 40========
====Feature update====
epoch            class_loss      
0                0.4210762680    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7097206116     2.6315999031     0.0781207457    
Counter({1: 11829, 0: 10521, 2: 7122})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3842511177     0.4581276476     0.8423787355     0.9203650923     0.7752442997     0.6623376623     34.4246311188   

========ROUND 41========
====Feature update====
epoch            class_loss      
0                0.3526630104    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6862931252     2.5645298958     0.1217632592    
Counter({1: 12256, 0: 10022, 2: 7194})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2638559043     0.4867745936     0.7506304979     0.9061142780     0.7721226927     0.6542207792     35.4691808224   

========ROUND 42========
====Feature update====
epoch            class_loss      
0                0.4610665143    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6548361778     2.5264871120     0.1283491552    
Counter({1: 11680, 0: 10328, 2: 7464})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3266523778     0.4475379288     0.7741903067     0.9144611835     0.7703583062     0.6668831169     34.5352578163   

========ROUND 43========
====Feature update====
epoch            class_loss      
0                0.4658856094    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.9001636505     2.6775627136     0.2226010412    
Counter({1: 11479, 0: 10319, 2: 7674})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3265021443     0.5497226715     0.8762248158     0.9116110206     0.7798588491     0.6506493506     34.5931806564   

========ROUND 44========
====Feature update====
epoch            class_loss      
0                0.6150268912    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5417401791     2.4391925335     0.1025475487    
Counter({1: 11585, 0: 9942, 2: 7945})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2773503065     0.5448164940     0.8221668005     0.9243010315     0.7844733985     0.6681818182     35.9039063454   

========ROUND 45========
====Feature update====
epoch            class_loss      
0                0.4275420904    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4712541103     2.4114134312     0.0598406903    
Counter({1: 11151, 0: 10063, 2: 8258})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5005230904     0.4425290823     0.9430521727     0.9118146037     0.7732084691     0.6575757576     34.2667381763   

========ROUND 46========
====Feature update====
epoch            class_loss      
0                0.4765376747    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4281065464     2.3594779968     0.0686284378    
Counter({1: 11485, 0: 9522, 2: 8465})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5835292935     0.4732503891     1.0567796230     0.9180917481     0.7801302932     0.6566017316     34.2015354633   

========ROUND 47========
====Feature update====
epoch            class_loss      
0                0.5265207887    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5807151794     2.3899109364     0.1908041984    
Counter({1: 10929, 0: 9350, 2: 9193})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3476004601     0.6045752168     0.9521756768     0.9253868078     0.7816232356     0.6745670996     34.2418174744   

========ROUND 48========
====Feature update====
epoch            class_loss      
0                0.5875456929    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5791530609     2.4418494701     0.1373036355    
Counter({1: 10949, 0: 9507, 2: 9016})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2281128615     0.6371037364     0.8652166128     0.9156148208     0.7747014115     0.6596320346     34.2765314579   

========ROUND 49========
====Feature update====
epoch            class_loss      
0                0.3898900449    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5797464848     2.5031201839     0.0766263083    
Counter({1: 11113, 2: 9192, 0: 9167})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3108060658     0.5950612426     0.9058673382     0.9296959826     0.7836590662     0.6707792208     34.3028988838   

========ROUND 50========
====Feature update====
epoch            class_loss      
0                0.4295184910    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5684812069     2.4684188366     0.1000624597    
Counter({1: 10902, 0: 9287, 2: 9283})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3194190562     0.6486521959     0.9680712223     0.9270833333     0.7797231270     0.6716450216     35.1828594208   

========ROUND 51========
====Feature update====
epoch            class_loss      
0                0.7676210403    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4759464264     2.4166545868     0.0592917204    
Counter({1: 11014, 2: 9492, 0: 8966})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.6038824916     0.5478158593     1.1516983509     0.9346498371     0.7878664495     0.6681818182     35.0707995892   

========ROUND 52========
====Feature update====
epoch            class_loss      
0                0.5042491555    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6587634087     2.5645177364     0.0942455828    
Counter({1: 10899, 0: 9423, 2: 9150})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3339515924     0.6892442107     1.0231957436     0.9254207383     0.7782301846     0.6792207792     34.6203420162   

========ROUND 53========
====Feature update====
epoch            class_loss      
0                0.4575569630    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7922527790     2.6341817379     0.1580711156    
Counter({1: 10634, 2: 9705, 0: 9133})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3922924995     0.4784808159     0.8707733154     0.9324443540     0.7820304017     0.6758658009     34.3441083431   

========ROUND 54========
====Feature update====
epoch            class_loss      
0                0.5413751006    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5660548210     2.4288609028     0.1371939927    
Counter({1: 10640, 2: 10037, 0: 8795})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2041418701     0.6462871432     0.8504289985     0.9347516287     0.7881378936     0.6791125541     34.8553605080   

========ROUND 55========
====Feature update====
epoch            class_loss      
0                0.6398332715    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8063242435     2.6004827023     0.2058414966    
Counter({2: 10933, 1: 10253, 0: 8286})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3925165832     0.8047506809     1.1972672939     0.9292548860     0.7837947883     0.6624458874     34.6010420322   

========ROUND 56========
====Feature update====
epoch            class_loss      
0                0.3242061436    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8098402023     2.6874454021     0.1223946884    
Counter({2: 11390, 1: 9879, 0: 8203})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4602544308     0.5691383481     1.0293927193     0.9153433768     0.7734799131     0.6475108225     35.9910080433   

========ROUND 57========
====Feature update====
epoch            class_loss      
0                0.5958920717    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.5874633789     2.5038208961     0.0836425424    
Counter({2: 11304, 1: 9926, 0: 8242})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3201945722     0.5612457395     0.8814402819     0.9175149294     0.7757871878     0.6680735931     34.2631139755   

========ROUND 58========
====Feature update====
epoch            class_loss      
0                0.4379213750    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6673908234     2.5650136471     0.1023771390    
Counter({2: 11777, 1: 9770, 0: 7925})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2665036619     0.5390205979     0.8055242300     0.9263707926     0.7817589577     0.6656926407     34.5139815807   

========ROUND 59========
====Feature update====
epoch            class_loss      
0                0.3779992163    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7130913734     2.6090536118     0.1040378138    
Counter({2: 11997, 1: 9379, 0: 8096})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2714731395     0.5277137160     0.7991868258     0.9329533116     0.7810803474     0.6767316017     35.4309995174   

========ROUND 60========
====Feature update====
epoch            class_loss      
0                0.6558352113    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7692534924     2.6826355457     0.0866179243    
Counter({2: 11960, 1: 9356, 0: 8156})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3593955338     0.5372421145     0.8966376781     0.9310192725     0.7843376764     0.6768398268     34.0016148090   

========ROUND 61========
====Feature update====
epoch            class_loss      
0                0.3775236607    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8382427692     2.6514625549     0.1867802292    
Counter({2: 12144, 1: 9429, 0: 7899})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2699178755     0.5569625497     0.8268804550     0.9252510858     0.7793159609     0.6664502165     35.0449883938   

========ROUND 62========
====Feature update====
epoch            class_loss      
0                0.3750217855    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7862949371     2.6916620731     0.0946329609    
Counter({2: 11402, 1: 9529, 0: 8541})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3836804628     0.5989507437     0.9826312065     0.9424538545     0.7871878393     0.6799783550     34.4298253059   

========ROUND 63========
====Feature update====
epoch            class_loss      
0                0.4982790053    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8179934025     2.6049020290     0.2130914778    
Counter({2: 11197, 1: 9626, 0: 8649})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2934967577     0.7760561109     1.0695528984     0.9310192725     0.7782301846     0.6610389610     33.8380107880   

========ROUND 64========
====Feature update====
epoch            class_loss      
0                0.7166920304    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7905607224     2.6450831890     0.1454774886    
Counter({2: 10977, 1: 9440, 0: 9055})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3150916398     0.5948459506     0.9099376202     0.9231813246     0.7741585233     0.6834415584     34.6875264645   

========ROUND 65========
====Feature update====
epoch            class_loss      
0                0.4588736296    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6924471855     2.5992419720     0.0932053253    
Counter({2: 11494, 1: 9450, 0: 8528})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2181702405     0.5315442681     0.7497144938     0.9161577090     0.7709011944     0.6656926407     33.5369048119   

========ROUND 66========
====Feature update====
epoch            class_loss      
0                0.3894305229    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6974089146     2.6027860641     0.0946228281    
Counter({2: 11499, 1: 9272, 0: 8701})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4043705165     0.5730882287     0.9774587154     0.9268797503     0.7780944625     0.6617965368     34.3625888824   

========ROUND 67========
====Feature update====
epoch            class_loss      
0                0.4117927253    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8131465912     2.6671037674     0.1460427791    
Counter({2: 11518, 1: 9280, 0: 8674})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5325889587     0.7696070671     1.3021960258     0.9313585776     0.7809446254     0.6820346320     34.7938303947   

========ROUND 68========
====Feature update====
epoch            class_loss      
0                0.5940369368    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7485566139     2.6479494572     0.1006071791    
Counter({2: 11400, 1: 9487, 0: 8585})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3622473776     0.6117153168     0.9739626646     0.9339372964     0.7836590662     0.6833333333     33.5368068218   

========ROUND 69========
====Feature update====
epoch            class_loss      
0                0.3456135690    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6809852123     2.5791680813     0.1018172130    
Counter({2: 11240, 1: 9476, 0: 8756})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2279207110     0.4447106421     0.6726313829     0.9418431053     0.7859663409     0.6783549784     34.5932703018   

========ROUND 70========
====Feature update====
epoch            class_loss      
0                0.4293191433    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6942706108     2.5877664089     0.1065042615    
Counter({2: 11449, 1: 9709, 0: 8314})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4667080939     0.5602392554     1.0269473791     0.9321729099     0.7820304017     0.6728354978     34.7234559059   

========ROUND 71========
====Feature update====
epoch            class_loss      
0                0.2480831295    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7843914032     2.6680910587     0.1163002253    
Counter({2: 11415, 1: 9491, 0: 8566})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2549451590     0.5801661015     0.8351112604     0.9359731270     0.7813517915     0.6624458874     34.9269170761   

========ROUND 72========
====Feature update====
epoch            class_loss      
0                0.4083526433    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6900346279     2.5929195881     0.0971149281    
Counter({2: 11568, 1: 9615, 0: 8289})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2701479197     0.7371299863     1.0072779655     0.9285084148     0.7759229099     0.6572510823     34.2990906239   

========ROUND 73========
====Feature update====
epoch            class_loss      
0                0.3234480917    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7833354473     2.6352651119     0.1480704397    
Counter({2: 11436, 1: 9537, 0: 8499})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3499487936     0.4913434088     0.8412922025     0.9414698697     0.7823018458     0.6839826840     34.8969995975   

========ROUND 74========
====Feature update====
epoch            class_loss      
0                0.3148912489    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7542936802     2.6479873657     0.1063063443    
Counter({2: 11285, 1: 9578, 0: 8609})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3398747444     0.5715845823     0.9114593267     0.9325800760     0.7786373507     0.6703463203     33.8435440063   

========ROUND 75========
====Feature update====
epoch            class_loss      
0                0.3891254961    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6472783089     2.5800094604     0.0672689304    
Counter({2: 11011, 1: 9720, 0: 8741})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2445316762     0.5760073066     0.8205389977     0.9305442454     0.7732084691     0.6658008658     34.2232608795   

========ROUND 76========
====Feature update====
epoch            class_loss      
0                0.6864356399    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7978506088     2.6311662197     0.1666842848    
Counter({2: 10991, 1: 9446, 0: 9035})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4916590154     0.5128355026     1.0044945478     0.9395019001     0.7858306189     0.6674242424     35.1035985947   

========ROUND 77========
====Feature update====
epoch            class_loss      
0                0.2755688727    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7218105793     2.5643484592     0.1574621350    
Counter({2: 10862, 0: 9307, 1: 9303})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4034079015     0.5954677463     0.9988756180     0.9341069490     0.7771444083     0.6700216450     34.3268363476   

========ROUND 78========
====Feature update====
epoch            class_loss      
0                0.3994104564    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6889317036     2.5986750126     0.0902567804    
Counter({2: 10931, 1: 9489, 0: 9052})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2773542106     0.5140548348     0.7914090157     0.9451004343     0.7911237785     0.6748917749     33.9340503216   

========ROUND 79========
====Feature update====
epoch            class_loss      
0                0.3176493347    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7555298805     2.6575949192     0.0979350507    
Counter({2: 11088, 0: 9226, 1: 9158})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3714100122     0.5010858178     0.8724958301     0.9341408795     0.7810803474     0.6753246753     34.9641652107   

========ROUND 80========
====Feature update====
epoch            class_loss      
0                0.2962521613    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7869930267     2.5790319443     0.2079609632    
Counter({2: 10870, 1: 9468, 0: 9134})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5560178161     0.6635910869     1.2196089029     0.9331229642     0.7748371336     0.6836580087     34.1940217018   

========ROUND 81========
====Feature update====
epoch            class_loss      
0                0.4225839674    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6425864697     2.5810062885     0.0615800656    
Counter({2: 10736, 1: 9644, 0: 9092})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4636554718     0.5230292678     0.9866847396     0.9422502714     0.7804017372     0.6741341991     33.9900407791   

========ROUND 82========
====Feature update====
epoch            class_loss      
0                0.2490063757    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6976816654     2.6587345600     0.0389470570    
Counter({2: 10529, 0: 9551, 1: 9392})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3503905833     0.6507866979     1.0011773109     0.9368892508     0.7809446254     0.6579004329     34.7488420010   

========ROUND 83========
====Feature update====
epoch            class_loss      
0                0.3188367188    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6431381702     2.5932912827     0.0498469137    
Counter({2: 10642, 0: 9616, 1: 9214})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2952578366     0.4961942434     0.7914520502     0.9253528773     0.7673724213     0.6632034632     34.1205005646   

========ROUND 84========
====Feature update====
epoch            class_loss      
0                0.3921604455    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7290723324     2.5490920544     0.1799802780    
Counter({2: 10676, 0: 9685, 1: 9111})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3791657686     0.5071483850     0.8863141537     0.9208401194     0.7671009772     0.6613636364     34.4990379810   

========ROUND 85========
====Feature update====
epoch            class_loss      
0                0.1804105490    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6274063587     2.5626981258     0.0647082701    
Counter({2: 10523, 0: 10172, 1: 8777})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3549429476     0.4852353334     0.8401782513     0.9384161238     0.7771444083     0.6770562771     34.7354154587   

========ROUND 86========
====Feature update====
epoch            class_loss      
0                0.4876078665    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7924129963     2.6276614666     0.1647515297    
Counter({2: 10601, 0: 10030, 1: 8841})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3757295609     0.8610207438     1.2367503643     0.9393661781     0.7847448426     0.6699134199     34.2179305553   

========ROUND 87========
====Feature update====
epoch            class_loss      
0                0.2619878352    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7326390743     2.6681487560     0.0644903257    
Counter({2: 10490, 0: 10023, 1: 8959})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2170038372     0.5314906836     0.7484945059     0.9392304560     0.7802660152     0.6653679654     34.0448257923   

========ROUND 88========
====Feature update====
epoch            class_loss      
0                0.2965283096    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8275713921     2.6555538177     0.1720176488    
Counter({2: 10258, 0: 10231, 1: 8983})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3747046292     0.5921201110     0.9668247700     0.9390608035     0.7778230185     0.6610389610     34.6371603012   

========ROUND 89========
====Feature update====
epoch            class_loss      
0                0.2759552896    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6753802299     2.6214897633     0.0538904630    
Counter({0: 10589, 2: 10083, 1: 8800})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3469554484     0.5351075530     0.8820630312     0.9446593377     0.7768729642     0.6744588745     34.5155088902   

========ROUND 90========
====Feature update====
epoch            class_loss      
0                0.5030139089    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6719164848     2.5931751728     0.0787413940    
Counter({0: 10565, 2: 10182, 1: 8725})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3346847594     0.6758756042     1.0105603933     0.9425217155     0.7766015201     0.6812770563     33.6341753006   

========ROUND 91========
====Feature update====
epoch            class_loss      
0                0.4836484492    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6650536060     2.5690977573     0.0959558412    
Counter({0: 10908, 2: 10002, 1: 8562})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2769287229     0.5766394734     0.8535681963     0.9477130836     0.7866449511     0.6735930736     34.8030087948   

========ROUND 92========
====Feature update====
epoch            class_loss      
0                0.2591603398    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7626099586     2.6355915070     0.1270183325    
Counter({0: 10900, 2: 9951, 1: 8621})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3870555162     0.5602900386     0.9473455548     0.9329533116     0.7711726384     0.6599567100     33.8505887985   

========ROUND 93========
====Feature update====
epoch            class_loss      
0                0.4068953693    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7144823074     2.6526446342     0.0618377179    
Counter({0: 10646, 2: 10177, 1: 8649})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2260121852     0.6433795094     0.8693916798     0.9438450054     0.7867806732     0.6660173160     33.9541227818   

========ROUND 94========
====Feature update====
epoch            class_loss      
0                0.3514759243    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6950790882     2.6180534363     0.0770255551    
Counter({0: 11002, 2: 9843, 1: 8627})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1664312333     0.4962700605     0.6627013087     0.9394679696     0.7723941368     0.6621212121     35.0064988136   

========ROUND 95========
====Feature update====
epoch            class_loss      
0                0.4363745153    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6023414135     2.5446014404     0.0577399246    
Counter({0: 10670, 2: 10059, 1: 8743})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3007638454     0.6322863698     0.9330502152     0.9430985342     0.7837947883     0.6759740260     33.9704840183   

========ROUND 96========
====Feature update====
epoch            class_loss      
0                0.3236129582    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6047494411     2.5648174286     0.0399320759    
Counter({0: 10646, 2: 10197, 1: 8629})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5201271176     0.6443402767     1.1644673347     0.9271511944     0.7681867535     0.6590909091     35.5482749939   

========ROUND 97========
====Feature update====
epoch            class_loss      
0                0.5738243461    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7446813583     2.5979063511     0.1467750669    
Counter({0: 10648, 2: 10279, 1: 8545})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2711934745     0.5633486509     0.8345421553     0.9435057003     0.7785016287     0.6743506494     35.9745628834   

========ROUND 98========
====Feature update====
epoch            class_loss      
0                0.3480475843    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6816036701     2.6051840782     0.0764196590    
Counter({0: 11023, 2: 10032, 1: 8417})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2606359720     0.5965254903     0.8571614623     0.9416734528     0.7742942454     0.6622294372     35.5024130344   

========ROUND 99========
====Feature update====
epoch            class_loss      
0                0.3268188238    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.9312911034     2.7685317993     0.1627593189    
Counter({0: 11017, 2: 10103, 1: 8352})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3275258839     0.5986115932     0.9261374474     0.9314603692     0.7729370250     0.6586580087     35.0626163483   

========ROUND 100========
====Feature update====
epoch            class_loss      
0                0.5496939421    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6943733692     2.6211931705     0.0731802657    
Counter({0: 11244, 2: 10012, 1: 8216})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2876162827     0.6417469978     0.9293632507     0.9422502714     0.7785016287     0.6687229437     34.4742543697   

========ROUND 101========
====Feature update====
epoch            class_loss      
0                0.4553429186    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8356068134     2.7506601810     0.0849466845    
Counter({0: 11283, 2: 9941, 1: 8248})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2649540007     0.5819565654     0.8469105959     0.9308835505     0.7691368078     0.6619047619     32.7408156395   

========ROUND 102========
====Feature update====
epoch            class_loss      
0                0.8020923138    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7218210697     2.6032574177     0.1185636222    
Counter({0: 11052, 2: 9845, 1: 8575})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3311297894     0.5988475680     0.9299773574     0.9384839848     0.7745656895     0.6717532468     32.8263075352   

========ROUND 103========
====Feature update====
epoch            class_loss      
0                0.2859421372    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6511189938     2.5587437153     0.0923752561    
Counter({0: 10998, 2: 10080, 1: 8394})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4349625409     0.5908227563     1.0257853270     0.9477130836     0.7791802389     0.6833333333     35.5850398540   

========ROUND 104========
====Feature update====
epoch            class_loss      
0                0.4475880563    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6250884533     2.5298626423     0.0952256992    
Counter({0: 11135, 2: 9907, 1: 8430})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3483605385     0.5783261657     0.9266867042     0.9393661781     0.7757871878     0.6612554113     33.2005069256   

========ROUND 105========
====Feature update====
epoch            class_loss      
0                0.3654239476    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7154438496     2.6625983715     0.0528455228    
Counter({0: 11296, 2: 9912, 1: 8264})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2063518912     0.5181064010     0.7244582772     0.9308835505     0.7780944625     0.6617965368     34.3909602165   

========ROUND 106========
====Feature update====
epoch            class_loss      
0                0.4668048322    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6340939999     2.5982532501     0.0358408578    
Counter({0: 11155, 2: 10067, 1: 8250})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2926972210     0.8121604323     1.1048576832     0.9363124321     0.7744299674     0.6675324675     35.4946157932   

========ROUND 107========
====Feature update====
epoch            class_loss      
0                0.3507852852    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7137877941     2.6272912025     0.0864966735    
Counter({0: 11511, 2: 9767, 1: 8194})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4240694940     0.5960897207     1.0201592445     0.9305103149     0.7728013029     0.6649350649     39.0889978409   

========ROUND 108========
====Feature update====
epoch            class_loss      
0                0.5149777532    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8477017879     2.6671259403     0.1805758476    
Counter({0: 11590, 2: 9863, 1: 8019})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2742144465     0.5310116410     0.8052260876     0.9451343648     0.7778230185     0.6859307359     36.2128140926   

========ROUND 109========
====Feature update====
epoch            class_loss      
0                0.3721275330    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.4855377674     2.4472644329     0.0382732563    
Counter({0: 11403, 2: 9889, 1: 8180})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2345452905     0.6639969945     0.8985422850     0.9378732356     0.7749728556     0.6622294372     36.7044460773   

========ROUND 110========
====Feature update====
epoch            class_loss      
0                0.4481630325    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7815828323     2.5438189507     0.2377638072    
Counter({0: 11260, 2: 9980, 1: 8232})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2876576483     0.4960621297     0.7837197781     0.9394001086     0.7711726384     0.6660173160     35.8021774292   

========ROUND 111========
====Feature update====
epoch            class_loss      
0                0.6784070134    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6076881886     2.5654881001     0.0422000475    
Counter({0: 11745, 2: 9575, 1: 8152})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3247255385     0.5283435583     0.8530690670     0.9458469055     0.7816232356     0.6738095238     35.8306155205   

========ROUND 112========
====Feature update====
epoch            class_loss      
0                0.4335859716    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6600942612     2.5856111050     0.0744830891    
Counter({0: 11503, 2: 9682, 1: 8287})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2538418472     0.5655207634     0.8193626404     0.9183631922     0.7612649294     0.6635281385     35.1780631542   

========ROUND 113========
====Feature update====
epoch            class_loss      
0                0.7492325902    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6505293846     2.4801216125     0.1704077125    
Counter({0: 11330, 2: 9834, 1: 8308})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.5280225873     0.6675159335     1.1955385208     0.9430985342     0.7760586319     0.6709956710     35.1086235046   

========ROUND 114========
====Feature update====
epoch            class_loss      
0                0.3659163415    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.8747267723     2.7962830067     0.0784438252    
Counter({0: 11618, 2: 9785, 1: 8069})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4140107632     0.6910056472     1.1050164700     0.9281012486     0.7684581976     0.6729437229     35.8456482887   

========ROUND 115========
====Feature update====
epoch            class_loss      
0                0.2096120566    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7898736000     2.6710813046     0.1187923551    
Counter({0: 11638, 2: 9614, 1: 8220})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4089560509     0.6852238774     1.0941798687     0.9337676439     0.7707654723     0.6689393939     35.3652482033   

========ROUND 116========
====Feature update====
epoch            class_loss      
0                0.2936457992    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.6863358021     2.6087520123     0.0775837675    
Counter({0: 11941, 2: 9500, 1: 8031})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3602293730     0.5598244071     0.9200537801     0.9449307818     0.7775515744     0.6658008658     35.6205561161   

========ROUND 117========
====Feature update====
epoch            class_loss      
0                0.3122650981    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7282919884     2.6508414745     0.0774504840    
Counter({0: 11900, 2: 9539, 1: 8033})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3822760880     0.6220620275     1.0043381453     0.9492399566     0.7791802389     0.6800865801     35.3104631901   

========ROUND 118========
====Feature update====
epoch            class_loss      
0                0.2106516808    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7120368481     2.5958178043     0.1162190214    
Counter({0: 12054, 2: 9390, 1: 8028})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2828211188     0.5487912893     0.8316124082     0.9385857763     0.7759229099     0.6688311688     35.1893498898   

========ROUND 119========
====Feature update====
epoch            class_loss      
0                0.3778638542    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                2.7527647018     2.7033755779     0.0493890531    
Counter({0: 12190, 2: 9337, 1: 7945})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1681128740     0.5496399403     0.7177528143     0.9476452226     0.7760586319     0.6603896104     36.1463634968   
Target acc: 0.6749
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 12, in <module>
  File "<string>", line 1, in <module>
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\spawn.py", line 105, in spawn_main
    for data in train_loader:
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 444, in __iter__
    exitcode = _main(fd)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\spawn.py", line 114, in _main
    prepare(preparation_data)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\spawn.py", line 225, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\spawn.py", line 277, in _fixup_main_from_path
    run_name="__mp_main__")
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\runpy.py", line 263, in run_path
    pkg_name=pkg_name, script_name=fname)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\runpy.py", line 96, in _run_module_code
    mod_name, mod_spec, pkg_name, script_name)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "E:\robustlearn\diversify\test.py", line 12, in <module>
    for data in train_loader:
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 444, in __iter__
    return self._get_iterator()
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 390, in _get_iterator
    return self._get_iterator()
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 390, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 1077, in __init__
    return _MultiProcessingDataLoaderIter(self)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 1077, in __init__
    w.start()
      File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\process.py", line 112, in start
w.start()
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\process.py", line 112, in start
    self._popen = self._Popen(self)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 322, in _Popen
    return Popen(process_obj)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\popen_spawn_win32.py", line 46, in __init__
    self._popen = self._Popen(self)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 322, in _Popen
    return Popen(process_obj)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\popen_spawn_win32.py", line 89, in __init__
        prep_data = spawn.get_preparation_data(process_obj._name)reduction.dump(process_obj, to_child)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\reduction.py", line 60, in dump
ration_data
    _check_not_importing_main()
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\multiprocessing\spawn.py", line 136, in _check_not_importing_main
    is not going to be frozen to produce an executable.''')
RuntimeError: 
        An attempt has been made to start a new process before the
        current process has finished its bootstrapping phase.

        This probably means that you are not using fork to start your
        child processes and you have forgotten to use the proper idiom
        in the main module:

            if __name__ == '__main__':
                freeze_support()
                ...

        The "freeze_support()" line can be omitted if the program
        is not going to be frozen to produce an executable.
    ForkingPickler(file, protocol).dump(obj)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 12, in <module>
    for data in train_loader:
KeyboardInterrupt
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 7, in <module>
    model = torch.load("model.pth")
KeyboardInterrupt
Traceback (most recent call last):
  File "C:/Program Files/JetBrains/PyCharm 2021.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "E:\robustlearn\diversify\test.py", line 13, in <module>
    output = model(data)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 201, in _forward_unimplemented
    raise NotImplementedError(f"Module [{type(self).__name__}] is missing the required \"forward\" function")
NotImplementedError: Module [Diversify] is missing the required "forward" function
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 14, in <module>
    print(output)
KeyboardInterrupt
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 13, in <module>
    output = modelopera.accuracy(model, target_loader, None)
  File "E:\robustlearn\diversify\alg\modelopera.py", line 20, in accuracy
    for data in loader:
KeyboardInterrupt
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 14, in <module>
    print(output)
KeyboardInterrupt
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 14, in <module>
    print(output)
KeyboardInterrupt
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 13, in <module>
    output = modelopera.accuracy(model, target_loader, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 42, in accuracy
    total += batch_weights.sum().item()
KeyboardInterrupt
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 13, in <module>
    output = modelopera.accuracy(model, target_loader, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 24, in accuracy
    p = network.predict(x)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 148, in predict
    return self.classifier(self.bottleneck(self.featurizer(x)))
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\robustlearn\diversify\network\common_network.py", line 39, in forward
    return x
KeyboardInterrupt
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 13, in <module>
    output = modelopera.accuracy(model, target_loader, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 40, in accuracy
    correct += (p.argmax(1).eq(y).float() *
KeyboardInterrupt
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 13, in <module>
    output = modelopera.accuracy(model, target_loader, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 22, in accuracy
    x = data[0].cuda().float()
KeyboardInterrupt
Traceback (most recent call last):
  File "E:\robustlearn\diversify\alg\modelopera.py", line 43, in accuracy
    t = p.argmax(1).numpy()
TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.
Traceback (most recent call last):
  File "E:\robustlearn\diversify\alg\modelopera.py", line 44, in accuracy
    class_predict = np.concatenate(class_predict, t)
  File "<__array_function__ internals>", line 6, in concatenate
TypeError: only integer scalar arrays can be converted to a scalar index
Traceback (most recent call last):
  File "E:\robustlearn\diversify\alg\modelopera.py", line 43, in accuracy
    t = p.argmax(1).cpu().data().numpy()
TypeError: 'Tensor' object is not callable
Traceback (most recent call last):
  File "E:\robustlearn\diversify\alg\modelopera.py", line 44, in accuracy
    class_predict = np.concatenate(class_predict, t)
  File "<__array_function__ internals>", line 6, in concatenate
TypeError: only integer scalar arrays can be converted to a scalar index
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 13, in <module>
    output = modelopera.accuracy(model, target_loader, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 44, in accuracy
    class_predict = np.concatenate(class_predict, t)
KeyboardInterrupt
Traceback (most recent call last):
  File "C:/Program Files/JetBrains/PyCharm 2021.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "E:\robustlearn\diversify\test.py", line 13, in <module>
    output = modelopera.accuracy(model, target_loader, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 49, in accuracy
    _, labels = loader[:]
TypeError: 'DataLoader' object is not subscriptable
Traceback (most recent call last):
  File "C:/Program Files/JetBrains/PyCharm 2021.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "E:\robustlearn\diversify\test.py", line 13, in <module>
    output = modelopera.accuracy(model, target_loader, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 50, in accuracy
    _, labels = loader.dataset
ValueError: too many values to unpack (expected 2)
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 13, in <module>
    output = modelopera.accuracy(model, target_loader, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 50, in accuracy
    _, labels = loader.dataset
KeyboardInterrupt
              precision    recall  f1-score   support

         0.0       0.65      0.73      0.69       800
         1.0       0.65      0.79      0.71       440
         2.0       0.67      0.75      0.71       440
         3.0       0.70      0.60      0.64       640
         4.0       0.80      0.76      0.78       680
         5.0       0.78      0.84      0.81       480
         6.0       0.52      0.65      0.58       360
         7.0       0.41      0.57      0.48       440
         8.0       0.72      0.47      0.57       800
         9.0       0.63      0.88      0.73       480
        10.0       0.85      0.64      0.73       800
        11.0       0.53      0.60      0.56       600
        12.0       0.52      0.66      0.58       520
        13.0       0.71      0.46      0.56       560
        14.0       0.69      0.55      0.61       640
        15.0       0.81      0.75      0.78       560

    accuracy                           0.66      9240
   macro avg       0.66      0.67      0.66      9240
weighted avg       0.68      0.66      0.66      9240

Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 13, in <module>
    output = modelopera.accuracy(model, target_loader, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 53, in accuracy
    return correct / total
KeyboardInterrupt
              precision    recall  f1-score   support

         0.0       0.06      0.06      0.06      1679
         1.0       0.06      0.06      0.06      1950
         2.0       0.07      0.07      0.07      1954
         3.0       0.06      0.06      0.06      1783
         4.0       0.06      0.06      0.06      1775
         5.0       0.06      0.06      0.06      1927
         6.0       0.07      0.07      0.07      2015
         7.0       0.06      0.07      0.06      1922
         8.0       0.07      0.07      0.07      1679
         9.0       0.06      0.07      0.06      1909
        10.0       0.05      0.05      0.05      1650
        11.0       0.06      0.06      0.06      1851
        12.0       0.06      0.06      0.06      1896
        13.0       0.06      0.06      0.06      1843
        14.0       0.06      0.05      0.05      1789
        15.0       0.07      0.07      0.07      1850

    accuracy                           0.06     29472
   macro avg       0.06      0.06      0.06     29472
weighted avg       0.06      0.06      0.06     29472

Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 13, in <module>
    output = modelopera.accuracy(model, train_loader, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 53, in accuracy
    return correct / total
KeyboardInterrupt
              precision    recall  f1-score   support

         0.0       0.91      0.95      0.93      1679
         1.0       0.98      0.96      0.97      1950
         2.0       0.96      0.97      0.96      1954
         3.0       0.96      0.95      0.96      1783
         4.0       0.97      0.96      0.96      1775
         5.0       0.98      0.96      0.97      1927
         6.0       0.92      0.92      0.92      2015
         7.0       0.87      0.95      0.91      1922
         8.0       0.98      0.95      0.96      1679
         9.0       0.90      0.97      0.93      1909
        10.0       0.98      0.92      0.95      1650
        11.0       0.92      0.94      0.93      1851
        12.0       0.94      0.96      0.95      1896
        13.0       0.97      0.92      0.94      1843
        14.0       0.97      0.89      0.93      1789
        15.0       0.99      0.99      0.99      1850

    accuracy                           0.95     29472
   macro avg       0.95      0.95      0.95     29472
weighted avg       0.95      0.95      0.95     29472

Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 13, in <module>
    output = modelopera.accuracy(model, train_loader_noshuffle, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 53, in accuracy
    return correct / total
KeyboardInterrupt
              precision    recall  f1-score   support

         0.0       0.74      0.82      0.78       401
         1.0       0.85      0.83      0.84       490
         2.0       0.81      0.83      0.82       486
         3.0       0.81      0.79      0.80       457
         4.0       0.76      0.77      0.77       425
         5.0       0.88      0.83      0.86       473
         6.0       0.79      0.80      0.79       505
         7.0       0.62      0.72      0.67       518
         8.0       0.82      0.78      0.80       401
         9.0       0.74      0.79      0.76       491
        10.0       0.78      0.72      0.75       430
        11.0       0.72      0.76      0.74       429
        12.0       0.74      0.75      0.74       464
        13.0       0.80      0.72      0.76       477
        14.0       0.79      0.70      0.74       451
        15.0       0.83      0.83      0.83       470

    accuracy                           0.78      7368
   macro avg       0.78      0.78      0.78      7368
weighted avg       0.78      0.78      0.78      7368

Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 13, in <module>
    output = modelopera.accuracy(model, valid_loader, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 27, in accuracy
    p = network.predict(x)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 148, in predict
    return self.classifier(self.bottleneck(self.featurizer(x)))
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\robustlearn\diversify\network\common_network.py", line 39, in forward
    return x
KeyboardInterrupt
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 13, in <module>
    output = modelopera.accuracy(model, valid_loader, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 27, in accuracy
    p = network.predict(x)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 148, in predict
    return self.classifier(self.bottleneck(self.featurizer(x)))
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\robustlearn\diversify\network\common_network.py", line 38, in forward
    x = self.fc(x)
KeyboardInterrupt
Traceback (most recent call last):
  File "C:/Program Files/JetBrains/PyCharm 2021.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "E:\robustlearn\diversify\test.py", line 11, in <module>
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 40, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 18, in __init__
    x, cy, py, sy = loaddata_from_numpy(self.dataset, self.task, root_dir)
  File "E:\robustlearn\diversify\datautil\actdata\util.py", line 45, in loaddata_from_numpy
    tsne_results = TSNE(n_components=2, learning_rate='auto',init = 'random', perplexity = 3).fit_transform(x_train)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\sklearn\manifold\_t_sne.py", line 1108, in fit_transform
    embedding = self._fit(X)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\sklearn\manifold\_t_sne.py", line 834, in _fit
    dtype=[np.float32, np.float64],
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\sklearn\base.py", line 566, in _validate_data
    X = check_array(X, **check_params)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\sklearn\utils\validation.py", line 796, in check_array
    % (array.ndim, estimator_name)
ValueError: Found array with dim 3. Estimator expected <= 2.
Traceback (most recent call last):
  File "C:/Program Files/JetBrains/PyCharm 2021.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "E:\robustlearn\diversify\test.py", line 11, in <module>
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 40, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 18, in __init__
    x, cy, py, sy = loaddata_from_numpy(self.dataset, self.task, root_dir)
  File "E:\robustlearn\diversify\datautil\actdata\util.py", line 45, in loaddata_from_numpy
    tsne_results = TSNE(n_components=3, learning_rate='auto',init = 'random', perplexity = 3).fit_transform(x_train)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\sklearn\manifold\_t_sne.py", line 1108, in fit_transform
    embedding = self._fit(X)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\sklearn\manifold\_t_sne.py", line 834, in _fit
    dtype=[np.float32, np.float64],
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\sklearn\base.py", line 566, in _validate_data
    X = check_array(X, **check_params)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\sklearn\utils\validation.py", line 796, in check_array
    % (array.ndim, estimator_name)
ValueError: Found array with dim 3. Estimator expected <= 2.
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 11, in <module>
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 40, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 18, in __init__
    x, cy, py, sy = loaddata_from_numpy(self.dataset, self.task, root_dir)
  File "E:\robustlearn\diversify\datautil\actdata\util.py", line 45, in loaddata_from_numpy
    tsne_results = TSNE(n_components=16, learning_rate='auto',init = 'random', perplexity = 3).fit_transform(x_train)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\sklearn\manifold\_t_sne.py", line 1108, in fit_transform
    embedding = self._fit(X)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\sklearn\manifold\_t_sne.py", line 863, in _fit
    "'n_components' should be inferior to 4 for the "
ValueError: 'n_components' should be inferior to 4 for the barnes_hut algorithm as it relies on quad-tree or oct-tree.
Traceback (most recent call last):
  File "C:/Program Files/JetBrains/PyCharm 2021.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "E:\robustlearn\diversify\test.py", line 11, in <module>
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 40, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 18, in __init__
    x, cy, py, sy = loaddata_from_numpy(self.dataset, self.task, root_dir)
  File "E:\robustlearn\diversify\datautil\actdata\util.py", line 45, in loaddata_from_numpy
    tsne_results = TSNE(n_components=16, learning_rate='auto',init = 'random', perplexity = 3).fit_transform(x_train)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\sklearn\manifold\_t_sne.py", line 1108, in fit_transform
    embedding = self._fit(X)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\sklearn\manifold\_t_sne.py", line 863, in _fit
    "'n_components' should be inferior to 4 for the "
ValueError: 'n_components' should be inferior to 4 for the barnes_hut algorithm as it relies on quad-tree or oct-tree.
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 11, in <module>
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 40, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 18, in __init__
    x, cy, py, sy = loaddata_from_numpy(self.dataset, self.task, root_dir)
  File "E:\robustlearn\diversify\datautil\actdata\util.py", line 46, in loaddata_from_numpy
    tsne_results = pd.DataFrame(tsne_results, columns=['tsne1', 'tsne2'])
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\pandas\core\frame.py", line 678, in __init__
    typ=manager,
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\pandas\core\internals\construction.py", line 324, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\pandas\core\internals\construction.py", line 393, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (36840, 3), indices imply (36840, 2)
Traceback (most recent call last):
  File "C:/Program Files/JetBrains/PyCharm 2021.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "E:\robustlearn\diversify\test.py", line 11, in <module>
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 40, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 22, in __init__
    self.x = self.x[:, :, np.newaxis, :]
IndexError: too many indices for array: array is 2-dimensional, but 3 were indexed
Traceback (most recent call last):
  File "C:/Program Files/JetBrains/PyCharm 2021.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "E:\robustlearn\diversify\test.py", line 11, in <module>
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 40, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 18, in __init__
    x, cy, py, sy = loaddata_from_numpy(self.dataset, self.task, root_dir)
  File "E:\robustlearn\diversify\datautil\actdata\util.py", line 72, in loaddata_from_numpy
    tsne_results = TSNE(n_components=2, learning_rate='auto',init = 'random', perplexity = 16).fit_transform(data_x)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\sklearn\manifold\_t_sne.py", line 1108, in fit_transform
    embedding = self._fit(X)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\sklearn\manifold\_t_sne.py", line 834, in _fit
    dtype=[np.float32, np.float64],
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\sklearn\base.py", line 566, in _validate_data
    X = check_array(X, **check_params)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\sklearn\utils\validation.py", line 796, in check_array
    % (array.ndim, estimator_name)
ValueError: Found array with dim 3. Estimator expected <= 2.
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 11, in <module>
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 40, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 18, in __init__
    x, cy, py, sy = loaddata_from_numpy(self.dataset, self.task, root_dir)
  File "E:\robustlearn\diversify\datautil\actdata\util.py", line 85, in loaddata_from_numpy
    return x_train, cy, py, sy
KeyboardInterrupt
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 12, in <module>
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 40, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 18, in __init__
    x, cy, py, sy = loaddata_from_numpy(self.dataset, self.task, root_dir)
  File "E:\robustlearn\diversify\datautil\actdata\util.py", line 107, in loaddata_from_numpy
    return x_train, cy, py, sy
KeyboardInterrupt
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 11, in <module>
    train_loader, train_loader_noshuffle, valid_loader, target_loader, _, _, _ = get_act_dataloader(
KeyboardInterrupt
Traceback (most recent call last):
  File "E:\robustlearn\diversify\alg\modelopera.py", line 27, in accuracy
    p = network.predict(x)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 148, in predict
    return self.classifier(self.bottleneck(self.featurizer(x)))
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\robustlearn\diversify\network\act_network.py", line 38, in forward
    x = self.conv2(self.conv1(x))
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\container.py", line 139, in forward
    input = module(input)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\conv.py", line 454, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Given groups=1, weight of size [16, 5, 1, 9], expected input[32, 8000, 1, 5] to have 5 channels, but got 8000 channels instead
Traceback (most recent call last):
  File "E:\robustlearn\diversify\alg\modelopera.py", line 27, in accuracy
    p = network.predict(x)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 148, in predict
    return self.classifier(self.bottleneck(self.featurizer(x)))
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\robustlearn\diversify\network\act_network.py", line 39, in forward
    x = x.view(-1, self.in_features)
RuntimeError: shape '[-1, 1408]' is invalid for input of size 2041856
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 12, in <module>
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 40, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 18, in __init__
    x, cy, py, sy = loaddata_from_numpy(self.dataset, self.task, root_dir)
  File "E:\robustlearn\diversify\datautil\actdata\util.py", line 108, in loaddata_from_numpy
    return x_train, cy, py, sy
KeyboardInterrupt
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 12, in <module>
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 40, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 18, in __init__
    x, cy, py, sy = loaddata_from_numpy(self.dataset, self.task, root_dir)
  File "E:\robustlearn\diversify\datautil\actdata\util.py", line 72, in loaddata_from_numpy
    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[2], x_train.shape[1]))
KeyboardInterrupt
              precision    recall  f1-score   support

           0       0.60      0.60      0.60         5
           1       1.00      1.00      1.00         3
           2       1.00      1.00      1.00         5
           3       1.00      0.88      0.93         8
           4       1.00      0.75      0.86         8
           5       1.00      1.00      1.00         4
           6       0.88      1.00      0.93         7
           7       1.00      0.89      0.94         9
           8       0.89      1.00      0.94         8
           9       1.00      1.00      1.00         7
          10       1.00      1.00      1.00         7
          11       0.86      1.00      0.92         6
          12       0.88      1.00      0.93         7
          13       1.00      1.00      1.00        10
          14       0.80      0.80      0.80         5
          15       1.00      1.00      1.00         5

    accuracy                           0.93       104
   macro avg       0.93      0.93      0.93       104
weighted avg       0.94      0.93      0.93       104

0.9326923076923077
              precision    recall  f1-score   support

           0       0.45      1.00      0.62         5
           1       1.00      1.00      1.00         3
           2       1.00      1.00      1.00         5
           3       0.50      0.25      0.33         8
           4       0.80      1.00      0.89         8
           5       0.60      0.75      0.67         4
           6       1.00      0.29      0.44         7
           7       0.82      1.00      0.90         9
           8       0.50      0.38      0.43         8
           9       0.78      1.00      0.88         7
          10       1.00      0.14      0.25         7
          11       0.33      0.83      0.48         6
          12       0.67      0.86      0.75         7
          13       1.00      0.70      0.82        10
          14       0.60      0.60      0.60         5
          15       1.00      0.20      0.33         5

    accuracy                           0.67       104
   macro avg       0.75      0.69      0.65       104
weighted avg       0.76      0.67      0.65       104

Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 15, in <module>
    print(output)
KeyboardInterrupt
              precision    recall  f1-score   support

           0       0.83      1.00      0.91         5
           1       1.00      0.67      0.80         3
           2       1.00      0.80      0.89         5
           3       1.00      1.00      1.00         8
           4       1.00      1.00      1.00         8
           5       1.00      1.00      1.00         4
           6       1.00      0.86      0.92         7
           7       1.00      1.00      1.00         9
           8       0.83      0.62      0.71         8
           9       0.70      1.00      0.82         7
          10       0.75      0.86      0.80         7
          11       1.00      1.00      1.00         6
          12       1.00      1.00      1.00         7
          13       1.00      1.00      1.00        10
          14       0.80      0.80      0.80         5
          15       1.00      1.00      1.00         5

    accuracy                           0.92       104
   macro avg       0.93      0.91      0.92       104
weighted avg       0.93      0.92      0.92       104

Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 15, in <module>
    print(output)
KeyboardInterrupt
              precision    recall  f1-score   support

           0       0.71      1.00      0.83         5
           1       0.50      0.67      0.57         3
           2       1.00      1.00      1.00         5
           3       0.89      1.00      0.94         8
           4       1.00      1.00      1.00         8
           5       1.00      1.00      1.00         4
           6       0.88      1.00      0.93         7
           7       0.67      0.22      0.33         9
           8       1.00      1.00      1.00         8
           9       1.00      1.00      1.00         7
          10       1.00      0.71      0.83         7
          11       0.60      1.00      0.75         6
          12       0.86      0.86      0.86         7
          13       1.00      0.90      0.95        10
          14       0.80      0.80      0.80         5
          15       1.00      1.00      1.00         5

    accuracy                           0.88       104
   macro avg       0.87      0.89      0.86       104
weighted avg       0.88      0.88      0.86       104

Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 15, in <module>
    print(output)
KeyboardInterrupt
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 14, in <module>
    output = modelopera.accuracy(model, valid_loader, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 30, in accuracy
    if weights is None:
KeyboardInterrupt
              precision    recall  f1-score   support

           0       0.71      1.00      0.83         5
           1       0.50      0.67      0.57         3
           2       1.00      1.00      1.00         5
           3       0.89      1.00      0.94         8
           4       1.00      1.00      1.00         8
           5       1.00      1.00      1.00         4
           6       0.88      1.00      0.93         7
           7       0.67      0.22      0.33         9
           8       1.00      1.00      1.00         8
           9       1.00      1.00      1.00         7
          10       1.00      0.71      0.83         7
          11       0.60      1.00      0.75         6
          12       0.86      0.86      0.86         7
          13       1.00      0.90      0.95        10
          14       0.80      0.80      0.80         5
          15       1.00      1.00      1.00         5

    accuracy                           0.88       104
   macro avg       0.87      0.89      0.86       104
weighted avg       0.88      0.88      0.86       104

0.875
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 14, in <module>
    output = modelopera.accuracy(model, valid_loader, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 27, in accuracy
    p = network.predict(x)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 148, in predict
    return self.classifier(self.bottleneck(self.featurizer(x)))
KeyboardInterrupt
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 14, in <module>
    output = modelopera.accuracy(model, valid_loader, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 27, in accuracy
    p = network.predict(x)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 148, in predict
    return self.classifier(self.bottleneck(self.featurizer(x)))
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
KeyboardInterrupt
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 14, in <module>
    output = modelopera.accuracy(model, valid_loader, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 27, in accuracy
    p = network.predict(x)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 149, in predict
    return self.classifier(self.bottleneck(self.featurizer(x)))
KeyboardInterrupt
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 14, in <module>
    output = modelopera.accuracy(model, valid_loader, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 27, in accuracy
    p = network.predict(x)
  File "E:\robustlearn\diversify\alg\algs\diversify.py", line 149, in predict
    return self.classifier(self.bottleneck(self.featurizer(x)))
KeyboardInterrupt
Traceback (most recent call last):
  File "E:\robustlearn\diversify\alg\modelopera.py", line 29, in accuracy
    features = np.concatenate((features, feature))
  File "<__array_function__ internals>", line 6, in concatenate
ValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)
Traceback (most recent call last):
  File "E:\robustlearn\diversify\alg\modelopera.py", line 29, in accuracy
    features = np.concatenate((features, feature))
  File "<__array_function__ internals>", line 6, in concatenate
ValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)
E:\robustlearn\diversify\alg\modelopera.py:53: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  features = np.array(features)
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 14, in <module>
    output = modelopera.accuracy(model, valid_loader, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 54, in accuracy
    features = np.reshape(data_x, (data_x.shape[0], data_x.shape[2] * data_x.shape[1]))
KeyboardInterrupt
E:\robustlearn\diversify\alg\modelopera.py:53: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  features = np.array(features)
Traceback (most recent call last):
  File "C:/Program Files/JetBrains/PyCharm 2021.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm 2021.2.3\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "E:\robustlearn\diversify\test.py", line 14, in <module>
    output = modelopera.accuracy(model, valid_loader, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 54, in accuracy
    features = np.reshape(features, (features.shape[0] * features.shape[1], features.shape[2]))
IndexError: tuple index out of range
E:\robustlearn\diversify\alg\modelopera.py:53: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  features = np.array(features)
Traceback (most recent call last):
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\numpy\core\fromnumeric.py", line 57, in _wrapfunc
    return bound(*args, **kwds)
ValueError: cannot reshape array of size 4 into shape (128,1408)
E:\robustlearn\diversify\alg\modelopera.py:53: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  features = np.array(features)
Traceback (most recent call last):
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\numpy\core\fromnumeric.py", line 57, in _wrapfunc
    return bound(*args, **kwds)
ValueError: cannot reshape array of size 4 into shape (128,1408)
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 14, in <module>
    output = modelopera.accuracy(model, valid_loader, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 54, in accuracy
    features = np.array(features)
KeyboardInterrupt
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 14, in <module>
    output = modelopera.accuracy(model, valid_loader, None, "p")
KeyboardInterrupt
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 12, in <module>
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 61, in get_act_dataloader
    train_loader, train_loader_noshuffle, valid_loader, target_loader = get_dataloader(
KeyboardInterrupt
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 12, in <module>
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 61, in get_act_dataloader
    train_loader, train_loader_noshuffle, valid_loader, target_loader = get_dataloader(
KeyboardInterrupt
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 14, in <module>
    output = modelopera.accuracy(model, train_loader, None, "p")
KeyboardInterrupt
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 14, in <module>
    output = modelopera.accuracy(model, train_loader_noshuffle, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 54, in accuracy
    features = np.array(features)
KeyboardInterrupt
E:\robustlearn\diversify\alg\modelopera.py:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  features = np.array(features)
Traceback (most recent call last):
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\numpy\core\fromnumeric.py", line 57, in _wrapfunc
    return bound(*args, **kwds)
ValueError: cannot reshape array of size 17 into shape (524,1408)
              precision    recall  f1-score   support

           0       0.53      0.76      0.62        33
           1       0.79      0.85      0.82        27
           2       0.87      0.87      0.87        30
           3       0.60      0.27      0.37        33
           4       1.00      0.97      0.99        37
           5       0.95      0.64      0.77        28
           6       0.71      0.97      0.82        33
           7       0.69      1.00      0.82        29
           8       0.93      0.93      0.93        41
           9       0.72      1.00      0.84        31
          10       0.78      0.82      0.80        34
          11       0.75      0.38      0.50        32
          12       0.53      0.25      0.34        32
          13       0.71      0.97      0.82        35
          14       0.65      0.33      0.44        33
          15       0.80      1.00      0.89        36

    accuracy                           0.76       524
   macro avg       0.75      0.75      0.73       524
weighted avg       0.75      0.76      0.73       524

Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 14, in <module>
    output = modelopera.accuracy(model, train_loader_noshuffle, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 56, in accuracy
    features = np.array(features)
KeyboardInterrupt
              precision    recall  f1-score   support

           0       0.53      0.76      0.62        33
           1       0.79      0.85      0.82        27
           2       0.87      0.87      0.87        30
           3       0.60      0.27      0.37        33
           4       1.00      0.97      0.99        37
           5       0.95      0.64      0.77        28
           6       0.71      0.97      0.82        33
           7       0.69      1.00      0.82        29
           8       0.93      0.93      0.93        41
           9       0.72      1.00      0.84        31
          10       0.78      0.82      0.80        34
          11       0.75      0.38      0.50        32
          12       0.53      0.25      0.34        32
          13       0.71      0.97      0.82        35
          14       0.65      0.33      0.44        33
          15       0.80      1.00      0.89        36

    accuracy                           0.76       524
   macro avg       0.75      0.75      0.73       524
weighted avg       0.75      0.76      0.73       524

Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 14, in <module>
    output = modelopera.accuracy(model, train_loader_noshuffle, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 57, in accuracy
    features = np.array(features)
KeyboardInterrupt
              precision    recall  f1-score   support

           0       0.97      0.97      0.97        33
           1       0.93      1.00      0.96        27
           2       0.97      1.00      0.98        30
           3       0.88      0.91      0.90        33
           4       0.90      1.00      0.95        37
           5       0.96      0.96      0.96        28
           6       0.76      0.85      0.80        33
           7       0.76      0.90      0.83        29
           8       1.00      0.98      0.99        41
           9       0.89      1.00      0.94        31
          10       1.00      0.94      0.97        34
          11       1.00      0.97      0.98        32
          12       0.88      0.88      0.88        32
          13       0.78      0.51      0.62        35
          14       1.00      0.85      0.92        33
          15       1.00      1.00      1.00        36

    accuracy                           0.92       524
   macro avg       0.92      0.92      0.92       524
weighted avg       0.92      0.92      0.92       524

Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 14, in <module>
    output = modelopera.accuracy(model, train_loader_noshuffle, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 57, in accuracy
    features = np.array(features)
KeyboardInterrupt
              precision    recall  f1-score   support

           0       0.86      0.97      0.91        33
           1       1.00      0.78      0.88        27
           2       1.00      0.87      0.93        30
           3       0.91      0.94      0.93        33
           4       1.00      0.95      0.97        37
           5       0.97      1.00      0.98        28
           6       0.94      0.94      0.94        33
           7       0.83      1.00      0.91        29
           8       0.97      0.80      0.88        41
           9       0.76      1.00      0.86        31
          10       0.91      0.88      0.90        34
          11       0.93      0.88      0.90        32
          12       0.97      0.97      0.97        32
          13       1.00      1.00      1.00        35
          14       0.90      0.82      0.86        33
          15       0.92      1.00      0.96        36

    accuracy                           0.92       524
   macro avg       0.93      0.92      0.92       524
weighted avg       0.93      0.92      0.92       524

Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 14, in <module>
    output = modelopera.accuracy(model, train_loader_noshuffle, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 57, in accuracy
    features = np.array(features)
KeyboardInterrupt
              precision    recall  f1-score   support

           0       0.86      0.94      0.90        33
           1       0.44      0.52      0.47        27
           2       0.73      1.00      0.85        30
           3       0.81      0.91      0.86        33
           4       1.00      0.62      0.77        37
           5       0.82      1.00      0.90        28
           6       0.93      0.85      0.89        33
           7       0.31      0.31      0.31        29
           8       0.81      0.41      0.55        41
           9       0.77      0.77      0.77        31
          10       0.84      0.79      0.82        34
          11       0.87      0.84      0.86        32
          12       0.94      0.97      0.95        32
          13       0.79      0.77      0.78        35
          14       0.93      0.76      0.83        33
          15       0.68      1.00      0.81        36

    accuracy                           0.78       524
   macro avg       0.78      0.78      0.77       524
weighted avg       0.79      0.78      0.77       524

Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 14, in <module>
    output = modelopera.accuracy(model, train_loader_noshuffle, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 57, in accuracy
    features = np.array(features)
KeyboardInterrupt
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 12, in <module>
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 40, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 18, in __init__
    x, cy, py, sy = loaddata_from_numpy(self.dataset, self.task, root_dir)
  File "E:\robustlearn\diversify\datautil\actdata\util.py", line 65, in loaddata_from_numpy
    if data_y.count(y_train[id_]) > num_class[str(y_train[id_])]:
KeyboardInterrupt
              precision    recall  f1-score   support

           0       0.86      0.94      0.90        33
           1       0.44      0.52      0.47        27
           2       0.73      1.00      0.85        30
           3       0.81      0.91      0.86        33
           4       1.00      0.62      0.77        37
           5       0.82      1.00      0.90        28
           6       0.93      0.85      0.89        33
           7       0.31      0.31      0.31        29
           8       0.81      0.41      0.55        41
           9       0.77      0.77      0.77        31
          10       0.84      0.79      0.82        34
          11       0.87      0.84      0.86        32
          12       0.94      0.97      0.95        32
          13       0.79      0.77      0.78        35
          14       0.93      0.76      0.83        33
          15       0.68      1.00      0.81        36

    accuracy                           0.78       524
   macro avg       0.78      0.78      0.77       524
weighted avg       0.79      0.78      0.77       524

Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 14, in <module>
    output = modelopera.accuracy(model, train_loader_noshuffle, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 63, in accuracy
    return correct / total
KeyboardInterrupt
              precision    recall  f1-score   support

           0       0.79      0.70      0.74        33
           1       0.96      0.93      0.94        27
           2       0.96      0.87      0.91        30
           3       0.94      0.94      0.94        33
           4       1.00      0.97      0.99        37
           5       1.00      1.00      1.00        28
           6       0.92      1.00      0.96        33
           7       0.88      1.00      0.94        29
           8       0.97      0.88      0.92        41
           9       0.83      0.97      0.90        31
          10       0.96      0.79      0.87        34
          11       0.73      1.00      0.84        32
          12       0.91      1.00      0.96        32
          13       0.90      0.77      0.83        35
          14       0.89      0.73      0.80        33
          15       0.90      0.97      0.93        36

    accuracy                           0.90       524
   macro avg       0.91      0.91      0.90       524
weighted avg       0.91      0.90      0.90       524

No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 14, in <module>
    output = modelopera.accuracy(model, train_loader_noshuffle, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 64, in accuracy
    return correct / total
KeyboardInterrupt
              precision    recall  f1-score   support

           0       0.79      0.70      0.74        33
           1       0.96      0.93      0.94        27
           2       0.96      0.87      0.91        30
           3       0.94      0.94      0.94        33
           4       1.00      0.97      0.99        37
           5       1.00      1.00      1.00        28
           6       0.92      1.00      0.96        33
           7       0.88      1.00      0.94        29
           8       0.97      0.88      0.92        41
           9       0.83      0.97      0.90        31
          10       0.96      0.79      0.87        34
          11       0.73      1.00      0.84        32
          12       0.91      1.00      0.96        32
          13       0.90      0.77      0.83        35
          14       0.89      0.73      0.80        33
          15       0.90      0.97      0.93        36

    accuracy                           0.90       524
   macro avg       0.91      0.91      0.90       524
weighted avg       0.91      0.90      0.90       524

Traceback (most recent call last):
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\matplotlib\cbook\__init__.py", line 2016, in _setattr_cm
    yield
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\matplotlib\artist.py", line 1067, in update
    raise AttributeError(f"{type(self).__name__!r} object "
AttributeError: 'PathCollection' object has no property 'palette'
              precision    recall  f1-score   support

           0       0.79      0.70      0.74        33
           1       0.96      0.93      0.94        27
           2       0.96      0.87      0.91        30
           3       0.94      0.94      0.94        33
           4       1.00      0.97      0.99        37
           5       1.00      1.00      1.00        28
           6       0.92      1.00      0.96        33
           7       0.88      1.00      0.94        29
           8       0.97      0.88      0.92        41
           9       0.83      0.97      0.90        31
          10       0.96      0.79      0.87        34
          11       0.73      1.00      0.84        32
          12       0.91      1.00      0.96        32
          13       0.90      0.77      0.83        35
          14       0.89      0.73      0.80        33
          15       0.90      0.97      0.93        36

    accuracy                           0.90       524
   macro avg       0.91      0.91      0.90       524
weighted avg       0.91      0.90      0.90       524

Traceback (most recent call last):
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\matplotlib\cbook\__init__.py", line 2016, in _setattr_cm
    yield
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\matplotlib\artist.py", line 1067, in update
    raise AttributeError(f"{type(self).__name__!r} object "
AttributeError: 'PathCollection' object has no property 'palette'
              precision    recall  f1-score   support

           0       0.79      0.70      0.74        33
           1       0.96      0.93      0.94        27
           2       0.96      0.87      0.91        30
           3       0.94      0.94      0.94        33
           4       1.00      0.97      0.99        37
           5       1.00      1.00      1.00        28
           6       0.92      1.00      0.96        33
           7       0.88      1.00      0.94        29
           8       0.97      0.88      0.92        41
           9       0.83      0.97      0.90        31
          10       0.96      0.79      0.87        34
          11       0.73      1.00      0.84        32
          12       0.91      1.00      0.96        32
          13       0.90      0.77      0.83        35
          14       0.89      0.73      0.80        33
          15       0.90      0.97      0.93        36

    accuracy                           0.90       524
   macro avg       0.91      0.91      0.90       524
weighted avg       0.91      0.90      0.90       524

Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 14, in <module>
    output = modelopera.accuracy(model, train_loader_noshuffle, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 71, in accuracy
    return correct / total
KeyboardInterrupt
              precision    recall  f1-score   support

           0       0.86      0.97      0.91        33
           1       1.00      0.78      0.88        27
           2       1.00      0.87      0.93        30
           3       0.91      0.94      0.93        33
           4       1.00      0.95      0.97        37
           5       0.97      1.00      0.98        28
           6       0.94      0.94      0.94        33
           7       0.83      1.00      0.91        29
           8       0.97      0.80      0.88        41
           9       0.76      1.00      0.86        31
          10       0.91      0.88      0.90        34
          11       0.93      0.88      0.90        32
          12       0.97      0.97      0.97        32
          13       1.00      1.00      1.00        35
          14       0.90      0.82      0.86        33
          15       0.92      1.00      0.96        36

    accuracy                           0.92       524
   macro avg       0.93      0.92      0.92       524
weighted avg       0.93      0.92      0.92       524

Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 14, in <module>
    output = modelopera.accuracy(model, train_loader_noshuffle, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 71, in accuracy
    return correct / total
KeyboardInterrupt
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 12, in <module>
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 40, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 18, in __init__
    x, cy, py, sy = loaddata_from_numpy(self.dataset, self.task, root_dir)
  File "E:\robustlearn\diversify\datautil\actdata\util.py", line 119, in loaddata_from_numpy
    return x_train, cy, py, sy
KeyboardInterrupt
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 12, in <module>
    args)
  File "E:\robustlearn\diversify\datautil\getdataloader_single.py", line 40, in get_act_dataloader
    args, args.dataset, args.data_dir, item, i, transform=actutil.act_train())
  File "E:\robustlearn\diversify\datautil\actdata\cross_people.py", line 18, in __init__
    x, cy, py, sy = loaddata_from_numpy(self.dataset, self.task, root_dir)
  File "E:\robustlearn\diversify\datautil\actdata\util.py", line 119, in loaddata_from_numpy
    return x_train, cy, py, sy
KeyboardInterrupt
              precision    recall  f1-score   support

           0       0.80      1.00      0.89        33
           1       0.93      1.00      0.96        27
           2       0.94      1.00      0.97        30
           3       1.00      1.00      1.00        33
           4       1.00      0.86      0.93        37
           5       0.79      0.93      0.85        28
           6       0.89      0.52      0.65        33
           7       0.68      0.97      0.80        29
           8       0.78      0.78      0.78        41
           9       0.83      0.94      0.88        31
          10       0.97      0.85      0.91        34
          11       0.90      0.81      0.85        32
          12       0.76      0.78      0.77        32
          13       0.86      0.89      0.87        35
          14       1.00      0.88      0.94        33
          15       0.90      0.78      0.84        36

    accuracy                           0.87       524
   macro avg       0.88      0.87      0.87       524
weighted avg       0.88      0.87      0.87       524

Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 14, in <module>
    output = modelopera.accuracy(model, train_loader_noshuffle, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 71, in accuracy
    return correct / total
KeyboardInterrupt
              precision    recall  f1-score   support

           0       0.86      0.97      0.91        33
           1       1.00      0.78      0.88        27
           2       1.00      0.87      0.93        30
           3       0.91      0.94      0.93        33
           4       1.00      0.95      0.97        37
           5       0.97      1.00      0.98        28
           6       0.94      0.94      0.94        33
           7       0.83      1.00      0.91        29
           8       0.97      0.80      0.88        41
           9       0.76      1.00      0.86        31
          10       0.91      0.88      0.90        34
          11       0.93      0.88      0.90        32
          12       0.97      0.97      0.97        32
          13       1.00      1.00      1.00        35
          14       0.90      0.82      0.86        33
          15       0.92      1.00      0.96        36

    accuracy                           0.92       524
   macro avg       0.93      0.92      0.92       524
weighted avg       0.93      0.92      0.92       524

Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 14, in <module>
    output = modelopera.accuracy(model, train_loader_noshuffle, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 71, in accuracy
    return correct / total
KeyboardInterrupt
              precision    recall  f1-score   support

           0       0.72      0.55      0.62        33
           1       0.90      1.00      0.95        27
           2       0.67      0.20      0.31        30
           3       0.53      1.00      0.69        33
           4       0.88      0.97      0.92        37
           5       0.93      0.96      0.95        28
           6       0.69      0.67      0.68        33
           7       0.52      0.45      0.48        29
           8       0.85      0.98      0.91        41
           9       0.57      0.90      0.70        31
          10       0.88      0.62      0.72        34
          11       0.64      0.56      0.60        32
          12       0.94      0.94      0.94        32
          13       0.79      0.54      0.64        35
          14       0.94      0.91      0.92        33
          15       1.00      0.97      0.99        36

    accuracy                           0.77       524
   macro avg       0.78      0.76      0.75       524
weighted avg       0.78      0.77      0.76       524

Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 14, in <module>
    output = modelopera.accuracy(model, train_loader_noshuffle, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 71, in accuracy
    return correct / total
KeyboardInterrupt
              precision    recall  f1-score   support

           0       0.86      0.97      0.91        33
           1       1.00      0.78      0.88        27
           2       1.00      0.87      0.93        30
           3       0.91      0.94      0.93        33
           4       1.00      0.95      0.97        37
           5       0.97      1.00      0.98        28
           6       0.94      0.94      0.94        33
           7       0.83      1.00      0.91        29
           8       0.97      0.80      0.88        41
           9       0.76      1.00      0.86        31
          10       0.91      0.88      0.90        34
          11       0.93      0.88      0.90        32
          12       0.97      0.97      0.97        32
          13       1.00      1.00      1.00        35
          14       0.90      0.82      0.86        33
          15       0.92      1.00      0.96        36

    accuracy                           0.92       524
   macro avg       0.93      0.92      0.92       524
weighted avg       0.93      0.92      0.92       524

Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 14, in <module>
    output = modelopera.accuracy(model, train_loader_noshuffle, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 71, in accuracy
    return correct / total
KeyboardInterrupt
              precision    recall  f1-score   support

           0       0.79      0.70      0.74        33
           1       0.96      0.93      0.94        27
           2       0.96      0.87      0.91        30
           3       0.94      0.94      0.94        33
           4       1.00      0.97      0.99        37
           5       1.00      1.00      1.00        28
           6       0.92      1.00      0.96        33
           7       0.88      1.00      0.94        29
           8       0.97      0.88      0.92        41
           9       0.83      0.97      0.90        31
          10       0.96      0.79      0.87        34
          11       0.73      1.00      0.84        32
          12       0.91      1.00      0.96        32
          13       0.90      0.77      0.83        35
          14       0.89      0.73      0.80        33
          15       0.90      0.97      0.93        36

    accuracy                           0.90       524
   macro avg       0.91      0.91      0.90       524
weighted avg       0.91      0.90      0.90       524

Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 14, in <module>
    output = modelopera.accuracy(model, train_loader_noshuffle, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 71, in accuracy
    return correct / total
KeyboardInterrupt
              precision    recall  f1-score   support

           0       0.79      0.70      0.74        33
           1       0.96      0.93      0.94        27
           2       0.96      0.87      0.91        30
           3       0.94      0.94      0.94        33
           4       1.00      0.97      0.99        37
           5       1.00      1.00      1.00        28
           6       0.92      1.00      0.96        33
           7       0.88      1.00      0.94        29
           8       0.97      0.88      0.92        41
           9       0.83      0.97      0.90        31
          10       0.96      0.79      0.87        34
          11       0.73      1.00      0.84        32
          12       0.91      1.00      0.96        32
          13       0.90      0.77      0.83        35
          14       0.89      0.73      0.80        33
          15       0.90      0.97      0.93        36

    accuracy                           0.90       524
   macro avg       0.91      0.91      0.90       524
weighted avg       0.91      0.90      0.90       524

Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 14, in <module>
    output = modelopera.accuracy(model, train_loader_noshuffle, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 75, in accuracy
    return correct / total
KeyboardInterrupt
              precision    recall  f1-score   support

           0       0.79      0.70      0.74        33
           1       0.96      0.93      0.94        27
           2       0.96      0.87      0.91        30
           3       0.94      0.94      0.94        33
           4       1.00      0.97      0.99        37
           5       1.00      1.00      1.00        28
           6       0.92      1.00      0.96        33
           7       0.88      1.00      0.94        29
           8       0.97      0.88      0.92        41
           9       0.83      0.97      0.90        31
          10       0.96      0.79      0.87        34
          11       0.73      1.00      0.84        32
          12       0.91      1.00      0.96        32
          13       0.90      0.77      0.83        35
          14       0.89      0.73      0.80        33
          15       0.90      0.97      0.93        36

    accuracy                           0.90       524
   macro avg       0.91      0.91      0.90       524
weighted avg       0.91      0.90      0.90       524

Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 14, in <module>
    output = modelopera.accuracy(model, train_loader_noshuffle, None, "p")
  File "E:\robustlearn\diversify\alg\modelopera.py", line 75, in accuracy
    return correct / total
KeyboardInterrupt
Traceback (most recent call last):
  File "E:\robustlearn\diversify\test.py", line 7, in <module>
    model = torch.load("model.pth")
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\serialization.py", line 712, in load
    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\serialization.py", line 1049, in _load
    result = unpickler.load()
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\serialization.py", line 1019, in persistent_load
    load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\serialization.py", line 1001, in load_tensor
    wrap_storage=restore_location(storage, location),
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\serialization.py", line 175, in default_restore_location
    result = fn(storage, location)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\serialization.py", line 157, in _cuda_deserialize
    return obj.cuda(device)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\_utils.py", line 78, in _cuda
    return torch._UntypedStorage(self.size(), device=torch.device('cuda')).copy_(self, non_blocking)
  File "C:\Users\ADMIN\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\storage.py", line 23, in __init__
    def __init__(self, *args, **kwargs): ...  # noqa: E704
KeyboardInterrupt
